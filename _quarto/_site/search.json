[
  {
    "objectID": "CITATION.html",
    "href": "CITATION.html",
    "title": "Citation",
    "section": "",
    "text": "Citation\nTo cite package ‘webgazeR’ in publications use:\n\nGeller J, Prystauka Y (????). webgazeR: Tools for Processing Webcam Eye Tracking Data. R package version 0.1.0.",
    "crumbs": [
      "Citation"
    ]
  },
  {
    "objectID": "LICENSE.html",
    "href": "LICENSE.html",
    "title": "webgazeR v0.7.2",
    "section": "",
    "text": "MIT License\nCopyright (c) 2025 Jason Geller\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\nTHE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.",
    "crumbs": [
      "License"
    ]
  },
  {
    "objectID": "vignettes/webgazeR_vignette.html",
    "href": "vignettes/webgazeR_vignette.html",
    "title": "Introduction to webgazeR",
    "section": "",
    "text": "Here I outline the basic functions of the webgazeR package. I am using quarto-webr which allows for code to be run interactively in your browser!",
    "crumbs": [
      "Articles",
      "Introduction to webgazeR"
    ]
  },
  {
    "objectID": "vignettes/webgazeR_vignette.html#packages",
    "href": "vignettes/webgazeR_vignette.html#packages",
    "title": "Introduction to webgazeR",
    "section": "Packages",
    "text": "Packages\nBelow are the basic packages needed to run this vignette. The below code chunks will load in the packages needed.\n\nResultInteractive\n\n\noptions(stringsAsFactors = F)          # no automatic data transformation\noptions(\"scipen\" = 100, \"digits\" = 10) # suppress math annotation\nlibrary(tidyverse) \nlibrary(here) # relative paths instead of abosoulte aids in reproduce\nlibrary(tinytable) # nice tables\nlibrary(janitor)# functions for cleaning up your column names\nlibrary(easystats)\nlibrary(knitr)\nlibrary(ggokabeito)\n#install.packages('webgazeR', repos = c('https://jgeller112.r-universe.dev', 'https://cloud.r-project.org'))\nlibrary(webgazeR)\nlibrary(zoo)# interpolation\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\nLoad webgazeR\n\nFirst you must install it via Github.\n\n\nResultInteractive\n\n\n# do not run interactively\nremotes::install_github(\"https://github.com/jgeller112/webgazeR\")\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\nThen you can load it into your session\n\n\nResultInteractive\n\n\n# load the package\nlibrary(webgazeR)\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.",
    "crumbs": [
      "Articles",
      "Introduction to webgazeR"
    ]
  },
  {
    "objectID": "vignettes/webgazeR_vignette.html#eye-data",
    "href": "vignettes/webgazeR_vignette.html#eye-data",
    "title": "Introduction to webgazeR",
    "section": "Eye data",
    "text": "Eye data\nWhen data is generated from Gorilla, each trial in your experiment is its own file. Because of this, we need to take all the individual files and merge them together. The merge_webcam_files function merges each trial from each participant into a single tibble or dataframe. Before running the merge_webcam_files function, ensure that your working directory is set to where the files are stored. This function reads in all the .xlsx files, binds them together into one dataframe, and cleans up the column names. The function then filters the data to include only rows where the type is “prediction” and the screen_index matches the specified value (in our case, screen 4). This is where eye-tracking data was recorded. The function renames the spreadsheet_row column to trial and sets both trial and subjectas factors for further analysis in our pipeline. As a note, all steps should be followed in order due to the renaming of column names. If you encounter an error it might be because column names have not been changed.\n\nResultInteractive\n\n\n# Get the list of all files in the folder\nvwp_files  &lt;- list.files(here::here(\"data\", \"monolinguals\", \"raw\"), pattern = \"\\\\.xlsx$\", full.names = TRUE)\n\n# Exclude files that contain \"calibration\" in their filename\nvwp_paths_filtered &lt;- vwp_files[!grepl(\"calibration\", vwp_files)]\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\nResultInteractive\n\n\nsetwd(here::here(\"data\", \"monolinguals\", \"raw\")) # set working directory to raw data folder\n\nedat &lt;- merge_webcam_files(vwp_paths_filtered, screen_index=4) # eye tracking occured ons creen index 4\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nthe webgazeR package includes a combined dataset for us to use.\n\nResultInteractive\n\n\nedat &lt;- webgazeR::eyedata\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\nBehavioral Data\nGorilla produces a .csv file that include trial-level information (agg_ege_data). Below we read that object in and create an object called emstr that selects useful columns from that file and renames stimuli to make them more intuitive. Because most of this will be user-specific, no function is called here.\n\nResultInteractive\n\n\n# load in trial level data\nagg_eye_data &lt;- webgazeR::behav_data\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nBelow we describe the pre-processing done on the behavioral data file. The below code processes and transforms the agg_eye_data dataset into a cleaned and structured format for further analysis. First, the code renames several columns for easier access using the janitor::clean_names function. It filters the dataset to include only rows where zone_type is “response_button_image”, representing the picture selected for that trial. Afterward, the function renames additional columns (tlpic to TL, trpic to TR, etc.). We also renamed participant_private_id to subject, spreadsheet_row to trial, and reaction_time to RT. This makes our columns consistent with the edat above for merging later on. Lastly, the `reaction time (RT) is converted to a numeric format for further numerical analysis.\n\nResultInteractive\n\n\nemstr &lt;- agg_eye_data %&gt;%\n  \n  janitor::clean_names() %&gt;%\n  \n  # Select specific columns to keep in the dataset\n  dplyr::select(participant_private_id,  correct, tlpic, trpic, blpic, brpic, trialtype, targetword, screen_name, tlcode, trcode, blcode, brcode, zone_name, zone_type,reaction_time, spreadsheet_row, response) %&gt;%\n  \n  # Filter the rows where 'Zone.Type' equals \"response_button_image\"\n  dplyr::filter(screen_name == \"VWP\", zone_type == \"response_button_image\") %&gt;%\n  \n  # Rename columns for easier use and readability\n  dplyr::rename(\n    \"TL\" = \"tlpic\",              # Rename 'tlpic' to 'TL'\n    \"TR\" = \"trpic\",             # Rename 'trpic' to 'TR'\n    \"BL\" = \"blpic\",            # Rename 'blpic' to 'BL'\n    \"BR\" = \"brpic\",                # Rename 'brpic' to 'BR'\n    \"targ_loc\" = \"zone_name\",       # Rename 'Zone.Name' to 'targ_loc'\n    \"subject\" = \"participant_private_id\",  # Rename 'Participant.Private.ID' to 'subject'\n    \"trial\" = \"spreadsheet_row\",    # Rename 'spreadsheet_row' to 'trial'\n    \"acc\" = \"correct\",              # Rename 'Correct' to 'acc' (accuracy)\n    \"RT\" = \"reaction_time\"          # Rename 'Reaction.Time' to 'RT'\n  ) %&gt;%\n  \n  # Convert the 'RT' (Reaction Time) column to numeric type\n  mutate(RT = as.numeric(RT), \n         subject=as.factor(subject), \n         trial=as.factor(trial))\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\nGet audio onset time\nBecause we are using audio on each trial and we are running this experiment for the browser audio onset is never going to to conistent across participants. In Gorilla there is an option to collect advanced audio features such as when the audio play was requested, fired (played) and ended. We will want to incorporate this into our pipeline. Gorilla records the onset of the audio which varies by participant. We are extracting that here by filtering zone_type to content_web_audio and response equal to “AUDIO PLAY EVENT FIRED”. This will tell us when the audio was triggered in the experiment (reaction_time).\n\nResultInteractive\n\n\naudio_rt &lt;- agg_eye_data %&gt;%\n  \n  janitor::clean_names()%&gt;% \n\nselect(participant_private_id,zone_type, spreadsheet_row, reaction_time, response) %&gt;%\n\n  filter(zone_type==\"content_web_audio\", response==\"AUDIO PLAY EVENT FIRED\")%&gt;%\n  distinct() %&gt;%\nrename(\"subject\" = \"participant_private_id\", \n       \"trial\" =\"spreadsheet_row\",  \n       \"RT_audio\" = \"reaction_time\") %&gt;%\nselect(-zone_type) %&gt;%\nmutate(RT_audio=as.numeric(RT_audio))\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nWe then merge this information with emstr. We see that RT_audio has been added to our dataframe.\n\nResultInteractive\n\n\ntrial_data_rt &lt;- merge(emstr, audio_rt, by=c(\"subject\", \"trial\"))\n\nhead(trial_data_rt) %&gt;%\n  head() %&gt;%\n  kable()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsubject\ntrial\nacc\nTL\nTR\nBL\nBR\ntrialtype\ntargetword\nscreen_name\ntlcode\ntrcode\nblcode\nbrcode\ntarg_loc\nzone_type\nRT\nresponse.x\nRT_audio\nresponse.y\n\n\n\n\n11788555\n10\n1\nsunrise.jpg\npillar.jpg\npillow.jpg\nwillow.jpg\nTRUU\nwillow.jpg\nVWP\nR\nU\nU2\nT\nBR\nresponse_button_image\n1822.1999998\nwillow.jpg\n17.09999990\nAUDIO PLAY EVENT FIRED\n\n\n11788555\n103\n1\ncap.jpg\nhose.jpg\ngoal.jpg\nhole.jpg\nTCUU\nhose.jpg\nVWP\nU\nT\nU2\nC\nTR\nresponse_button_image\n1467.0000000\nhose.jpg\n10.59999990\nAUDIO PLAY EVENT FIRED\n\n\n11788555\n104\n0\nhip.jpg\ncave.jpg\ncage.jpg\ngauge.jpg\nTCRU\ncage.jpg\nVWP\nU\nC\nT\nR\nTR\nresponse_button_image\n929.8999996\ncave.jpg\n17.89999962\nAUDIO PLAY EVENT FIRED\n\n\n11788555\n106\n1\npear.jpg\nbear.jpg\njet.jpg\nbase.jpg\nTUUU\njet.jpg\nVWP\nU3\nU\nT\nU2\nBL\nresponse_button_image\n1661.4000001\njet.jpg\n12.00000000\nAUDIO PLAY EVENT FIRED\n\n\n11788555\n107\n1\nbeagle.jpg\nmother.jpg\nmoney.jpg\nhoney.jpg\nTCUU\nmother.jpg\nVWP\nU\nT\nC\nU2\nTR\nresponse_button_image\n1513.5999999\nmother.jpg\n15.90000010\nAUDIO PLAY EVENT FIRED\n\n\n11788555\n108\n1\nparrot.jpg\ncarrot.jpg\ncarriage.jpg\ntadpole.jpg\nTCRU\ncarrot.jpg\nVWP\nR\nT\nC\nU\nTR\nresponse_button_image\n1456.8000002\ncarrot.jpg\n16.00000000\nAUDIO PLAY EVENT FIRED\n\n\n\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\nSampling Rate\nWhile most commercial eye-trackers sample at a constant rate, webcam eye-trackers do not. Below is some code to calculate the sampling rate of each participant. Ideally, you should not have a sampling rate less than 5 Hz. It has been recommended you drop those values. The below function analyze_sample_rate calculates calculates the sampling rate for each subject and trial in an eye-tracking dataset. It provides overall statistics, including the median and standard deviation of sampling rates in your experiment,and also generates a histogram of median sampling rates by subject with a density plot overlayed.\n\nResultInteractive\n\n\nsamp_rate &lt;- analyze_sampling_rate(edat, summary_stat = \"mean\")\n\nOverall mean Sampling Rate (Hz): 22.71 \nOverall SD of Sampling Rate (Hz): 7.85 \n\n\n\n\n\n\n\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\nResultInteractive\n\n\nsamp_rate$subject &lt;- as.factor(samp_rate$subject)\nsamp_rate$trial &lt;- as.factor(samp_rate$trial)\n\n\ntrial_data &lt;- left_join(trial_data_rt, samp_rate, by=c(\"subject\", \"trial\"))\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nUsers can use the filter_sampling_rate function to either either (1) throw out data, by subject, by trial, or both, and (2) label it sampling rates below a certain threshold as bad (TRUE or FALSE). Let’s use the filter_sampling_rate() function to do this. We will read in our target_data_with_full_SR object.\nWe leave it up to the user to decide what to do and make no specific recommendations. In our case we are going to remove the data by subject and by trial (action==“both”) if sampling frequency is below 5hz (threshold=5). The filter_sampling_rate function is designed to process a dataset containing subject-level and trial-level sampling rates. It allows the user to either filter out data that falls below a certain sampling rate threshold or simply label it as “bad”. The function gives flexibility by allowing the threshold to be applied at the subject level, trial level, or both. It also lets the user decide whether to remove the data or flag it as below the threshold without removing it. If action = remove, the function will output how many subjects and trials were removed by on the threshold.\n\nResultInteractive\n\n\nfilter_edat &lt;- filter_sampling_rate(trial_data,threshold = 5, \n                                         action = \"remove\", \n                                         by = \"both\")\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nfilter_edat returns a dataframe with trials and subjects removed. If we set the argument action to label, filter_edat_label would return a dataframe that includes column(s) with sampling rates &lt; 5 labeled as TRUE (bad) or FALSE\n\nResultInteractive\n\n\nfilter_edat_label &lt;- filter_sampling_rate(trial_data,threshold = 5, \n                                         action = \"label\", \n                                         by=\"both\")\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nHere no subjects had a threshold below 5. However, 18 trials did, and they were removed.\n\n\nOut-of-bounds (outside of screen)\nIt is important that we do not include points that fall outside the standardized coordinates. The gaze_oob function calculates how many of the data points fall outside the standardized range. This function returns how many data points fall outside this range by subject and provides a percentage. This information would be useful to include in the final paper. We then add by-subject and by-trial out of bounds data and exclude participants and trials with &gt; 30% missing data.\n\nResultInteractive\n\n\noob_data &lt;- gaze_oob(data=edat, subject_col = \"subject\",\n                      trial_col = \"trial\",\n                      x_col = \"x_pred_normalised\",\n                      y_col = \"y_pred_normalised\",\n                     screen_size = c(1, 1), # standardized coordinates have screen size 1,1\n                      remove = TRUE)\n\nSubject: 11788555\nTotal trials: 54\nTotal points: 2483\nTotal missing percentage: 24.49%\nX: 17.28%\nY: 13.53%\n\n\nSubject: 11788682\nTotal trials: 154\nTotal points: 5798\nTotal missing percentage: 9.5%\nX: 6.83%\nY: 3.47%\n\n\nSubject: 11788824\nTotal trials: 134\nTotal points: 6961\nTotal missing percentage: 25.74%\nX: 17.14%\nY: 13.37%\n\n\nSubject: 11788857\nTotal trials: 54\nTotal points: 2237\nTotal missing percentage: 12.38%\nX: 11.85%\nY: 1.3%\n\n\nSubject: 11789574\nTotal trials: 54\nTotal points: 932\nTotal missing percentage: 23.71%\nX: 14.16%\nY: 16.09%\n\n\nSubject: 11795362\nTotal trials: 154\nTotal points: 3951\nTotal missing percentage: 15.39%\nX: 10%\nY: 7.69%\n\n\nSubject: 11795372\nTotal trials: 154\nTotal points: 4598\nTotal missing percentage: 14.72%\nX: 9.11%\nY: 8.22%\n\n\nSubject: 11795375\nTotal trials: 154\nTotal points: 6795\nTotal missing percentage: 14.83%\nX: 11.18%\nY: 6.99%\n\n\nSubject: 11795376\nTotal trials: 154\nTotal points: 6749\nTotal missing percentage: 24.83%\nX: 13.48%\nY: 16.42%\n\n\nSubject: 11795379\nTotal trials: 54\nTotal points: 2247\nTotal missing percentage: 15.58%\nX: 4.36%\nY: 12.28%\n\n\nSubject: 11795382\nTotal trials: 154\nTotal points: 5239\nTotal missing percentage: 10.08%\nX: 6.91%\nY: 5.99%\n\n\nSubject: 11795385\nTotal trials: 154\nTotal points: 6172\nTotal missing percentage: 25.23%\nX: 14.52%\nY: 15.83%\n\n\nSubject: 11795386\nTotal trials: 154\nTotal points: 4658\nTotal missing percentage: 29.99%\nX: 17%\nY: 22.33%\n\n\nSubject: 11795387\nTotal trials: 154\nTotal points: 3634\nTotal missing percentage: 16.13%\nX: 9.41%\nY: 9.25%\n\n\nSubject: 11795388\nTotal trials: 154\nTotal points: 4097\nTotal missing percentage: 18.43%\nX: 11.33%\nY: 11.11%\n\n\nSubject: 11795426\nTotal trials: 154\nTotal points: 1242\nTotal missing percentage: 9.82%\nX: 6.44%\nY: 6.44%\n\n\nSubject: 11795446\nTotal trials: 154\nTotal points: 6712\nTotal missing percentage: 8.13%\nX: 5.91%\nY: 4.68%\n\n\nSubject: 11795529\nTotal trials: 154\nTotal points: 4668\nTotal missing percentage: 10.33%\nX: 6.92%\nY: 4.86%\n\n\nSubject: 11795650\nTotal trials: 154\nTotal points: 2213\nTotal missing percentage: 4.56%\nX: 2.08%\nY: 2.89%\n\n\nSubject: 11795671\nTotal trials: 154\nTotal points: 4982\nTotal missing percentage: 28.86%\nX: 18.15%\nY: 17.7%\n\n\nSubject: 11796749\nTotal trials: 154\nTotal points: 6469\nTotal missing percentage: 29.23%\nX: 23.09%\nY: 13.48%\n\n\nSubject: 11796756\nTotal trials: 154\nTotal points: 6249\nTotal missing percentage: 13.12%\nX: 7.25%\nY: 8.64%\n\n\nSubject: 11796779\nTotal trials: 154\nTotal points: 5737\nTotal missing percentage: 4.41%\nX: 2.18%\nY: 2.75%\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\nZone coordinates\nIn the lab, we can control every aspect of the experiment. Online we cant do this. Participants are going to be completing the experiment under a variety of conditions. This includes using different computers, with very different screen dimensions. To control for this, Gorilla outputs standardized zone coordinates. As discussed in the Gorilla documentation, the Gorilla layout engine lays everything out in a 4:3 frame and makes that frame as big as possible. The normalized coordinates are then expressed relative to this frame; for example, the coordinate 0.5, 0.5 will always be the center of the screen, regardless of the size of the participant’s screen. We used the normalized coordinates in our analysis. However, there are a few different ways to specify the four coordinates of the screen, which I think is worth highlighting.\n\nQuadrant Approach\nOne way is to make the AOIs as big as possible and place them in the four quadrants of the screen. What we will need to first is create a dataframe with location of the AOI (e.g., TL, TR, BL, BR), x and y normalized coordinates and width and height normalized. In addition, we will get the xmin, xmanx, and ymax and ymin of the AOIs.\n\nResultInteractive\n\n\n# Create a data frame for the quadrants with an added column for the quadrant labels\naoi_loc &lt;- data.frame(\n  loc = c('TL', 'TR', 'BL', 'BR'), \n  x_normalized = c(0, 0.5, 0, 0.5),\n   y_normalized = c(0.5, 0.5, 0, 0),\n  width_normalized = c(0.5, 0.5, 0.5, 0.5),\n  height_normalized = c(0.5, 0.5, 0.5, 0.5)) %&gt;% \n  \n  mutate(xmin = x_normalized, ymin = y_normalized,\n         xmax = x_normalized+width_normalized,\n         ymax = y_normalized+height_normalized)\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nloc\nx_normalized\ny_normalized\nwidth_normalized\nheight_normalized\nxmin\nymin\nxmax\nymax\n\n\n\n\nTL\n0.0\n0.5\n0.5\n0.5\n0.0\n0.5\n0.5\n1.0\n\n\nTR\n0.5\n0.5\n0.5\n0.5\n0.5\n0.5\n1.0\n1.0\n\n\nBL\n0.0\n0.0\n0.5\n0.5\n0.0\n0.0\n0.5\n0.5\n\n\nBR\n0.5\n0.0\n0.5\n0.5\n0.5\n0.0\n1.0\n0.5\n\n\n\n\n\n\n\nClean-up eye data\nHere we are going to remove poor convergence scales and confidence. We will also remove coordinates that are 0 in our data.\n\nResultInteractive\n\n\nedat_1 &lt;- oob_data$data_clean  %&gt;%\n dplyr::filter(convergence &lt;= .5, face_conf &gt;= .5)\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\nCombining Eye and Trial-level data\nNext we are going to combine the eye-tracking data and behavioral data by using the left_join function.\n\nResultInteractive\n\n\nedat_1$subject&lt;-as.factor(edat_1$subject)\nedat_1$trial&lt;-as.factor(edat_1$trial)\n\n\n\ndat &lt;- left_join(edat_1, filter_edat, by = c(\"subject\",\"trial\"))\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nLet’s verify our AOIs look how they are suppose to.\n\n\n\n\n\n\n\n\n\n\n\nExcellent!\n\n\nMatching conditions with screen locations\nIn this experiment we have four different trial types:\n\nTarget, Cohort, Rhyme, Unrealted\nTarget, Cohort, Unrealted, Unrelated\nTarget, Unrelated, Unrealted, Unrelated\nTarget, Rhyme, Unrelated, Unrelated\n\nWe will first match the pictures in the TL, TR, BL, BR columns to the correct code condition (T,C, R, U, U2, U3).\n\nResultInteractive\n\n\n# Assuming your data is in a data frame called df\ndat &lt;- dat %&gt;%\n  mutate(\n    Target = case_when(\n      tlcode == \"T\" ~ TL,\n      trcode == \"T\" ~ TR,\n      blcode == \"T\" ~ BL,\n      brcode == \"T\" ~ BR,\n      TRUE ~ NA_character_  # Default to NA if no match\n    ),\n    Unrelated = case_when(\n      tlcode == \"U\" ~ TL,\n      trcode == \"U\" ~ TR,\n      blcode == \"U\" ~ BL,\n      brcode == \"U\" ~ BR,\n      TRUE ~ NA_character_\n    ),\n    Unrelated2 = case_when(\n      tlcode == \"U2\" ~ TL,\n      trcode == \"U2\" ~ TR,\n      blcode == \"U2\" ~ BL,\n      brcode == \"U2\" ~ BR,\n      TRUE ~ NA_character_\n    ),\n    Unrelated3 = case_when(\n      tlcode == \"U3\" ~ TL,\n      trcode == \"U3\" ~ TR,\n      blcode == \"U3\" ~ BL,\n      brcode == \"U3\" ~ BR,\n      TRUE ~ NA_character_\n    ),\n    Rhyme = case_when(\n      tlcode == \"R\" ~ TL,\n      trcode == \"R\" ~ TR,\n      blcode == \"R\" ~ BL,\n      brcode == \"R\" ~ BR,\n      TRUE ~ NA_character_\n    ),\n    Cohort = case_when(\n      tlcode == \"C\" ~ TL,\n      trcode == \"C\" ~ TR,\n      blcode == \"C\" ~ BL,\n      brcode == \"C\" ~ BR,\n      TRUE ~ NA_character_\n    )\n  )\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nX\nx0\nfilename\ntrial\ntime_stamp\ntime\ntype\nscreen_index\nx_pred\ny_pred\nx_pred_normalised\ny_pred_normalised\nconvergence\nface_conf\nzone_name\nzone_x\nzone_y\nzone_width\nzone_height\nzone_x_normalised\nzone_y_normalised\nzone_width_normalised\nzone_height_normalised\nsubject\ntrial_missing_percentage\nsubject_missing_percentage\nacc\nTL\nTR\nBL\nBR\ntrialtype\ntargetword\nscreen_name\ntlcode\ntrcode\nblcode\nbrcode\ntarg_loc\nzone_type\nRT\nresponse.x\nRT_audio\nresponse.y\nn_times\nmax_time\nSR_trial\nSR_subject\nTarget\nUnrelated\nUnrelated2\nUnrelated3\nRhyme\nCohort\n\n\n\n\n2\nNA\neyetracking_collection\n153\n1727868218999\n34.00000000\nprediction\n4\n958.2899489\n78.26706763\n0.4988631366\n0.0771104115\n0\n1\nNA\n0\n0\n0\n0\n0\n0\n0\n0\n11788555\n10.52631579\n24.48650826\n1\ncandle.jpg\nsandal.jpg\nsandwich.jpg\nbuilding.jpg\nTCUU\nsandwich.jpg\nVWP\nU2\nC\nT\nU\nBL\nresponse_button_image\n1997.8\nsandwich.jpg\n13.0999999\nAUDIO PLAY EVENT FIRED\n57\n1922.4\n29.65043695\n29.57322764\nsandwich.jpg\nbuilding.jpg\ncandle.jpg\nNA\nNA\nsandal.jpg\n\n\n3\nNA\neyetracking_collection\n153\n1727868219039\n73.30000019\nprediction\n4\n1036.1006719\n247.37493626\n0.5563729098\n0.2437191490\n0\n1\nNA\n0\n0\n0\n0\n0\n0\n0\n0\n11788555\n10.52631579\n24.48650826\n1\ncandle.jpg\nsandal.jpg\nsandwich.jpg\nbuilding.jpg\nTCUU\nsandwich.jpg\nVWP\nU2\nC\nT\nU\nBL\nresponse_button_image\n1997.8\nsandwich.jpg\n13.0999999\nAUDIO PLAY EVENT FIRED\n57\n1922.4\n29.65043695\n29.57322764\nsandwich.jpg\nbuilding.jpg\ncandle.jpg\nNA\nNA\nsandal.jpg\n\n\n4\nNA\neyetracking_collection\n153\n1727868219076\n113.09999990\nprediction\n4\n1048.4626414\n383.69717600\n0.5655096204\n0.3780267744\n0\n1\nNA\n0\n0\n0\n0\n0\n0\n0\n0\n11788555\n10.52631579\n24.48650826\n1\ncandle.jpg\nsandal.jpg\nsandwich.jpg\nbuilding.jpg\nTCUU\nsandwich.jpg\nVWP\nU2\nC\nT\nU\nBL\nresponse_button_image\n1997.8\nsandwich.jpg\n13.0999999\nAUDIO PLAY EVENT FIRED\n57\n1922.4\n29.65043695\n29.57322764\nsandwich.jpg\nbuilding.jpg\ncandle.jpg\nNA\nNA\nsandal.jpg\n\n\n5\nNA\neyetracking_collection\n153\n1727868219111\n148.40000010\nprediction\n4\n1018.1750413\n433.21330043\n0.5431241067\n0.4268111334\n0\n1\nNA\n0\n0\n0\n0\n0\n0\n0\n0\n11788555\n10.52631579\n24.48650826\n1\ncandle.jpg\nsandal.jpg\nsandwich.jpg\nbuilding.jpg\nTCUU\nsandwich.jpg\nVWP\nU2\nC\nT\nU\nBL\nresponse_button_image\n1997.8\nsandwich.jpg\n13.0999999\nAUDIO PLAY EVENT FIRED\n57\n1922.4\n29.65043695\n29.57322764\nsandwich.jpg\nbuilding.jpg\ncandle.jpg\nNA\nNA\nsandal.jpg\n\n\n6\nNA\neyetracking_collection\n153\n1727868219145\n182.00000000\nprediction\n4\n1040.6113826\n514.57934044\n0.5597067684\n0.5069747196\n0\n1\nNA\n0\n0\n0\n0\n0\n0\n0\n0\n11788555\n10.52631579\n24.48650826\n1\ncandle.jpg\nsandal.jpg\nsandwich.jpg\nbuilding.jpg\nTCUU\nsandwich.jpg\nVWP\nU2\nC\nT\nU\nBL\nresponse_button_image\n1997.8\nsandwich.jpg\n13.0999999\nAUDIO PLAY EVENT FIRED\n57\n1922.4\n29.65043695\n29.57322764\nsandwich.jpg\nbuilding.jpg\ncandle.jpg\nNA\nNA\nsandal.jpg\n\n\n7\nNA\neyetracking_collection\n153\n1727868219177\n214.59999990\nprediction\n4\n1022.8150845\n634.36924699\n0.5465535547\n0.6249943320\n0\n1\nNA\n0\n0\n0\n0\n0\n0\n0\n0\n11788555\n10.52631579\n24.48650826\n1\ncandle.jpg\nsandal.jpg\nsandwich.jpg\nbuilding.jpg\nTCUU\nsandwich.jpg\nVWP\nU2\nC\nT\nU\nBL\nresponse_button_image\n1997.8\nsandwich.jpg\n13.0999999\nAUDIO PLAY EVENT FIRED\n57\n1922.4\n29.65043695\n29.57322764\nsandwich.jpg\nbuilding.jpg\ncandle.jpg\nNA\nNA\nsandal.jpg\n\n\n\n\n\n\nIn our study, we need to track not only the condition of each image shown (such as Target, Cohort, Rhyme, or Unrelated) but also where each image is located on the screen during each trial as they are randomized on each trial. To do this, we use a function named find_location. This function is designed to determine the location of a specific image on the screen by comparing the image with the list of possible locations.\nThe function find_location first checks if the image is NA (missing). If the image is NA, the function returns NA, meaning that there’s no location to find for this image. If the image is not NA, the function creates a vector loc_names that lists the names of the possible locations. It then attempts to match the given image with the locations. If a match is found, it returns the name of the location (e.g., TL, TR, BL, or BR) where the image is located. If there is no match, the function returns NA.\n\nResultInteractive\n\n\n# Apply the function to each of the targ, cohort, rhyme, and unrelated columns\ndat_colnames &lt;- dat %&gt;%\n  rowwise() %&gt;%\n  mutate(\n    targ_loc = find_location(c(TL = TL, TR = TR, BL = BL, BR = BR), Target),\n    cohort_loc = find_location(c(TL = TL, TR = TR, BL = BL, BR = BR), Cohort),\n    rhyme_loc = find_location(c(TL = TL, TR = TR, BL = BL, BR = BR), Rhyme),\n    unrelated_loc = find_location(c(TL = TL, TR = TR, BL = BL, BR = BR), Unrelated),\n    unrelated2_loc = find_location(c(TL = TL, TR = TR, BL = BL, BR = BR), Unrelated2),\n    unrelated3_loc = find_location(c(TL = TL, TR = TR, BL = BL, BR = BR), Unrelated3)\n  ) %&gt;%\n  ungroup()\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nHere is where we are going to use our coordinate information from above. We use the assign_aoi that is adaopted from the gazeR package (Geller et al., 2020) to loop through our object dat_colnames and assign locations (i.e., TR, TL, BL, BR) to our normalized x and y coordinates. This function will label non-looks and off screen coordinates with NA. To make it easier to read we change the numerals assigned by the function to actual screen locations.\n\nResultInteractive\n\n\nassign &lt;- assign_aoi(dat_colnames,X=\"x_pred_normalised\", Y=\"y_pred_normalised\",aoi_loc = aoi_loc)\n\n\nAOI &lt;- assign %&gt;%\n\n  mutate(loc1 = case_when(\n\n    AOI==1 ~ \"TL\", \n\n    AOI==2 ~ \"TR\", \n\n    AOI==3 ~ \"BL\", \n\n    AOI==4 ~ \"BR\"\n\n  ))\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nX\nx0\nfilename\ntrial\ntime_stamp\ntime\ntype\nscreen_index\nx_pred\ny_pred\nx_pred_normalised\ny_pred_normalised\nconvergence\nface_conf\nzone_name\nzone_x\nzone_y\nzone_width\nzone_height\nzone_x_normalised\nzone_y_normalised\nzone_width_normalised\nzone_height_normalised\nsubject\ntrial_missing_percentage\nsubject_missing_percentage\nacc\nTL\nTR\nBL\nBR\ntrialtype\ntargetword\nscreen_name\ntlcode\ntrcode\nblcode\nbrcode\ntarg_loc\nzone_type\nRT\nresponse.x\nRT_audio\nresponse.y\nn_times\nmax_time\nSR_trial\nSR_subject\nTarget\nUnrelated\nUnrelated2\nUnrelated3\nRhyme\nCohort\ncohort_loc\nrhyme_loc\nunrelated_loc\nunrelated2_loc\nunrelated3_loc\nAOI\nloc1\n\n\n\n\n2\nNA\neyetracking_collection\n153\n1727868218999\n34.00000000\nprediction\n4\n958.2899489\n78.26706763\n0.4988631366\n0.0771104115\n0\n1\nNA\n0\n0\n0\n0\n0\n0\n0\n0\n11788555\n10.52631579\n24.48650826\n1\ncandle.jpg\nsandal.jpg\nsandwich.jpg\nbuilding.jpg\nTCUU\nsandwich.jpg\nVWP\nU2\nC\nT\nU\nBL\nresponse_button_image\n1997.8\nsandwich.jpg\n13.0999999\nAUDIO PLAY EVENT FIRED\n57\n1922.4\n29.65043695\n29.57322764\nsandwich.jpg\nbuilding.jpg\ncandle.jpg\nNA\nNA\nsandal.jpg\nTR\nNA\nBR\nTL\nNA\n3\nBL\n\n\n3\nNA\neyetracking_collection\n153\n1727868219039\n73.30000019\nprediction\n4\n1036.1006719\n247.37493626\n0.5563729098\n0.2437191490\n0\n1\nNA\n0\n0\n0\n0\n0\n0\n0\n0\n11788555\n10.52631579\n24.48650826\n1\ncandle.jpg\nsandal.jpg\nsandwich.jpg\nbuilding.jpg\nTCUU\nsandwich.jpg\nVWP\nU2\nC\nT\nU\nBL\nresponse_button_image\n1997.8\nsandwich.jpg\n13.0999999\nAUDIO PLAY EVENT FIRED\n57\n1922.4\n29.65043695\n29.57322764\nsandwich.jpg\nbuilding.jpg\ncandle.jpg\nNA\nNA\nsandal.jpg\nTR\nNA\nBR\nTL\nNA\n4\nBR\n\n\n4\nNA\neyetracking_collection\n153\n1727868219076\n113.09999990\nprediction\n4\n1048.4626414\n383.69717600\n0.5655096204\n0.3780267744\n0\n1\nNA\n0\n0\n0\n0\n0\n0\n0\n0\n11788555\n10.52631579\n24.48650826\n1\ncandle.jpg\nsandal.jpg\nsandwich.jpg\nbuilding.jpg\nTCUU\nsandwich.jpg\nVWP\nU2\nC\nT\nU\nBL\nresponse_button_image\n1997.8\nsandwich.jpg\n13.0999999\nAUDIO PLAY EVENT FIRED\n57\n1922.4\n29.65043695\n29.57322764\nsandwich.jpg\nbuilding.jpg\ncandle.jpg\nNA\nNA\nsandal.jpg\nTR\nNA\nBR\nTL\nNA\n4\nBR\n\n\n5\nNA\neyetracking_collection\n153\n1727868219111\n148.40000010\nprediction\n4\n1018.1750413\n433.21330043\n0.5431241067\n0.4268111334\n0\n1\nNA\n0\n0\n0\n0\n0\n0\n0\n0\n11788555\n10.52631579\n24.48650826\n1\ncandle.jpg\nsandal.jpg\nsandwich.jpg\nbuilding.jpg\nTCUU\nsandwich.jpg\nVWP\nU2\nC\nT\nU\nBL\nresponse_button_image\n1997.8\nsandwich.jpg\n13.0999999\nAUDIO PLAY EVENT FIRED\n57\n1922.4\n29.65043695\n29.57322764\nsandwich.jpg\nbuilding.jpg\ncandle.jpg\nNA\nNA\nsandal.jpg\nTR\nNA\nBR\nTL\nNA\n4\nBR\n\n\n6\nNA\neyetracking_collection\n153\n1727868219145\n182.00000000\nprediction\n4\n1040.6113826\n514.57934044\n0.5597067684\n0.5069747196\n0\n1\nNA\n0\n0\n0\n0\n0\n0\n0\n0\n11788555\n10.52631579\n24.48650826\n1\ncandle.jpg\nsandal.jpg\nsandwich.jpg\nbuilding.jpg\nTCUU\nsandwich.jpg\nVWP\nU2\nC\nT\nU\nBL\nresponse_button_image\n1997.8\nsandwich.jpg\n13.0999999\nAUDIO PLAY EVENT FIRED\n57\n1922.4\n29.65043695\n29.57322764\nsandwich.jpg\nbuilding.jpg\ncandle.jpg\nNA\nNA\nsandal.jpg\nTR\nNA\nBR\nTL\nNA\n2\nTR\n\n\n7\nNA\neyetracking_collection\n153\n1727868219177\n214.59999990\nprediction\n4\n1022.8150845\n634.36924699\n0.5465535547\n0.6249943320\n0\n1\nNA\n0\n0\n0\n0\n0\n0\n0\n0\n11788555\n10.52631579\n24.48650826\n1\ncandle.jpg\nsandal.jpg\nsandwich.jpg\nbuilding.jpg\nTCUU\nsandwich.jpg\nVWP\nU2\nC\nT\nU\nBL\nresponse_button_image\n1997.8\nsandwich.jpg\n13.0999999\nAUDIO PLAY EVENT FIRED\n57\n1922.4\n29.65043695\n29.57322764\nsandwich.jpg\nbuilding.jpg\ncandle.jpg\nNA\nNA\nsandal.jpg\nTR\nNA\nBR\nTL\nNA\n2\nTR\n\n\n\n\n\n\nIn the AOI object we have our condition variables as columns. For this example, the fixation locations need to be “gathered” from separate columns into a single column and “NA” values need to be re-coded as non-fixations (0). We logically evaluate these below so we know which item was fixated each sample and what was not.\n\nResultInteractive\n\n\nAOI$target &lt;- ifelse(AOI$loc1==AOI$targ_loc, 1, 0) # if in coordinates 1, if not 0. \n\nAOI$unrelated &lt;- ifelse(AOI$loc1 == AOI$unrelated_loc, 1, 0)# if in coordinates 1, if not 0. \n\nAOI$unrelated2 &lt;- ifelse(AOI$loc1 == AOI$unrelated2_loc, 1, 0)# if in coordinates 1, if not 0. \n\nAOI$unrelated3 &lt;- ifelse(AOI$loc1 == AOI$unrelated3_loc, 1, 0)# if in coordinates 1, if not 0. \n\nAOI$rhyme &lt;- ifelse(AOI$loc1 == AOI$rhyme_loc, 1, 0)# if in coordinates 1, if not 0. \n\n\nAOI$cohort &lt;- ifelse(AOI$loc1 == AOI$cohort_loc, 1, 0)# if in coordinates 1, if not 0. \n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nX\nx0\nfilename\ntrial\ntime_stamp\ntime\ntype\nscreen_index\nx_pred\ny_pred\nx_pred_normalised\ny_pred_normalised\nconvergence\nface_conf\nzone_name\nzone_x\nzone_y\nzone_width\nzone_height\nzone_x_normalised\nzone_y_normalised\nzone_width_normalised\nzone_height_normalised\nsubject\ntrial_missing_percentage\nsubject_missing_percentage\nacc\nTL\nTR\nBL\nBR\ntrialtype\ntargetword\nscreen_name\ntlcode\ntrcode\nblcode\nbrcode\ntarg_loc\nzone_type\nRT\nresponse.x\nRT_audio\nresponse.y\nn_times\nmax_time\nSR_trial\nSR_subject\nTarget\nUnrelated\nUnrelated2\nUnrelated3\nRhyme\nCohort\ncohort_loc\nrhyme_loc\nunrelated_loc\nunrelated2_loc\nunrelated3_loc\nAOI\nloc1\ntarget\nunrelated\nunrelated2\nunrelated3\nrhyme\ncohort\n\n\n\n\n2\nNA\neyetracking_collection\n153\n1727868218999\n34.00000000\nprediction\n4\n958.2899489\n78.26706763\n0.4988631366\n0.0771104115\n0\n1\nNA\n0\n0\n0\n0\n0\n0\n0\n0\n11788555\n10.52631579\n24.48650826\n1\ncandle.jpg\nsandal.jpg\nsandwich.jpg\nbuilding.jpg\nTCUU\nsandwich.jpg\nVWP\nU2\nC\nT\nU\nBL\nresponse_button_image\n1997.8\nsandwich.jpg\n13.0999999\nAUDIO PLAY EVENT FIRED\n57\n1922.4\n29.65043695\n29.57322764\nsandwich.jpg\nbuilding.jpg\ncandle.jpg\nNA\nNA\nsandal.jpg\nTR\nNA\nBR\nTL\nNA\n3\nBL\n1\n0\n0\nNA\nNA\n0\n\n\n3\nNA\neyetracking_collection\n153\n1727868219039\n73.30000019\nprediction\n4\n1036.1006719\n247.37493626\n0.5563729098\n0.2437191490\n0\n1\nNA\n0\n0\n0\n0\n0\n0\n0\n0\n11788555\n10.52631579\n24.48650826\n1\ncandle.jpg\nsandal.jpg\nsandwich.jpg\nbuilding.jpg\nTCUU\nsandwich.jpg\nVWP\nU2\nC\nT\nU\nBL\nresponse_button_image\n1997.8\nsandwich.jpg\n13.0999999\nAUDIO PLAY EVENT FIRED\n57\n1922.4\n29.65043695\n29.57322764\nsandwich.jpg\nbuilding.jpg\ncandle.jpg\nNA\nNA\nsandal.jpg\nTR\nNA\nBR\nTL\nNA\n4\nBR\n0\n1\n0\nNA\nNA\n0\n\n\n4\nNA\neyetracking_collection\n153\n1727868219076\n113.09999990\nprediction\n4\n1048.4626414\n383.69717600\n0.5655096204\n0.3780267744\n0\n1\nNA\n0\n0\n0\n0\n0\n0\n0\n0\n11788555\n10.52631579\n24.48650826\n1\ncandle.jpg\nsandal.jpg\nsandwich.jpg\nbuilding.jpg\nTCUU\nsandwich.jpg\nVWP\nU2\nC\nT\nU\nBL\nresponse_button_image\n1997.8\nsandwich.jpg\n13.0999999\nAUDIO PLAY EVENT FIRED\n57\n1922.4\n29.65043695\n29.57322764\nsandwich.jpg\nbuilding.jpg\ncandle.jpg\nNA\nNA\nsandal.jpg\nTR\nNA\nBR\nTL\nNA\n4\nBR\n0\n1\n0\nNA\nNA\n0\n\n\n5\nNA\neyetracking_collection\n153\n1727868219111\n148.40000010\nprediction\n4\n1018.1750413\n433.21330043\n0.5431241067\n0.4268111334\n0\n1\nNA\n0\n0\n0\n0\n0\n0\n0\n0\n11788555\n10.52631579\n24.48650826\n1\ncandle.jpg\nsandal.jpg\nsandwich.jpg\nbuilding.jpg\nTCUU\nsandwich.jpg\nVWP\nU2\nC\nT\nU\nBL\nresponse_button_image\n1997.8\nsandwich.jpg\n13.0999999\nAUDIO PLAY EVENT FIRED\n57\n1922.4\n29.65043695\n29.57322764\nsandwich.jpg\nbuilding.jpg\ncandle.jpg\nNA\nNA\nsandal.jpg\nTR\nNA\nBR\nTL\nNA\n4\nBR\n0\n1\n0\nNA\nNA\n0\n\n\n6\nNA\neyetracking_collection\n153\n1727868219145\n182.00000000\nprediction\n4\n1040.6113826\n514.57934044\n0.5597067684\n0.5069747196\n0\n1\nNA\n0\n0\n0\n0\n0\n0\n0\n0\n11788555\n10.52631579\n24.48650826\n1\ncandle.jpg\nsandal.jpg\nsandwich.jpg\nbuilding.jpg\nTCUU\nsandwich.jpg\nVWP\nU2\nC\nT\nU\nBL\nresponse_button_image\n1997.8\nsandwich.jpg\n13.0999999\nAUDIO PLAY EVENT FIRED\n57\n1922.4\n29.65043695\n29.57322764\nsandwich.jpg\nbuilding.jpg\ncandle.jpg\nNA\nNA\nsandal.jpg\nTR\nNA\nBR\nTL\nNA\n2\nTR\n0\n0\n0\nNA\nNA\n1\n\n\n7\nNA\neyetracking_collection\n153\n1727868219177\n214.59999990\nprediction\n4\n1022.8150845\n634.36924699\n0.5465535547\n0.6249943320\n0\n1\nNA\n0\n0\n0\n0\n0\n0\n0\n0\n11788555\n10.52631579\n24.48650826\n1\ncandle.jpg\nsandal.jpg\nsandwich.jpg\nbuilding.jpg\nTCUU\nsandwich.jpg\nVWP\nU2\nC\nT\nU\nBL\nresponse_button_image\n1997.8\nsandwich.jpg\n13.0999999\nAUDIO PLAY EVENT FIRED\n57\n1922.4\n29.65043695\n29.57322764\nsandwich.jpg\nbuilding.jpg\ncandle.jpg\nNA\nNA\nsandal.jpg\nTR\nNA\nBR\nTL\nNA\n2\nTR\n0\n0\n0\nNA\nNA\n1\n\n\n\n\n\n\nNow we pivot so instead of each condition being an individual column it is one column. This helps with visualization. We pivot_longer or make longer the target, unrelated, unrealted2, unrelated3, rhyme, and cohort columns. We put them into a column called condition and place the values of 0 and 1 into a column called look.\n\nResultInteractive\n\n\ndat_long_aoi_me &lt;- AOI  %&gt;%\n  select(subject, trial, trialtype, target, cohort, unrelated, unrelated2, unrelated3,  rhyme, time, x_pred_normalised, y_pred_normalised, RT_audio) %&gt;%\n    pivot_longer(\n        cols = c(target, unrelated, unrelated2, unrelated3, rhyme, cohort),\n        names_to = \"condition\",\n        values_to = \"Looks\"\n    )\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\n\n\n\nNon-looks\n\n\n\nThere are two ways we can handle missingness here. We can either re-code the NA values as non-looks, or we can exclude looks that occurred outside an AOI.\nHere we are going to treat them as non-looks (0)",
    "crumbs": [
      "Articles",
      "Introduction to webgazeR"
    ]
  },
  {
    "objectID": "vignettes/webgazeR_vignette.html#downsampling",
    "href": "vignettes/webgazeR_vignette.html#downsampling",
    "title": "Introduction to webgazeR",
    "section": "Downsampling",
    "text": "Downsampling\nWe also downsampled our data into 100 ms bins using the downsample_gaze function from the webgazeR package. In this process, we read in our gaze_sub object, specified the bin.length argument as 200, and set the time variable as time. We also indicated the variables to aggregate on, such as condition and timebins. The time_bin variable is created by the function and represents the bins we are aggregating across. There is no clear consensus on binning, so we cannot provide a concrete rule of thumb here.\n\nResultInteractive\n\n\ngaze_sub &lt;- webgazeR::downsample_gaze(gaze_sub, bin.length=100, timevar=\"time\", aggvars=c(\"condition\", \"time_bin\"))\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.",
    "crumbs": [
      "Articles",
      "Introduction to webgazeR"
    ]
  },
  {
    "objectID": "vignettes/webgazeR_vignette.html#upsampling",
    "href": "vignettes/webgazeR_vignette.html#upsampling",
    "title": "Introduction to webgazeR",
    "section": "Upsampling",
    "text": "Upsampling\nYou might also want to upsample your data. If this is the case you can use the upsample_gaze function which will upsample the data to 1000Hz (or whatever sampling rate you want). After you upsample your data you can use smooth_gaze to apply a moving average of the gaze samples skipping over NA values. Finally, you can use interpolate_gaze to perform linear interpolation.\n\nResultInteractive\n\n\nAOI_upsample &lt;- AOI %&gt;%\n  group_by(subject, trial) %&gt;%\n  upsample_gaze(\n    gaze_cols = c(\"x_pred_normalised\", \"y_pred_normalised\"),\n    upsample_pupil = FALSE, \n    target_hz = 250)\n\n\nAOI_upsample %&gt;%\n  head() %&gt;%\n  select(subject, trial, time, x_pred_normalised, y_pred_normalised) %&gt;%\n  kable()\n\n\n\n\nsubject\ntrial\ntime\nx_pred_normalised\ny_pred_normalised\n\n\n\n\n11788555\n7\n0\n0.2067704716\n0.4331503515\n\n\n11788555\n7\n4\nNA\nNA\n\n\n11788555\n7\n8\nNA\nNA\n\n\n11788555\n7\n12\nNA\nNA\n\n\n11788555\n7\n16\nNA\nNA\n\n\n11788555\n7\n20\nNA\nNA\n\n\n\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\nSmoothing and Interpolation\nWe can also smooth the data\n\nResultInteractive\n\n\nAOI_smooth=smooth_gaze(AOI_upsample, n = 5, x_col = \"x_pred_normalised\", y_col = \"y_pred_normalised\",\n                        trial_col = \"trial\", subject_col = \"subject\")\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nand then interpolate it\n\nResultInteractive\n\n\ndeduplicated_data &lt;- AOI_smooth %&gt;%\n  group_by(subject, trial, time) %&gt;%\n  slice(1) %&gt;%\n  ungroup()\n\n\naoi_interp &lt;- interpolate_gaze(deduplicated_data,x_col = \"x_pred_normalised\", y_col = \"y_pred_normalised\",\n                        trial_col = \"trial\", subject_col = \"subject\", time_col=\"time\" )\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.",
    "crumbs": [
      "Articles",
      "Introduction to webgazeR"
    ]
  },
  {
    "objectID": "vignettes/webgazeR_vignette.html#plotting",
    "href": "vignettes/webgazeR_vignette.html#plotting",
    "title": "Introduction to webgazeR",
    "section": "Plotting",
    "text": "Plotting\nTo simplify plotting your time-course data, we have created the plot_IA_proportions function. This function takes several arguments. The ia_column argument specifies the column containing your Interest Area (IA) labels. The time_column argument requires the name of your time bin column, and the proportion_column argument specifies the column containing fixation or look proportions. Additional arguments allow you to specify custom names for each IA in the ia_column, enabling you to label them as desired.\n\nResultInteractive\n\n\nplot_IA_proportions(gaze_sub, \n                     ia_column = \"condition\", \n                     time_column = \"time_bin\", \n                     proportion_column = \"Fix\", \n                   ia_mapping = list(target = \"Target\", cohort = \"Cohort\", rhyme = \"Rhyme\", unrelated = \"Unrelated\"), use_color=TRUE)\n\n\n\n\n\n\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\nResultInteractive\n\n\nplot_IA_proportions(gaze_sub, \n                     ia_column = \"condition\", \n                     time_column = \"time_bin\", \n                     proportion_column = \"Fix\", \n                   ia_mapping = list(target = \"Target\", cohort = \"Cohort\", rhyme = \"Rhyme\", unrelated = \"Unrelated\"), use_color=FALSE)\n\n\n\n\n\n\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.",
    "crumbs": [
      "Articles",
      "Introduction to webgazeR"
    ]
  },
  {
    "objectID": "vignettes/webgazeR_vignette.html#gorilla-provided-coordinates",
    "href": "vignettes/webgazeR_vignette.html#gorilla-provided-coordinates",
    "title": "Introduction to webgazeR",
    "section": "Gorilla provided coordinates",
    "text": "Gorilla provided coordinates\nIf you open the each individual .xlsx file provided by gorilla you will see that it provides standardized coordinates for each location: TL, TR, BL, BR. Let’s use these coordinates instead of setting some general coordinates.\nWe will use the function extract_aois to get the coordinates for each quadrant on screen. You can use the zone_names argument to get the zones you want to use.\n\nResultInteractive\n\n\naois &lt;- extract_aois(vwp_paths_filtered, zone_names =  c(\"TL\", \"BR\", \"TR\", \"BL\"))\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nBelow is the table the extract_aois function will return.\n\nResultInteractive\n\n\n# Define the data\naois &lt;- data.frame(\n  loc = c(\"BL\", \"TL\", \"TR\", \"BR\"),\n  x_normalized = c(0.03, 0.02, 0.73, 0.73),\n  y_normalized = c(0.04, 0.74, 0.75, 0.06),\n  width_normalized = c(0.26, 0.26, 0.24, 0.23),\n  height_normalized = c(0.25, 0.25, 0.24, 0.25),\n  xmin = c(0.03, 0.02, 0.73, 0.73),\n  ymin = c(0.04, 0.74, 0.75, 0.06),\n  xmax = c(0.29, 0.28, 0.97, 0.96),\n  ymax = c(0.29, 0.99, 0.99, 0.31)\n)\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\nResultInteractive\n\n\n\naois %&gt;%\n  kable()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nloc\nx_normalized\ny_normalized\nwidth_normalized\nheight_normalized\nxmin\nymin\nxmax\nymax\n\n\n\n\nBL\n0.03\n0.04\n0.26\n0.25\n0.03\n0.04\n0.29\n0.29\n\n\nTL\n0.02\n0.74\n0.26\n0.25\n0.02\n0.74\n0.28\n0.99\n\n\nTR\n0.73\n0.75\n0.24\n0.24\n0.73\n0.75\n0.97\n0.99\n\n\nBR\n0.73\n0.06\n0.23\n0.25\n0.73\n0.06\n0.96\n0.31\n\n\n\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nWe see the AOIs are a bit smaller now with the gorilla provided coordinates.\n\n\n\n\n\n\n\n\n\n\n\nWe can follow the same steps from above to analyze our data, making sure we input the write coordinates into the aoi_loc argument.\n\nResultInteractive\n\n\nassign &lt;- assign_aoi(dat_colnames,X=\"x_pred_normalised\", Y=\"y_pred_normalised\",aoi_loc = aois)\n\n\nAOI &lt;- assign %&gt;%\n\n  mutate(loc1 = case_when(\n\n    AOI==1 ~ \"BL\", \n\n    AOI==2 ~ \"TL\", \n\n    AOI==3 ~ \"TR\", \n\n    AOI==4 ~ \"BR\"\n\n  ))\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\nResultInteractive\n\n\nAOI$target &lt;- ifelse(AOI$loc1==AOI$targ_loc, 1, 0) # if in coordinates 1, if not 0. \n\nAOI$unrelated &lt;- ifelse(AOI$loc1 == AOI$unrelated_loc, 1, 0)# if in coordinates 1, if not 0. \n\nAOI$unrelated2 &lt;- ifelse(AOI$loc1 == AOI$unrelated2_loc, 1, 0)# if in coordinates 1, if not 0. \n\nAOI$unrelated3 &lt;- ifelse(AOI$loc1 == AOI$unrelated3_loc, 1, 0)# if in coordinates 1, if not 0. \n\nAOI$rhyme &lt;- ifelse(AOI$loc1 == AOI$rhyme_loc, 1, 0)# if in coordinates 1, if not 0. \n\n\nAOI$cohort &lt;- ifelse(AOI$loc1 == AOI$cohort_loc, 1, 0)# if in coordinates 1, if not 0. \n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nNow we pivot so instead of each condition being an individual column it is one column.\n\ndat_long_aoi_me &lt;- AOI  %&gt;%\n  select(subject, trial, trialtype, target, cohort, unrelated, unrelated2, unrelated3,  rhyme, time, x_pred_normalised, y_pred_normalised, RT_audio) %&gt;%\n    pivot_longer(\n        cols = c(target, unrelated, unrelated2, unrelated3, rhyme, cohort),\n        names_to = \"condition\",\n        values_to = \"Looks\"\n    )\n\n\nResultInteractive\n\n\ndat_long_aoi_me_TCRU &lt;- dat_long_aoi_me %&gt;%\n  filter(trialtype==\"TCRU\") %&gt;%\n  na.omit()\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\nResultInteractive\n\n\ngaze_sub &lt;-dat_long_aoi_me_TCRU %&gt;% \ngroup_by(subject, trial) %&gt;%\n  mutate(time = (time-RT_audio)-300) %&gt;% # subtract audio rt onset for each\n filter(time &gt;= 0, time &lt; 2000) %&gt;% \n   dplyr::filter(x_pred_normalised &gt; 0,\n                x_pred_normalised &lt; 1,\n                y_pred_normalised &gt; 0,\n                y_pred_normalised &lt; 1)\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\nResultInteractive\n\n\ngaze_sub &lt;- downsample_gaze(gaze_sub, bin.length=100, timevar=\"time\", aggvars=c(\"condition\", \"time_bin\"))\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\nPlotting\n\nResultInteractive\n\n\ngor &lt;- plot_IA_proportions(gaze_sub, \n                     ia_column = \"condition\", \n                     time_column = \"time_bin\", \n                     proportion_column = \"Fix\", \n                   ia_mapping = list(target = \"Target\", cohort = \"Cohort\", rhyme = \"Rhyme\", unrelated = \"Unrelated\"))\n\ngor\n\n\n\n\n\n\n\nFigure 1\n\n\n\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nWe see the effect is a lot larger when using the gorilla provided coordinates, but a bit noiser.",
    "crumbs": [
      "Articles",
      "Introduction to webgazeR"
    ]
  },
  {
    "objectID": "man/smooth_gaze.html",
    "href": "man/smooth_gaze.html",
    "title": "webgazeR v0.7.2",
    "section": "",
    "text": "Apply a moving average smoothing function to gaze data (X and Y). This is generally recommended after up-sampling the data.\n\nDescription\nApply a moving average smoothing function to gaze data (X and Y). This is generally recommended after up-sampling the data.\n\n\nUsage\nsmooth_gaze(\n  x,\n  n = 5,\n  x_col = \"Gaze_X\",\n  y_col = \"Gaze_Y\",\n  trial_col = \"Trial\",\n  subject_col = \"Subject\"\n)\n\n\n\nArguments\n\n\n\nx\n\n\nA data frame containing gaze data.\n\n\n\n\nn\n\n\nThe window size (in samples) for the moving average.\n\n\n\n\nx_col\n\n\nThe name of the X gaze column (as string).\n\n\n\n\ny_col\n\n\nThe name of the Y gaze column (as string).\n\n\n\n\ntrial_col\n\n\nThe name of the trial column used for grouping (default = \"Trial\").\n\n\n\n\nsubject_col\n\n\nThe name of the subject column used for grouping (default = \"Subject\").\n\n\n\n\n\nValue\nA tibble with smoothed gaze X and Y columns (replacing originals).",
    "crumbs": [
      "Reference",
      "smooth_gaze"
    ]
  },
  {
    "objectID": "man/gaze_dispersion.html",
    "href": "man/gaze_dispersion.html",
    "title": "webgazeR v0.7.2",
    "section": "",
    "text": "Calculates centroid anddispersion from gaze data.\n\n\n\ngaze_dispersion(data, x, y, grouping_vars)\n\n\n\n\n\n\n\ndata\n\n\nA data frame or tibble.\n\n\n\n\nx\n\n\nA string: name of the column with X gaze coordinates.\n\n\n\n\ny\n\n\nA string: name of the column with Y gaze coordinates.\n\n\n\n\ngrouping_vars\n\n\nA character vector of column names to group by (e.g., subject, condition, trial).\n\n\n\n\n\n\nA tibble with centroid_x, centroid_y, dispersion, and log_dispersion for each group.",
    "crumbs": [
      "Reference",
      "gaze_dispersion"
    ]
  },
  {
    "objectID": "man/gaze_dispersion.html#compute-gaze-dispersion",
    "href": "man/gaze_dispersion.html#compute-gaze-dispersion",
    "title": "webgazeR v0.7.2",
    "section": "",
    "text": "Calculates centroid anddispersion from gaze data.\n\n\n\ngaze_dispersion(data, x, y, grouping_vars)\n\n\n\n\n\n\n\ndata\n\n\nA data frame or tibble.\n\n\n\n\nx\n\n\nA string: name of the column with X gaze coordinates.\n\n\n\n\ny\n\n\nA string: name of the column with Y gaze coordinates.\n\n\n\n\ngrouping_vars\n\n\nA character vector of column names to group by (e.g., subject, condition, trial).\n\n\n\n\n\n\nA tibble with centroid_x, centroid_y, dispersion, and log_dispersion for each group.",
    "crumbs": [
      "Reference",
      "gaze_dispersion"
    ]
  },
  {
    "objectID": "man/calculate_isc.html",
    "href": "man/calculate_isc.html",
    "title": "webgazeR v0.7.2",
    "section": "",
    "text": "Computes ISC using either the pairwise correlation method or the leave-one-out method. The pairwise method computes a full correlation matrix and averages Fisher-transformed values. The leave-one-out method computes the correlation of each participant’s time series with the mean of all others.\n\n\n\ncalculate_isc(data_matrix, method = \"pairwise\", summary_statistic = \"mean\")\n\n\n\n\n\n\n\ndata_matrix\n\n\nA numeric matrix where rows represent time points and columns represent participants.\n\n\n\n\nmethod\n\n\nA string specifying the ISC computation method. Options are ‘\"pairwise\"’ (default) or ‘\"leave-one-out\"’.\n\n\n\n\nsummary_statistic\n\n\nA string specifying whether to return ‘\"mean\"’, ‘\"median\"’, or ‘\"raw\"’ ISC values per participant.\n\n\n\n\n\n\nA numeric vector of ISC values, one per participant.",
    "crumbs": [
      "Reference",
      "calculate_isc"
    ]
  },
  {
    "objectID": "man/calculate_isc.html#compute-intersubject-correlation-isc",
    "href": "man/calculate_isc.html#compute-intersubject-correlation-isc",
    "title": "webgazeR v0.7.2",
    "section": "",
    "text": "Computes ISC using either the pairwise correlation method or the leave-one-out method. The pairwise method computes a full correlation matrix and averages Fisher-transformed values. The leave-one-out method computes the correlation of each participant’s time series with the mean of all others.\n\n\n\ncalculate_isc(data_matrix, method = \"pairwise\", summary_statistic = \"mean\")\n\n\n\n\n\n\n\ndata_matrix\n\n\nA numeric matrix where rows represent time points and columns represent participants.\n\n\n\n\nmethod\n\n\nA string specifying the ISC computation method. Options are ‘\"pairwise\"’ (default) or ‘\"leave-one-out\"’.\n\n\n\n\nsummary_statistic\n\n\nA string specifying whether to return ‘\"mean\"’, ‘\"median\"’, or ‘\"raw\"’ ISC values per participant.\n\n\n\n\n\n\nA numeric vector of ISC values, one per participant.",
    "crumbs": [
      "Reference",
      "calculate_isc"
    ]
  },
  {
    "objectID": "man/downsample_gaze.html",
    "href": "man/downsample_gaze.html",
    "title": "webgazeR v0.7.2",
    "section": "",
    "text": "This function combines gaze samples into time bins and optionally aggregates the data.\n\n\n\ndownsample_gaze(\n  dataframe,\n  bin.length = 50,\n  timevar = \"time\",\n  aggvars = c(\"subject\", \"condition\", \"target\", \"trial\", \"object\", \"time_bin\")\n)\n\n\n\n\n\n\n\ndataframe\n\n\nDataFrame containing gaze data.\n\n\n\n\nbin.length\n\n\nLength of time bins (in milliseconds).\n\n\n\n\ntimevar\n\n\nColumn name representing time.\n\n\n\n\naggvars\n\n\nVector of variable names to group by for aggregation. Use \"none\" to skip aggregation.\n\n\n\n\n\n\nDataFrame with time bins added and optionally aggregated data.",
    "crumbs": [
      "Reference",
      "downsample_gaze"
    ]
  },
  {
    "objectID": "man/downsample_gaze.html#downsample-gaze-data",
    "href": "man/downsample_gaze.html#downsample-gaze-data",
    "title": "webgazeR v0.7.2",
    "section": "",
    "text": "This function combines gaze samples into time bins and optionally aggregates the data.\n\n\n\ndownsample_gaze(\n  dataframe,\n  bin.length = 50,\n  timevar = \"time\",\n  aggvars = c(\"subject\", \"condition\", \"target\", \"trial\", \"object\", \"time_bin\")\n)\n\n\n\n\n\n\n\ndataframe\n\n\nDataFrame containing gaze data.\n\n\n\n\nbin.length\n\n\nLength of time bins (in milliseconds).\n\n\n\n\ntimevar\n\n\nColumn name representing time.\n\n\n\n\naggvars\n\n\nVector of variable names to group by for aggregation. Use \"none\" to skip aggregation.\n\n\n\n\n\n\nDataFrame with time bins added and optionally aggregated data.",
    "crumbs": [
      "Reference",
      "downsample_gaze"
    ]
  },
  {
    "objectID": "man/interpolate_gaze.html",
    "href": "man/interpolate_gaze.html",
    "title": "webgazeR v0.7.2",
    "section": "",
    "text": "Interpolate missing gaze data (X and Y) within trials, with optional max gap\n\n\n\ninterpolate_gaze(\n  x,\n  x_col = \"Gaze_X\",\n  y_col = \"Gaze_Y\",\n  trial_col = \"Trial\",\n  subject_col = \"Subject\",\n  time_col = \"Time\",\n  max_gap = Inf\n)\n\n\n\n\n\n\n\nx\n\n\nA data frame containing gaze data.\n\n\n\n\nx_col\n\n\nThe name of the X gaze column (as string).\n\n\n\n\ny_col\n\n\nThe name of the Y gaze column (as string).\n\n\n\n\ntrial_col\n\n\nThe name of the trial column (default = \"Trial\").\n\n\n\n\nsubject_col\n\n\nThe name of the subject column (default = \"Subject\").\n\n\n\n\ntime_col\n\n\nThe name of the time column used for sorting (default = \"Time\").\n\n\n\n\nmax_gap\n\n\nMaximum number of consecutive missing samples to interpolate. Gaps larger than this remain NA (default = Inf).\n\n\n\n\n\n\nA tibble with interpolated gaze X and Y columns (replacing originals).",
    "crumbs": [
      "Reference",
      "interpolate_gaze"
    ]
  },
  {
    "objectID": "man/interpolate_gaze.html#interpolate-missing-gaze-data-x-and-y-within-trials-with-optional-max-gap",
    "href": "man/interpolate_gaze.html#interpolate-missing-gaze-data-x-and-y-within-trials-with-optional-max-gap",
    "title": "webgazeR v0.7.2",
    "section": "",
    "text": "Interpolate missing gaze data (X and Y) within trials, with optional max gap\n\n\n\ninterpolate_gaze(\n  x,\n  x_col = \"Gaze_X\",\n  y_col = \"Gaze_Y\",\n  trial_col = \"Trial\",\n  subject_col = \"Subject\",\n  time_col = \"Time\",\n  max_gap = Inf\n)\n\n\n\n\n\n\n\nx\n\n\nA data frame containing gaze data.\n\n\n\n\nx_col\n\n\nThe name of the X gaze column (as string).\n\n\n\n\ny_col\n\n\nThe name of the Y gaze column (as string).\n\n\n\n\ntrial_col\n\n\nThe name of the trial column (default = \"Trial\").\n\n\n\n\nsubject_col\n\n\nThe name of the subject column (default = \"Subject\").\n\n\n\n\ntime_col\n\n\nThe name of the time column used for sorting (default = \"Time\").\n\n\n\n\nmax_gap\n\n\nMaximum number of consecutive missing samples to interpolate. Gaps larger than this remain NA (default = Inf).\n\n\n\n\n\n\nA tibble with interpolated gaze X and Y columns (replacing originals).",
    "crumbs": [
      "Reference",
      "interpolate_gaze"
    ]
  },
  {
    "objectID": "man/upsample_gaze.html",
    "href": "man/upsample_gaze.html",
    "title": "webgazeR v0.7.2",
    "section": "",
    "text": "Increase the sampling frequency to ‘target_hz’ Hz by inserting additional rows. Missing values in gaze and pupil data will be preserved for later interpolation.\n\n\n\nupsample_gaze(\n  x,\n  pupil_cols = c(\"Pupil_Diameter\"),\n  gaze_cols = c(\"x_pred_normalised\", \"y_pred_normalised\"),\n  target_hz = 1000,\n  upsample_pupil = TRUE\n)\n\n\n\n\n\n\n\nx\n\n\nA dataframe containing gaze and pupil data with columns: ‘subject’, ‘trial’, and ‘time’.\n\n\n\n\npupil_cols\n\n\nCharacter vector of pupil diameter column names.\n\n\n\n\ngaze_cols\n\n\nCharacter vector of gaze position column names.\n\n\n\n\ntarget_hz\n\n\nTarget sampling frequency (default is 1000 Hz).\n\n\n\n\nupsample_pupil\n\n\nLogical; if ‘TRUE’, pupil data will also be upsampled.\n\n\n\n\n\n\nA dataframe with up-sampled time points and an ‘up_sampled’ column.",
    "crumbs": [
      "Reference",
      "upsample_gaze"
    ]
  },
  {
    "objectID": "man/upsample_gaze.html#up-sample-gaze-and-pupil-data",
    "href": "man/upsample_gaze.html#up-sample-gaze-and-pupil-data",
    "title": "webgazeR v0.7.2",
    "section": "",
    "text": "Increase the sampling frequency to ‘target_hz’ Hz by inserting additional rows. Missing values in gaze and pupil data will be preserved for later interpolation.\n\n\n\nupsample_gaze(\n  x,\n  pupil_cols = c(\"Pupil_Diameter\"),\n  gaze_cols = c(\"x_pred_normalised\", \"y_pred_normalised\"),\n  target_hz = 1000,\n  upsample_pupil = TRUE\n)\n\n\n\n\n\n\n\nx\n\n\nA dataframe containing gaze and pupil data with columns: ‘subject’, ‘trial’, and ‘time’.\n\n\n\n\npupil_cols\n\n\nCharacter vector of pupil diameter column names.\n\n\n\n\ngaze_cols\n\n\nCharacter vector of gaze position column names.\n\n\n\n\ntarget_hz\n\n\nTarget sampling frequency (default is 1000 Hz).\n\n\n\n\nupsample_pupil\n\n\nLogical; if ‘TRUE’, pupil data will also be upsampled.\n\n\n\n\n\n\nA dataframe with up-sampled time points and an ‘up_sampled’ column.",
    "crumbs": [
      "Reference",
      "upsample_gaze"
    ]
  },
  {
    "objectID": "man/find_location.html",
    "href": "man/find_location.html",
    "title": "webgazeR v0.7.2",
    "section": "",
    "text": "Find Image Location in a Given Set of Locations\n\n\n\nfind_location(locations, image)\n\n\n\n\n\n\n\nlocations\n\n\nA character vector of image names at each location.\n\n\n\n\nimage\n\n\nA character string: the image to locate.#’\n\n\n\n\n\n\nA character string representing the location name or NA if not found.",
    "crumbs": [
      "Reference",
      "find_location"
    ]
  },
  {
    "objectID": "man/find_location.html#find-image-location-in-a-given-set-of-locations",
    "href": "man/find_location.html#find-image-location-in-a-given-set-of-locations",
    "title": "webgazeR v0.7.2",
    "section": "",
    "text": "Find Image Location in a Given Set of Locations\n\n\n\nfind_location(locations, image)\n\n\n\n\n\n\n\nlocations\n\n\nA character vector of image names at each location.\n\n\n\n\nimage\n\n\nA character string: the image to locate.#’\n\n\n\n\n\n\nA character string representing the location name or NA if not found.",
    "crumbs": [
      "Reference",
      "find_location"
    ]
  },
  {
    "objectID": "man/gaze_oob.html",
    "href": "man/gaze_oob.html",
    "title": "webgazeR v0.7.2",
    "section": "",
    "text": "This function calculates the number and percentage of gaze points that fall outside the screen dimensions, and optionally removes only the out-of-bounds gaze points.\n\n\n\ngaze_oob(\n  data,\n  subject_col = \"subject\",\n  trial_col = \"trial\",\n  x_col = \"x\",\n  y_col = \"y\",\n  screen_size = c(1, 1),\n  remove = FALSE\n)\n\n\n\n\n\n\n\ndata\n\n\nA data frame containing gaze data.\n\n\n\n\nsubject_col\n\n\nA string specifying the name of the column that contains the subject identifier. Default is \"subject\".\n\n\n\n\ntrial_col\n\n\nA string specifying the name of the column that contains the trial identifier. Default is \"trial\".\n\n\n\n\nx_col\n\n\nA string specifying the name of the column that contains the X coordinate. Default is \"x\".\n\n\n\n\ny_col\n\n\nA string specifying the name of the column that contains the Y coordinate. Default is \"y\".\n\n\n\n\nscreen_size\n\n\nA numeric vector of length 2 specifying the screen width and height. Default is c(1, 1) assuming normalized coordinates.\n\n\n\n\nremove\n\n\nLogical; if TRUE, removes points outside of screen dimensions. Default is FALSE.\n\n\n\n\n\n\nA list containing:\n\n\nsubject_results\n\n\nSummary of missingness at the subject level.\n\n\ntrial_results\n\n\nSummary of missingness at the trial level.\n\n\ndata_clean\n\n\nDataset with optional removal of out-of-bounds points and missingness annotations.",
    "crumbs": [
      "Reference",
      "gaze_oob"
    ]
  },
  {
    "objectID": "man/gaze_oob.html#calculate-out-of-bounds-proportion-by-subject-and-trial",
    "href": "man/gaze_oob.html#calculate-out-of-bounds-proportion-by-subject-and-trial",
    "title": "webgazeR v0.7.2",
    "section": "",
    "text": "This function calculates the number and percentage of gaze points that fall outside the screen dimensions, and optionally removes only the out-of-bounds gaze points.\n\n\n\ngaze_oob(\n  data,\n  subject_col = \"subject\",\n  trial_col = \"trial\",\n  x_col = \"x\",\n  y_col = \"y\",\n  screen_size = c(1, 1),\n  remove = FALSE\n)\n\n\n\n\n\n\n\ndata\n\n\nA data frame containing gaze data.\n\n\n\n\nsubject_col\n\n\nA string specifying the name of the column that contains the subject identifier. Default is \"subject\".\n\n\n\n\ntrial_col\n\n\nA string specifying the name of the column that contains the trial identifier. Default is \"trial\".\n\n\n\n\nx_col\n\n\nA string specifying the name of the column that contains the X coordinate. Default is \"x\".\n\n\n\n\ny_col\n\n\nA string specifying the name of the column that contains the Y coordinate. Default is \"y\".\n\n\n\n\nscreen_size\n\n\nA numeric vector of length 2 specifying the screen width and height. Default is c(1, 1) assuming normalized coordinates.\n\n\n\n\nremove\n\n\nLogical; if TRUE, removes points outside of screen dimensions. Default is FALSE.\n\n\n\n\n\n\nA list containing:\n\n\nsubject_results\n\n\nSummary of missingness at the subject level.\n\n\ntrial_results\n\n\nSummary of missingness at the trial level.\n\n\ndata_clean\n\n\nDataset with optional removal of out-of-bounds points and missingness annotations.",
    "crumbs": [
      "Reference",
      "gaze_oob"
    ]
  },
  {
    "objectID": "man/merge_webcam_files.html",
    "href": "man/merge_webcam_files.html",
    "title": "webgazeR v0.7.2",
    "section": "",
    "text": "This function reads, merges, and processes webcam eye-tracking files. It standardizes column names (subject, trial, time, x, y) for universal use. Supports .csv, .tsv, and .xlsx formats.\n\n\n\nmerge_webcam_files(\n  file_paths,\n  screen_index = NULL,\n  kind = \"gorilla\",\n  col_map = list(subject = \"participant_id\", trial = \"spreadsheet_row\", time =\n    \"time_elapsed\", x = \"x\", y = \"y\")\n)\n\n\n\n\n\n\n\nfile_paths\n\n\nA list of file paths to webcam files.\n\n\n\n\nscreen_index\n\n\nOptional. If provided, filters data by one or more screen indices (for Gorilla).\n\n\n\n\nkind\n\n\nThe data collection platform. Options: \"gorilla\" (default), \"labvanced\".\n\n\n\n\ncol_map\n\n\nA named list mapping your current columns to WebGazer names: ‘subject’, ‘trial’, ‘time’, ‘x’, ‘y’.\n\n\n\n\n\n\nA dataframe with standardized columns depending on the platform.",
    "crumbs": [
      "Reference",
      "merge_webcam_files"
    ]
  },
  {
    "objectID": "man/merge_webcam_files.html#merge-and-process-webcam-eye-tracking-files",
    "href": "man/merge_webcam_files.html#merge-and-process-webcam-eye-tracking-files",
    "title": "webgazeR v0.7.2",
    "section": "",
    "text": "This function reads, merges, and processes webcam eye-tracking files. It standardizes column names (subject, trial, time, x, y) for universal use. Supports .csv, .tsv, and .xlsx formats.\n\n\n\nmerge_webcam_files(\n  file_paths,\n  screen_index = NULL,\n  kind = \"gorilla\",\n  col_map = list(subject = \"participant_id\", trial = \"spreadsheet_row\", time =\n    \"time_elapsed\", x = \"x\", y = \"y\")\n)\n\n\n\n\n\n\n\nfile_paths\n\n\nA list of file paths to webcam files.\n\n\n\n\nscreen_index\n\n\nOptional. If provided, filters data by one or more screen indices (for Gorilla).\n\n\n\n\nkind\n\n\nThe data collection platform. Options: \"gorilla\" (default), \"labvanced\".\n\n\n\n\ncol_map\n\n\nA named list mapping your current columns to WebGazer names: ‘subject’, ‘trial’, ‘time’, ‘x’, ‘y’.\n\n\n\n\n\n\nA dataframe with standardized columns depending on the platform.",
    "crumbs": [
      "Reference",
      "merge_webcam_files"
    ]
  },
  {
    "objectID": "man/analyze_sampling_rate.html",
    "href": "man/analyze_sampling_rate.html",
    "title": "webgazeR v0.7.2",
    "section": "",
    "text": "Computes sampling rate for each trial (subject × trial) and summarizes at the subject level. Uses distinct timepoints to avoid duplicate time values. Plots histogram of subject-level sampling rates.\n\n\n\nanalyze_sampling_rate(eye_data, summary_stat = \"median\")\n\n\n\n\n\n\n\neye_data\n\n\nA dataframe with subject, trial, time columns.\n\n\n\n\nsummary_stat\n\n\nEither \"median\" (default) or \"mean\".\n\n\n\n\n\n\nA tibble with subject, trial, SR_trial, SR_subject",
    "crumbs": [
      "Reference",
      "analyze_sampling_rate"
    ]
  },
  {
    "objectID": "man/analyze_sampling_rate.html#analyze-sampling-rates-trial-and-subject-levels-with-histogram",
    "href": "man/analyze_sampling_rate.html#analyze-sampling-rates-trial-and-subject-levels-with-histogram",
    "title": "webgazeR v0.7.2",
    "section": "",
    "text": "Computes sampling rate for each trial (subject × trial) and summarizes at the subject level. Uses distinct timepoints to avoid duplicate time values. Plots histogram of subject-level sampling rates.\n\n\n\nanalyze_sampling_rate(eye_data, summary_stat = \"median\")\n\n\n\n\n\n\n\neye_data\n\n\nA dataframe with subject, trial, time columns.\n\n\n\n\nsummary_stat\n\n\nEither \"median\" (default) or \"mean\".\n\n\n\n\n\n\nA tibble with subject, trial, SR_trial, SR_subject",
    "crumbs": [
      "Reference",
      "analyze_sampling_rate"
    ]
  },
  {
    "objectID": "man/make_webgazer.html",
    "href": "man/make_webgazer.html",
    "title": "webgazeR v0.7.2",
    "section": "",
    "text": "This function takes a dataframe and renames columns to match WebGazer conventions: subject, trial, time, x, y. All other columns are preserved. Standardize a Dataframe to WebGazer Conventions\n\n\n\nmake_webgazer(\n  data,\n  col_map = list(subject = \"subject\", trial = \"trial\", time = \"time\", x = \"x\", y = \"y\")\n)\n\n\n\n\n\n\n\ndata\n\n\nA dataframe containing gaze data.\n\n\n\n\ncol_map\n\n\nA named list mapping your current columns to WebGazer names: ‘subject’, ‘trial’, ‘time’, ‘x’, ‘y’.\n\n\n\n\n\n\nThis function takes a dataframe and renames columns to match WebGazer conventions: subject, trial, time, x, y. All other columns are preserved.\n\n\n\nA dataframe with renamed columns but preserves all other original columns.",
    "crumbs": [
      "Reference",
      "make_webgazer"
    ]
  },
  {
    "objectID": "man/make_webgazer.html#standardize-a-dataframe-to-webgazer-conventions",
    "href": "man/make_webgazer.html#standardize-a-dataframe-to-webgazer-conventions",
    "title": "webgazeR v0.7.2",
    "section": "",
    "text": "This function takes a dataframe and renames columns to match WebGazer conventions: subject, trial, time, x, y. All other columns are preserved. Standardize a Dataframe to WebGazer Conventions\n\n\n\nmake_webgazer(\n  data,\n  col_map = list(subject = \"subject\", trial = \"trial\", time = \"time\", x = \"x\", y = \"y\")\n)\n\n\n\n\n\n\n\ndata\n\n\nA dataframe containing gaze data.\n\n\n\n\ncol_map\n\n\nA named list mapping your current columns to WebGazer names: ‘subject’, ‘trial’, ‘time’, ‘x’, ‘y’.\n\n\n\n\n\n\nThis function takes a dataframe and renames columns to match WebGazer conventions: subject, trial, time, x, y. All other columns are preserved.\n\n\n\nA dataframe with renamed columns but preserves all other original columns.",
    "crumbs": [
      "Reference",
      "make_webgazer"
    ]
  },
  {
    "objectID": "man/assign_aoi.html",
    "href": "man/assign_aoi.html",
    "title": "webgazeR v0.7.2",
    "section": "",
    "text": "Takes a data frame of gaze positions (or other locations), plus screen size and aoi size (or location), and computes the area of interest (AOI) for each location. Defaults assume standard four-corner design.\n\n\n\nassign_aoi(\n  gaze,\n  screen_size = c(1024, 768),\n  aoi_size = c(400, 300),\n  aoi_loc = NULL,\n  X = \"CURRENT_FIX_X\",\n  Y = \"CURRENT_FIX_Y\"\n)\n\n\n\n\n\n\n\ngaze\n\n\ndata frame containing positions\n\n\n\n\nscreen_size\n\n\nsize of the screen in pixels. Defaults to c(1024, 768) and assumes reversed vertical (i.e., [0,0] is top left).\n\n\n\n\naoi_size\n\n\nsize of AOIs in pixels. Defaults to a c(400, 300) width-height pair and assumes AOIs are in screen corners. AOIs will be coded numerically 1 to 4 in reading order (left to right, top to bottom), with 0 as center location.\n\n\n\n\naoi_loc\n\n\nlocation of rectangular AOIs. Use as alternative to aoi_size for non-corner AOIs. Each AOI location should be a separate row in a data frame that has variables xmin, xmax, ymin, and ymax. Assumes reversed vertical (i.e., [0,0] is top left). AOIs will be coded numerically in row order.\n\n\n\n\nX\n\n\nname of variable containing X coordinates. Defaults to \"CURRENT_FIX_X\"\n\n\n\n\nY\n\n\nname of variable containing Y coordinates. Defaults to \"CURRENT_FIX_Y\"\n\n\n\n\n\n\nOriginal gaze data frame with AOI column added. Non-AOI and off-screen gazes are marked NA.",
    "crumbs": [
      "Reference",
      "assign_aoi"
    ]
  },
  {
    "objectID": "man/assign_aoi.html#assign-coordinates-to-areas-of-interest",
    "href": "man/assign_aoi.html#assign-coordinates-to-areas-of-interest",
    "title": "webgazeR v0.7.2",
    "section": "",
    "text": "Takes a data frame of gaze positions (or other locations), plus screen size and aoi size (or location), and computes the area of interest (AOI) for each location. Defaults assume standard four-corner design.\n\n\n\nassign_aoi(\n  gaze,\n  screen_size = c(1024, 768),\n  aoi_size = c(400, 300),\n  aoi_loc = NULL,\n  X = \"CURRENT_FIX_X\",\n  Y = \"CURRENT_FIX_Y\"\n)\n\n\n\n\n\n\n\ngaze\n\n\ndata frame containing positions\n\n\n\n\nscreen_size\n\n\nsize of the screen in pixels. Defaults to c(1024, 768) and assumes reversed vertical (i.e., [0,0] is top left).\n\n\n\n\naoi_size\n\n\nsize of AOIs in pixels. Defaults to a c(400, 300) width-height pair and assumes AOIs are in screen corners. AOIs will be coded numerically 1 to 4 in reading order (left to right, top to bottom), with 0 as center location.\n\n\n\n\naoi_loc\n\n\nlocation of rectangular AOIs. Use as alternative to aoi_size for non-corner AOIs. Each AOI location should be a separate row in a data frame that has variables xmin, xmax, ymin, and ymax. Assumes reversed vertical (i.e., [0,0] is top left). AOIs will be coded numerically in row order.\n\n\n\n\nX\n\n\nname of variable containing X coordinates. Defaults to \"CURRENT_FIX_X\"\n\n\n\n\nY\n\n\nname of variable containing Y coordinates. Defaults to \"CURRENT_FIX_Y\"\n\n\n\n\n\n\nOriginal gaze data frame with AOI column added. Non-AOI and off-screen gazes are marked NA.",
    "crumbs": [
      "Reference",
      "assign_aoi"
    ]
  },
  {
    "objectID": "man/extract_aois.html",
    "href": "man/extract_aois.html",
    "title": "webgazeR v0.7.2",
    "section": "",
    "text": "This function reads in multiple Gorilla webcam files, extracts the ‘loc’, ‘x_normalised’, ‘y_normalised’, ‘width_normalised’, and ‘height_normalised’ columns, and calculates the bounding box coordinates for the AOIs. It also rounds all numeric columns to 3 decimal places.\n\n\n\nextract_aois(file_paths, zone_names = NULL)\n\n\n\n\n\n\n\nfile_paths\n\n\nA list of file paths to webcam files (in .xlsx format).\n\n\n\n\n\n\nA dataframe containing distinct rows with AOI-related columns and calculated coordinates.",
    "crumbs": [
      "Reference",
      "extract_aois"
    ]
  },
  {
    "objectID": "man/extract_aois.html#extract-aoi-related-columns-from-webcam-files-and-calculate-locations",
    "href": "man/extract_aois.html#extract-aoi-related-columns-from-webcam-files-and-calculate-locations",
    "title": "webgazeR v0.7.2",
    "section": "",
    "text": "This function reads in multiple Gorilla webcam files, extracts the ‘loc’, ‘x_normalised’, ‘y_normalised’, ‘width_normalised’, and ‘height_normalised’ columns, and calculates the bounding box coordinates for the AOIs. It also rounds all numeric columns to 3 decimal places.\n\n\n\nextract_aois(file_paths, zone_names = NULL)\n\n\n\n\n\n\n\nfile_paths\n\n\nA list of file paths to webcam files (in .xlsx format).\n\n\n\n\n\n\nA dataframe containing distinct rows with AOI-related columns and calculated coordinates.",
    "crumbs": [
      "Reference",
      "extract_aois"
    ]
  },
  {
    "objectID": "man/plot_IA_proportions.html",
    "href": "man/plot_IA_proportions.html",
    "title": "webgazeR v0.7.2",
    "section": "",
    "text": "This function creates a time-course plot of the proportion of looks to specified Interest Areas (IAs). Optionally, it can facet the plot by an experimental condition. Custom labels for each IA can be specified through the ‘ia_mapping’ argument to define the display order.\n\n\n\nplot_IA_proportions(\n  data,\n  ia_column,\n  time_column,\n  proportion_column,\n  condition_column = NULL,\n  ia_mapping,\n  use_color = TRUE\n)\n\n\n\n\n\n\n\ndata\n\n\nA data frame containing the data to plot.\n\n\n\n\nia_column\n\n\nThe name of the column containing Interest Area (IA) identifiers.\n\n\n\n\ntime_column\n\n\nThe name of the column representing time (e.g., milliseconds).\n\n\n\n\nproportion_column\n\n\nThe name of the column with the proportion of looks for each IA.\n\n\n\n\ncondition_column\n\n\nOptional. The name of the column representing experimental conditions. If not provided, the plot will not be faceted by condition.\n\n\n\n\nia_mapping\n\n\nA named list specifying custom labels for each IA in the desired display order (e.g., ‘list(IA1 = \"Target\", IA2 = \"Cohort\", IA3 = \"Rhyme\", IA4 = \"Unrelated\")’).\n\n\n\n\nuse_color\n\n\nLogical. If ‘TRUE’ (default), the plot will use colors to differentiate Interest Areas. If ‘FALSE’, different line types, shapes, and line widths will be used instead.\n\n\n\n\n\n\nA ggplot2 plot of the proportion of looks over time for each IA, optionally faceted by condition.",
    "crumbs": [
      "Reference",
      "plot_IA_proportions"
    ]
  },
  {
    "objectID": "man/plot_IA_proportions.html#plot-proportion-of-looks-over-time-for-interest-areas-ias",
    "href": "man/plot_IA_proportions.html#plot-proportion-of-looks-over-time-for-interest-areas-ias",
    "title": "webgazeR v0.7.2",
    "section": "",
    "text": "This function creates a time-course plot of the proportion of looks to specified Interest Areas (IAs). Optionally, it can facet the plot by an experimental condition. Custom labels for each IA can be specified through the ‘ia_mapping’ argument to define the display order.\n\n\n\nplot_IA_proportions(\n  data,\n  ia_column,\n  time_column,\n  proportion_column,\n  condition_column = NULL,\n  ia_mapping,\n  use_color = TRUE\n)\n\n\n\n\n\n\n\ndata\n\n\nA data frame containing the data to plot.\n\n\n\n\nia_column\n\n\nThe name of the column containing Interest Area (IA) identifiers.\n\n\n\n\ntime_column\n\n\nThe name of the column representing time (e.g., milliseconds).\n\n\n\n\nproportion_column\n\n\nThe name of the column with the proportion of looks for each IA.\n\n\n\n\ncondition_column\n\n\nOptional. The name of the column representing experimental conditions. If not provided, the plot will not be faceted by condition.\n\n\n\n\nia_mapping\n\n\nA named list specifying custom labels for each IA in the desired display order (e.g., ‘list(IA1 = \"Target\", IA2 = \"Cohort\", IA3 = \"Rhyme\", IA4 = \"Unrelated\")’).\n\n\n\n\nuse_color\n\n\nLogical. If ‘TRUE’ (default), the plot will use colors to differentiate Interest Areas. If ‘FALSE’, different line types, shapes, and line widths will be used instead.\n\n\n\n\n\n\nA ggplot2 plot of the proportion of looks over time for each IA, optionally faceted by condition.",
    "crumbs": [
      "Reference",
      "plot_IA_proportions"
    ]
  },
  {
    "objectID": "man/filter_sampling_rate.html",
    "href": "man/filter_sampling_rate.html",
    "title": "webgazeR v0.7.2",
    "section": "",
    "text": "This function applies a sampling rate threshold and either removes or labels \"bad\" subjects/trials based on their sampling rates.\n\n\n\nfilter_sampling_rate(\n  data,\n  threshold = NA,\n  action = c(\"remove\", \"label\"),\n  by = c(\"subject\", \"trial\", \"both\")\n)\n\n\n\n\n\n\n\ndata\n\n\nA dataframe with columns: subject, trial, SR_subject, SR_trial.\n\n\n\n\nthreshold\n\n\nNumeric. Sampling rate threshold to apply.\n\n\n\n\naction\n\n\n\"remove\" (default) to delete bad data or \"label\" to flag bad data.\n\n\n\n\nby\n\n\n\"subject\", \"trial\", or \"both\" to specify where to apply the threshold.\n\n\n\n\n\n\nA dataframe with either rows removed or bad subjects/trials labeled.",
    "crumbs": [
      "Reference",
      "filter_sampling_rate"
    ]
  },
  {
    "objectID": "man/filter_sampling_rate.html#filter-or-label-data-based-on-sampling-rate-threshold",
    "href": "man/filter_sampling_rate.html#filter-or-label-data-based-on-sampling-rate-threshold",
    "title": "webgazeR v0.7.2",
    "section": "",
    "text": "This function applies a sampling rate threshold and either removes or labels \"bad\" subjects/trials based on their sampling rates.\n\n\n\nfilter_sampling_rate(\n  data,\n  threshold = NA,\n  action = c(\"remove\", \"label\"),\n  by = c(\"subject\", \"trial\", \"both\")\n)\n\n\n\n\n\n\n\ndata\n\n\nA dataframe with columns: subject, trial, SR_subject, SR_trial.\n\n\n\n\nthreshold\n\n\nNumeric. Sampling rate threshold to apply.\n\n\n\n\naction\n\n\n\"remove\" (default) to delete bad data or \"label\" to flag bad data.\n\n\n\n\nby\n\n\n\"subject\", \"trial\", or \"both\" to specify where to apply the threshold.\n\n\n\n\n\n\nA dataframe with either rows removed or bad subjects/trials labeled.",
    "crumbs": [
      "Reference",
      "filter_sampling_rate"
    ]
  },
  {
    "objectID": "vignettes/ISC.html",
    "href": "vignettes/ISC.html",
    "title": "Calculating Intersubject Correlations",
    "section": "",
    "text": "Intersubject correlation (ISC) is a measure used to assess the degree of synchrony among participants—that is, how similarly their responses change over time. ISC has been widely applied in fMRI and EEG research, particularly in naturalistic contexts, to quantify shared neural activity. More recently, ISC has been extended to webcam-based eye-tracking, allowing researchers to examine shared gaze patterns during dynamic stimuli.\nThis vignette demonstrates how to calculate ISC using two commonly used approaches:\nTo compute ISC, your data should be structured as a p × t matrix, where:\nBefore highlighting the function calculate_isc() I want to break down each step that goes into calculating the ISC.",
    "crumbs": [
      "Articles",
      "Calculating Intersubject Correlations"
    ]
  },
  {
    "objectID": "vignettes/ISC.html#pairwise-isc",
    "href": "vignettes/ISC.html#pairwise-isc",
    "title": "Calculating Intersubject Correlations",
    "section": "Pairwise ISC",
    "text": "Pairwise ISC\nBelow, we generate a 10 × 1000 matrix\n\nResultInteractive\n\n\nlibrary(tidyverse)\nlibrary(webgazeR)\nset.seed(123)\n\ndata_matrix &lt;- matrix(rnorm(10 * 1000), nrow = 1000, ncol = 10)\n\ndata_matrix %&gt;% \n  head()\n\n            [,1]        [,2]       [,3]        [,4]       [,5]       [,6]\n[1,] -0.56047565 -0.99579872 -0.5116037 -0.15030748  0.1965498 -0.4941739\n[2,] -0.23017749 -1.03995504  0.2369379 -0.32775713  0.6501132  1.1275935\n[3,]  1.55870831 -0.01798024 -0.5415892 -1.44816529  0.6710042 -1.1469495\n[4,]  0.07050839 -0.13217513  1.2192276 -0.69728458 -1.2841578  1.4810186\n[5,]  0.12928774 -2.54934277  0.1741359  2.59849023 -2.0261096  0.9161912\n[6,]  1.71506499  1.04057346 -0.6152683 -0.03741501  2.2053261  0.3351310\n           [,7]       [,8]       [,9]      [,10]\n[1,] -0.6992281 -1.6180367  0.5110004  1.9315759\n[2,]  0.9964515  0.3791812  1.8079928 -0.6164747\n[3,] -0.6927454  1.9022505 -1.7026150 -0.5625675\n[4,] -0.1034830  0.6018743  0.2874488 -0.9899631\n[5,]  0.6038661  1.7323497 -0.2691142  2.7312276\n[6,] -0.6080450 -0.1468696 -0.3795247 -0.7216662\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nWe use the cor() function to compute pairwise correlations between each participant’s time-binned data and that of every other participant.\nWe specify use = “pairwise.complete.obs” to ensure that:\n\nIf any missing values (NA) exist for a participant, those time points are excluded from the correlation for all comparisons involving that participant.\nThis allows us to retain all participants in the dataset while ensuring that correlations are computed using only available data.\n\n\nResultInteractive\n\n\ncorrelation_matrix &lt;- cor(data_matrix, use = \"pairwise.complete.obs\")\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nSince the diagonal of the correlation matrix represents self-correlations (i.e., each participant correlated with themselves), we replace those values with NA, as they are not meaningful for intersubject correlation (ISC):\n\nResultInteractive\n\n\ndiag(correlation_matrix) &lt;- NA\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\nResultInteractive\n\n\ncorrelation_matrix\n\n              [,1]         [,2]         [,3]          [,4]          [,5]\n [1,]           NA  0.086479441 -0.019329537 -0.0029947104  0.0322973377\n [2,]  0.086479441           NA  0.026503334 -0.0070290755  0.0924646624\n [3,] -0.019329537  0.026503334           NA  0.0505608499 -0.0150195347\n [4,] -0.002994710 -0.007029076  0.050560850            NA -0.0004005193\n [5,]  0.032297338  0.092464662 -0.015019535 -0.0004005193            NA\n [6,] -0.018267991 -0.055292983 -0.033003346  0.0438457353  0.0138042312\n [7,] -0.034340849  0.024316458  0.005282974 -0.0200855749 -0.0090534146\n [8,] -0.030156049  0.031077180 -0.025946806 -0.0055278737 -0.0777495779\n [9,] -0.009370688  0.022155213  0.058417535 -0.0064371559  0.0470798891\n[10,]  0.022344953  0.022481121  0.029148322  0.0459001272 -0.0047210318\n               [,6]         [,7]         [,8]          [,9]        [,10]\n [1,] -0.0182679912 -0.034340849 -0.030156049 -0.0093706879  0.022344953\n [2,] -0.0552929834  0.024316458  0.031077180  0.0221552128  0.022481121\n [3,] -0.0330033458  0.005282974 -0.025946806  0.0584175347  0.029148322\n [4,]  0.0438457353 -0.020085575 -0.005527874 -0.0064371559  0.045900127\n [5,]  0.0138042312 -0.009053415 -0.077749578  0.0470798891 -0.004721032\n [6,]            NA -0.016497452 -0.016411441 -0.0006214018 -0.010177844\n [7,] -0.0164974516           NA  0.037173511  0.0791431861  0.002523005\n [8,] -0.0164114415  0.037173511           NA -0.0422433679  0.010503101\n [9,] -0.0006214018  0.079143186 -0.042243368            NA -0.006174781\n[10,] -0.0101778437  0.002523005  0.010503101 -0.0061747810           NA\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nNext, we apply Fisher’s Z-transformation using atanh() to convert the correlation coefficients into Z-scores before averaging.\nAveraging correlation scores directly is bad practice because:\n\nCorrelations are bounded between -1 and 1, which skews their distribution.\nFisher’s Z-transformation normalizes correlation values, making them more suitable for averaging.\n\nYou can also choose to use the median instead (if this is the case you do not need to apply Fisher transformation)\n\nResultInteractive\n\n\nz_values &lt;- atanh(correlation_matrix)  # Fisher's Z transformation\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nOnce transformed, we compute the average ISC per participant and transform back to r.\n\nResultInteractive\n\n\nisc_values &lt;- tanh(rowMeans(z_values, na.rm = TRUE))  # Convert back to r\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nthe calculate_isc() function with method=“pairwise” does all this for us.\n\nResultInteractive\n\n\nisc_pairwise &lt;- calculate_isc(data_matrix, method = \"pairwise\", summary_statistic = \"mean\")\n\nisc_pairwise\n\n [1]  0.002985107  0.027061018  0.008523871  0.010880947  0.008761466\n [6] -0.010296001  0.007625601 -0.013271741  0.015797990  0.012429909\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.",
    "crumbs": [
      "Articles",
      "Calculating Intersubject Correlations"
    ]
  },
  {
    "objectID": "vignettes/ISC.html#leave-one-out-isc",
    "href": "vignettes/ISC.html#leave-one-out-isc",
    "title": "Calculating Intersubject Correlations",
    "section": "Leave one out ISC",
    "text": "Leave one out ISC\nIn the leave-one-out approach, we compute the correlation between each participant’s time series and the average time series of all other participants, excluding their own data.\nFirst, we extract the time series for a single participant:\n\nResultInteractive\n\n\n# Extract the full time series for the current subject\nsubject_time_series &lt;- data_matrix[, 1]\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nand calculate the mean of the other subjects data points, excluding the current subject\n\nResultInteractive\n\n\nleave_one_out_mean &lt;- rowMeans(data_matrix[, -1, drop = FALSE], na.rm = TRUE)\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nWe then compute the correlation between the participant’s time series and the leave-one-out mean:\n\nResultInteractive\n\n\nleave_one_out_isc &lt;- cor(subject_time_series, \n                                          leave_one_out_mean, \n                                          use = \"pairwise.complete.obs\")\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nSince this needs to be done for every participant, we use the calculate_isc() function to automate the process:\n\nResultInteractive\n\n\nisc_pairwise &lt;- calculate_isc(data_matrix, method = \"leave-one-out\")\n\nisc_pairwise\n\n [1]  0.008891827  0.080509746  0.025626567  0.031021518  0.026597776\n [6] -0.029482014  0.023592539 -0.038321505  0.046317774  0.036036027\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.",
    "crumbs": [
      "Articles",
      "Calculating Intersubject Correlations"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Webcam Eye-tracking R Package",
    "section": "",
    "text": "WebgazeR\nFunctions for analyzing webcam eye-tracking data",
    "crumbs": [
      "Home"
    ]
  }
]