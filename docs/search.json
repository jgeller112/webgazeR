[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Webcam Eye-tracking R Package",
    "section": "",
    "text": "WebgazeR\nFunctions for analyzing webcam eye-tracking data",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "CITATION.html",
    "href": "CITATION.html",
    "title": "Citation",
    "section": "",
    "text": "Citation\nTo cite package ‘webgazeR’ in publications use:\n\n  Geller J, Prystauka Y (2025). _webgazeR: Tools for Processing\n  Webcam Eye Tracking Data_. R package version 0.1.0,\n  https://github.com/jgeller112/webgazeR,\n  &lt;https://jgeller112.github.io/webgazeR/&gt;.\n\nA BibTeX entry for LaTeX users is\n\n  @Manual{,\n    title = {webgazeR: Tools for Processing Webcam Eye Tracking Data},\n    author = {Jason Geller and Yanina Prystauka},\n    year = {2025},\n    note = {R package version 0.1.0, \nhttps://github.com/jgeller112/webgazeR},\n    url = {https://jgeller112.github.io/webgazeR/},\n  }",
    "crumbs": [
      "Citation"
    ]
  },
  {
    "objectID": "man/filter_sampling_rate.html",
    "href": "man/filter_sampling_rate.html",
    "title": "webgazeR",
    "section": "",
    "text": "This function allows users to set a sampling rate threshold and choose to either remove the data that falls below the threshold or label it as \"bad.\" Users can apply this threshold either at the subject level, the trial level, or both.\n\n\n\nfilter_sampling_rate(\n  data,\n  threshold = NA,\n  action = c(\"remove\", \"label\"),\n  by = c(\"subject\", \"trial\", \"both\")\n)\n\n\n\n\n\n\n\ndata\n\n\nA dataframe that contains the data to be processed. The dataframe should include the columns:\n\n\n‘subject’\n\n\nUnique identifier for each participant in the dataset.\n\n\n‘med_SR’\n\n\nSubject-level median sampling rate (Hz). This represents the median sampling rate for a subject across trials.\n\n\n‘SR’\n\n\nTrial-level sampling rate (Hz). This represents the sampling rate for each specific trial.\n\n\n\n\n\n\nthreshold\n\n\nNumeric value specifying the sampling rate threshold. Data falling below this threshold will either be removed or labeled as \"bad\".\n\n\n\n\naction\n\n\nCharacter string specifying whether to \"remove\" data that falls below the threshold or \"label\" it as bad. Acceptable values are ‘\"remove\"’ or ‘\"label\"’.\n\n\n‘\"remove\"’\n\n\nRemoves rows from the dataset where the sampling rate falls below the threshold.\n\n\n‘\"label\"’\n\n\nAdds new columns ‘is_bad_subject’ and/or ‘is_bad_trial’ that flag rows where the sampling rate falls below the threshold.\n\n\n\n\n\n\nby\n\n\nCharacter string specifying whether the threshold should be applied at the \"subject\" level, the \"trial\" level, or \"both\". Acceptable values are ‘\"subject\"’, ‘\"trial\"’, or ‘\"both\"’.\n\n\n‘\"subject\"’\n\n\nApplies the threshold to the subject-level median sampling rate (‘med_SR’).\n\n\n‘\"trial\"’\n\n\nApplies the threshold to the trial-level sampling rate (‘SR’).\n\n\n‘\"both\"’\n\n\nApplies the threshold to both the subject-level (‘med_SR’) and trial-level (‘SR’) rates. Data is removed/labeled if either rate falls below the threshold.\n\n\n\n\n\n\n\n\nA dataframe with either rows removed or new columns (‘is_bad_subject’, ‘is_bad_trial’) added to indicate whether the data is below the threshold. Additionally, messages will inform the user how many subjects and trials were removed or labeled as \"bad.\"\n\n\n\nThe function will either return a dataset with rows removed based on the sampling rate threshold or add new columns, ‘is_bad_subject’ and/or ‘is_bad_trial’ to the dataset, which indicates whether the data is considered \"bad\" (i.e., below the sampling rate threshold).\n\n\n\n\n\nResultInteractive\n\n\nlibrary(webgazeR)\n\n# Example usage of the filter_sampling_rate function\nresult &lt;- filter_sampling_rate(data = data_with_sr, threshold = 500, action = \"remove\", by = \"both\")\n# Example usage to label data as \"bad\"\nresult &lt;- filter_sampling_rate(data = data_with_sr, threshold = 500, action = \"label\", by = \"trial\")\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.",
    "crumbs": [
      "Reference",
      "filter_sampling_rate"
    ]
  },
  {
    "objectID": "man/filter_sampling_rate.html#filter-or-label-data-based-on-sampling-rate-threshold",
    "href": "man/filter_sampling_rate.html#filter-or-label-data-based-on-sampling-rate-threshold",
    "title": "webgazeR",
    "section": "",
    "text": "This function allows users to set a sampling rate threshold and choose to either remove the data that falls below the threshold or label it as \"bad.\" Users can apply this threshold either at the subject level, the trial level, or both.\n\n\n\nfilter_sampling_rate(\n  data,\n  threshold = NA,\n  action = c(\"remove\", \"label\"),\n  by = c(\"subject\", \"trial\", \"both\")\n)\n\n\n\n\n\n\n\ndata\n\n\nA dataframe that contains the data to be processed. The dataframe should include the columns:\n\n\n‘subject’\n\n\nUnique identifier for each participant in the dataset.\n\n\n‘med_SR’\n\n\nSubject-level median sampling rate (Hz). This represents the median sampling rate for a subject across trials.\n\n\n‘SR’\n\n\nTrial-level sampling rate (Hz). This represents the sampling rate for each specific trial.\n\n\n\n\n\n\nthreshold\n\n\nNumeric value specifying the sampling rate threshold. Data falling below this threshold will either be removed or labeled as \"bad\".\n\n\n\n\naction\n\n\nCharacter string specifying whether to \"remove\" data that falls below the threshold or \"label\" it as bad. Acceptable values are ‘\"remove\"’ or ‘\"label\"’.\n\n\n‘\"remove\"’\n\n\nRemoves rows from the dataset where the sampling rate falls below the threshold.\n\n\n‘\"label\"’\n\n\nAdds new columns ‘is_bad_subject’ and/or ‘is_bad_trial’ that flag rows where the sampling rate falls below the threshold.\n\n\n\n\n\n\nby\n\n\nCharacter string specifying whether the threshold should be applied at the \"subject\" level, the \"trial\" level, or \"both\". Acceptable values are ‘\"subject\"’, ‘\"trial\"’, or ‘\"both\"’.\n\n\n‘\"subject\"’\n\n\nApplies the threshold to the subject-level median sampling rate (‘med_SR’).\n\n\n‘\"trial\"’\n\n\nApplies the threshold to the trial-level sampling rate (‘SR’).\n\n\n‘\"both\"’\n\n\nApplies the threshold to both the subject-level (‘med_SR’) and trial-level (‘SR’) rates. Data is removed/labeled if either rate falls below the threshold.\n\n\n\n\n\n\n\n\nA dataframe with either rows removed or new columns (‘is_bad_subject’, ‘is_bad_trial’) added to indicate whether the data is below the threshold. Additionally, messages will inform the user how many subjects and trials were removed or labeled as \"bad.\"\n\n\n\nThe function will either return a dataset with rows removed based on the sampling rate threshold or add new columns, ‘is_bad_subject’ and/or ‘is_bad_trial’ to the dataset, which indicates whether the data is considered \"bad\" (i.e., below the sampling rate threshold).\n\n\n\n\n\nResultInteractive\n\n\nlibrary(webgazeR)\n\n# Example usage of the filter_sampling_rate function\nresult &lt;- filter_sampling_rate(data = data_with_sr, threshold = 500, action = \"remove\", by = \"both\")\n# Example usage to label data as \"bad\"\nresult &lt;- filter_sampling_rate(data = data_with_sr, threshold = 500, action = \"label\", by = \"trial\")\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.",
    "crumbs": [
      "Reference",
      "filter_sampling_rate"
    ]
  },
  {
    "objectID": "man/extract_aois.html",
    "href": "man/extract_aois.html",
    "title": "webgazeR",
    "section": "",
    "text": "This function reads in multiple Gorilla webcam files, extracts the ‘loc’, ‘x_normalised’, ‘y_normalised’, ‘width_normalised’, and ‘height_normalised’ columns, and calculates the bounding box coordinates for the AOIs. It also rounds all numeric columns to 3 decimal places.\n\n\n\nextract_aois(file_paths, zone_names = NULL)\n\n\n\n\n\n\n\nfile_paths\n\n\nA list of file paths to webcam files (in .xlsx format).\n\n\n\n\n\n\nA dataframe containing distinct rows with AOI-related columns and calculated coordinates.\n\n\n\n\n\nResultInteractive\n\n\nlibrary(webgazeR)\n\n# Example usage:\n# file_paths &lt;- c(\"file1.xlsx\", \"file2.xlsx\")\n# aoi_data &lt;- extract_aois(file_paths)\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.",
    "crumbs": [
      "Reference",
      "extract_aois"
    ]
  },
  {
    "objectID": "man/extract_aois.html#extract-aoi-related-columns-from-webcam-files-and-calculate-locations",
    "href": "man/extract_aois.html#extract-aoi-related-columns-from-webcam-files-and-calculate-locations",
    "title": "webgazeR",
    "section": "",
    "text": "This function reads in multiple Gorilla webcam files, extracts the ‘loc’, ‘x_normalised’, ‘y_normalised’, ‘width_normalised’, and ‘height_normalised’ columns, and calculates the bounding box coordinates for the AOIs. It also rounds all numeric columns to 3 decimal places.\n\n\n\nextract_aois(file_paths, zone_names = NULL)\n\n\n\n\n\n\n\nfile_paths\n\n\nA list of file paths to webcam files (in .xlsx format).\n\n\n\n\n\n\nA dataframe containing distinct rows with AOI-related columns and calculated coordinates.\n\n\n\n\n\nResultInteractive\n\n\nlibrary(webgazeR)\n\n# Example usage:\n# file_paths &lt;- c(\"file1.xlsx\", \"file2.xlsx\")\n# aoi_data &lt;- extract_aois(file_paths)\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.",
    "crumbs": [
      "Reference",
      "extract_aois"
    ]
  },
  {
    "objectID": "man/downsample_gaze.html",
    "href": "man/downsample_gaze.html",
    "title": "webgazeR",
    "section": "",
    "text": "This function combines gaze samples into time bins and optionally aggregates the data.\n\n\n\ndownsample_gaze(\n  dataframe,\n  bin.length = 50,\n  timevar = \"time\",\n  aggvars = c(\"subject\", \"condition\", \"target\", \"trial\", \"object\", \"time_bin\")\n)\n\n\n\n\n\n\n\ndataframe\n\n\nDataFrame containing gaze data.\n\n\n\n\nbin.length\n\n\nLength of time bins (in milliseconds).\n\n\n\n\ntimevar\n\n\nColumn name representing time.\n\n\n\n\naggvars\n\n\nVector of variable names to group by for aggregation. Use \"none\" to skip aggregation.\n\n\n\n\n\n\nDataFrame with time bins added and optionally aggregated data.",
    "crumbs": [
      "Reference",
      "downsample_gaze"
    ]
  },
  {
    "objectID": "man/downsample_gaze.html#downsample-gaze-data",
    "href": "man/downsample_gaze.html#downsample-gaze-data",
    "title": "webgazeR",
    "section": "",
    "text": "This function combines gaze samples into time bins and optionally aggregates the data.\n\n\n\ndownsample_gaze(\n  dataframe,\n  bin.length = 50,\n  timevar = \"time\",\n  aggvars = c(\"subject\", \"condition\", \"target\", \"trial\", \"object\", \"time_bin\")\n)\n\n\n\n\n\n\n\ndataframe\n\n\nDataFrame containing gaze data.\n\n\n\n\nbin.length\n\n\nLength of time bins (in milliseconds).\n\n\n\n\ntimevar\n\n\nColumn name representing time.\n\n\n\n\naggvars\n\n\nVector of variable names to group by for aggregation. Use \"none\" to skip aggregation.\n\n\n\n\n\n\nDataFrame with time bins added and optionally aggregated data.",
    "crumbs": [
      "Reference",
      "downsample_gaze"
    ]
  },
  {
    "objectID": "man/merge_webcam_files.html",
    "href": "man/merge_webcam_files.html",
    "title": "webgazeR",
    "section": "",
    "text": "This function reads in multiple Gorilla webcam files, merges them, and optionally extracts area of interest (AOI) data. It cleans up column names, and allows filtering by screen index. If ‘extract_aois’ is TRUE, it extracts specific AOI-related columns (‘zone_name’, ‘zone_x_normalized’, ‘zone_y_normalized’, ‘zone_width_normalized’, and ‘zone_height_normalized’) and returns distinct rows for these columns.\n\n\n\nmerge_webcam_files(file_paths, screen_index = NULL)\n\n\n\n\n\n\n\nfile_paths\n\n\nA list of file paths to webcam files (in .xlsx format).\n\n\n\n\nscreen_index\n\n\nAn optional screen index to filter the data by. If NULL, the filter will be ignored.\n\n\n\n\nextract_aois\n\n\nLogical. If TRUE, extracts AOI-related columns and returns distinct rows for them.\n\n\n\n\n\n\nA dataframe containing the merged and processed data from the webcam files. If ‘extract_aois’ is TRUE, it returns a dataframe with distinct AOI-related columns.\n\n\n\n\n\nResultInteractive\n\n\nlibrary(webgazeR)\n\n# Example usage:\n# file_paths &lt;- c(\"file1.xlsx\", \"file2.xlsx\")\n# merged_data &lt;- extract_gorilla_aois(file_paths, screen_index = 4, extract_aois = FALSE)\n# aoi_data &lt;- extract_gorilla_aois(file_paths, screen_index = 4, extract_aois = TRUE)\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.",
    "crumbs": [
      "Reference",
      "merge_webcam_files"
    ]
  },
  {
    "objectID": "man/merge_webcam_files.html#extract-and-merge-gorilla-webcam-files-with-optional-aoi-extraction",
    "href": "man/merge_webcam_files.html#extract-and-merge-gorilla-webcam-files-with-optional-aoi-extraction",
    "title": "webgazeR",
    "section": "",
    "text": "This function reads in multiple Gorilla webcam files, merges them, and optionally extracts area of interest (AOI) data. It cleans up column names, and allows filtering by screen index. If ‘extract_aois’ is TRUE, it extracts specific AOI-related columns (‘zone_name’, ‘zone_x_normalized’, ‘zone_y_normalized’, ‘zone_width_normalized’, and ‘zone_height_normalized’) and returns distinct rows for these columns.\n\n\n\nmerge_webcam_files(file_paths, screen_index = NULL)\n\n\n\n\n\n\n\nfile_paths\n\n\nA list of file paths to webcam files (in .xlsx format).\n\n\n\n\nscreen_index\n\n\nAn optional screen index to filter the data by. If NULL, the filter will be ignored.\n\n\n\n\nextract_aois\n\n\nLogical. If TRUE, extracts AOI-related columns and returns distinct rows for them.\n\n\n\n\n\n\nA dataframe containing the merged and processed data from the webcam files. If ‘extract_aois’ is TRUE, it returns a dataframe with distinct AOI-related columns.\n\n\n\n\n\nResultInteractive\n\n\nlibrary(webgazeR)\n\n# Example usage:\n# file_paths &lt;- c(\"file1.xlsx\", \"file2.xlsx\")\n# merged_data &lt;- extract_gorilla_aois(file_paths, screen_index = 4, extract_aois = FALSE)\n# aoi_data &lt;- extract_gorilla_aois(file_paths, screen_index = 4, extract_aois = TRUE)\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.",
    "crumbs": [
      "Reference",
      "merge_webcam_files"
    ]
  },
  {
    "objectID": "man/gaze_oob.html",
    "href": "man/gaze_oob.html",
    "title": "webgazeR",
    "section": "",
    "text": "This function calculates the number and percentage of points that fall outside a specified range (0, 1) for both X and Y coordinates, grouped by subject.\n\n\n\ngaze_oob(\n  data,\n  subject_col = \"subject\",\n  x_col = \"x_pred_normalised\",\n  y_col = \"y_pred_normalised\"\n)\n\n\n\n\n\n\n\ndata\n\n\nA data frame containing gaze data.\n\n\n\n\nsubject_col\n\n\nA string specifying the name of the column that contains the subject identifier. Default is \"subject\".\n\n\n\n\nx_col\n\n\nA string specifying the name of the column that contains the X coordinate. Default is \"x_pred_normalised\".\n\n\n\n\ny_col\n\n\nA string specifying the name of the column that contains the Y coordinate. Default is \"y_pred_normalised\".\n\n\n\n\n\n\nA data frame with the following columns:\n\n\nsubject\n\n\nThe subject identifier.\n\n\ntotal_points\n\n\nThe total number of points for the subject.\n\n\noutside_count\n\n\nThe number of points outside the range for both X and Y coordinates.\n\n\nx_outside_count\n\n\nThe number of points outside the range for the X coordinate.\n\n\ny_outside_count\n\n\nThe number of points outside the range for the Y coordinate.\n\n\nx_outside_percentage\n\n\nThe percentage of points outside the range for the X coordinate.\n\n\ny_outside_percentage\n\n\nThe percentage of points outside the range for the Y coordinate.\n\n\n\n\n\n\n\nResultInteractive\n\n\nlibrary(webgazeR)\n\n  # Example data\n  data &lt;- data.frame(\n    subject = rep(1:2, each = 100),\n    x_pred_normalised = runif(200, -0.5, 1.5),\n    y_pred_normalised = runif(200, -0.5, 1.5)\n  )\n\n  # Calculate out-of-bounds proportion by subject\n  results &lt;- calculate_out_of_bounds_by_subject(data)\n  print(results)\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.",
    "crumbs": [
      "Reference",
      "gaze_oob"
    ]
  },
  {
    "objectID": "man/gaze_oob.html#calculate-out-of-bounds-proportion-by-subject",
    "href": "man/gaze_oob.html#calculate-out-of-bounds-proportion-by-subject",
    "title": "webgazeR",
    "section": "",
    "text": "This function calculates the number and percentage of points that fall outside a specified range (0, 1) for both X and Y coordinates, grouped by subject.\n\n\n\ngaze_oob(\n  data,\n  subject_col = \"subject\",\n  x_col = \"x_pred_normalised\",\n  y_col = \"y_pred_normalised\"\n)\n\n\n\n\n\n\n\ndata\n\n\nA data frame containing gaze data.\n\n\n\n\nsubject_col\n\n\nA string specifying the name of the column that contains the subject identifier. Default is \"subject\".\n\n\n\n\nx_col\n\n\nA string specifying the name of the column that contains the X coordinate. Default is \"x_pred_normalised\".\n\n\n\n\ny_col\n\n\nA string specifying the name of the column that contains the Y coordinate. Default is \"y_pred_normalised\".\n\n\n\n\n\n\nA data frame with the following columns:\n\n\nsubject\n\n\nThe subject identifier.\n\n\ntotal_points\n\n\nThe total number of points for the subject.\n\n\noutside_count\n\n\nThe number of points outside the range for both X and Y coordinates.\n\n\nx_outside_count\n\n\nThe number of points outside the range for the X coordinate.\n\n\ny_outside_count\n\n\nThe number of points outside the range for the Y coordinate.\n\n\nx_outside_percentage\n\n\nThe percentage of points outside the range for the X coordinate.\n\n\ny_outside_percentage\n\n\nThe percentage of points outside the range for the Y coordinate.\n\n\n\n\n\n\n\nResultInteractive\n\n\nlibrary(webgazeR)\n\n  # Example data\n  data &lt;- data.frame(\n    subject = rep(1:2, each = 100),\n    x_pred_normalised = runif(200, -0.5, 1.5),\n    y_pred_normalised = runif(200, -0.5, 1.5)\n  )\n\n  # Calculate out-of-bounds proportion by subject\n  results &lt;- calculate_out_of_bounds_by_subject(data)\n  print(results)\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.",
    "crumbs": [
      "Reference",
      "gaze_oob"
    ]
  },
  {
    "objectID": "man/find_location.html",
    "href": "man/find_location.html",
    "title": "webgazeR",
    "section": "",
    "text": "This function determines the location of an image within a set of locations. The function accepts a vector of locations (such as \"TL\", \"TR\", \"BL\", \"BR\") and an image identifier. It returns the corresponding location name if the image is found, or ‘NA’ if the image is not present or is ‘NA’.\n\n\n\nfind_location(locations, image)\n\n\n\n\n\n\n\nlocations\n\n\nA character vector representing the possible locations (e.g., ‘c(\"TL\", \"TR\", \"BL\", \"BR\")’).\n\n\n\n\nimage\n\n\nA character value representing the image to find in the locations.\n\n\n\n\n\n\nA character string representing the location of the image, or ‘NA’ if the image is not found or is missing.\n\n\n\n\n\nResultInteractive\n\n\nlibrary(webgazeR)\n\n# Example usage of the find_location function\nlocations &lt;- c(\"apple\", \"banana\", \"cherry\", \"date\")\nfind_location(locations, \"banana\")  # Returns \"TR\" if locations follow c(\"TL\", \"TR\", \"BL\", \"BR\")\n\n[1] \"TR\"\n\nfind_location(locations, \"orange\")  # Returns NA\n\n[1] NA\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.",
    "crumbs": [
      "Reference",
      "find_location"
    ]
  },
  {
    "objectID": "man/find_location.html#find-image-location-in-a-given-set-of-locations",
    "href": "man/find_location.html#find-image-location-in-a-given-set-of-locations",
    "title": "webgazeR",
    "section": "",
    "text": "This function determines the location of an image within a set of locations. The function accepts a vector of locations (such as \"TL\", \"TR\", \"BL\", \"BR\") and an image identifier. It returns the corresponding location name if the image is found, or ‘NA’ if the image is not present or is ‘NA’.\n\n\n\nfind_location(locations, image)\n\n\n\n\n\n\n\nlocations\n\n\nA character vector representing the possible locations (e.g., ‘c(\"TL\", \"TR\", \"BL\", \"BR\")’).\n\n\n\n\nimage\n\n\nA character value representing the image to find in the locations.\n\n\n\n\n\n\nA character string representing the location of the image, or ‘NA’ if the image is not found or is missing.\n\n\n\n\n\nResultInteractive\n\n\nlibrary(webgazeR)\n\n# Example usage of the find_location function\nlocations &lt;- c(\"apple\", \"banana\", \"cherry\", \"date\")\nfind_location(locations, \"banana\")  # Returns \"TR\" if locations follow c(\"TL\", \"TR\", \"BL\", \"BR\")\n\n[1] \"TR\"\n\nfind_location(locations, \"orange\")  # Returns NA\n\n[1] NA\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.",
    "crumbs": [
      "Reference",
      "find_location"
    ]
  },
  {
    "objectID": "man/analyze_sampling_rate.html",
    "href": "man/analyze_sampling_rate.html",
    "title": "webgazeR",
    "section": "",
    "text": "This function calculates the sampling rate for each subject and trial in an eye-tracking dataset. It provides overall statistics, including the median and standard deviation of sampling rates, and also generates a histogram of median sampling rates by subject, with a density plot overlayed, and a vertical line showing the overall median sampling rate and the standard deviation displayed.\n\n\n\nanalyze_sampling_rate(eye_data)\n\n\n\n\n\n\n\neye_data\n\n\nA dataframe containing eye-tracking data with columns ‘subject’, ‘trial’, and ‘time’. The column ‘time’ should represent the time in milliseconds for each trial.\n\n\n\n\n\n\nA list containing:\n\n\noverall_median_SR\n\n\nThe overall median sampling rate (Hz).\n\n\noverall_sd_SR\n\n\nThe overall standard deviation of sampling rates.\n\n\nmedian_SR_by_subject\n\n\nA dataframe with the median sampling rate by subject.\n\n\nSR_by_trial\n\n\nA dataframe with the sampling rate by subject and trial.\n\n\n\n\n\n\n\nResultInteractive\n\n\nlibrary(webgazeR)\n\n  # Assuming eye_data is a dataframe with appropriate columns\n  result &lt;- analyze_sampling_rate(eye_data)\n  print(result)\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.",
    "crumbs": [
      "Reference",
      "analyze_sampling_rate"
    ]
  },
  {
    "objectID": "man/analyze_sampling_rate.html#analyze-sampling-rates-for-eye-tracking-data",
    "href": "man/analyze_sampling_rate.html#analyze-sampling-rates-for-eye-tracking-data",
    "title": "webgazeR",
    "section": "",
    "text": "This function calculates the sampling rate for each subject and trial in an eye-tracking dataset. It provides overall statistics, including the median and standard deviation of sampling rates, and also generates a histogram of median sampling rates by subject, with a density plot overlayed, and a vertical line showing the overall median sampling rate and the standard deviation displayed.\n\n\n\nanalyze_sampling_rate(eye_data)\n\n\n\n\n\n\n\neye_data\n\n\nA dataframe containing eye-tracking data with columns ‘subject’, ‘trial’, and ‘time’. The column ‘time’ should represent the time in milliseconds for each trial.\n\n\n\n\n\n\nA list containing:\n\n\noverall_median_SR\n\n\nThe overall median sampling rate (Hz).\n\n\noverall_sd_SR\n\n\nThe overall standard deviation of sampling rates.\n\n\nmedian_SR_by_subject\n\n\nA dataframe with the median sampling rate by subject.\n\n\nSR_by_trial\n\n\nA dataframe with the sampling rate by subject and trial.\n\n\n\n\n\n\n\nResultInteractive\n\n\nlibrary(webgazeR)\n\n  # Assuming eye_data is a dataframe with appropriate columns\n  result &lt;- analyze_sampling_rate(eye_data)\n  print(result)\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.",
    "crumbs": [
      "Reference",
      "analyze_sampling_rate"
    ]
  },
  {
    "objectID": "man/assign_aoi.html",
    "href": "man/assign_aoi.html",
    "title": "webgazeR",
    "section": "",
    "text": "Takes a data frame of gaze positions (or other locations), plus screen size and aoi size (or location), and computes the area of interest (AOI) for each location. Defaults assume standard four-corner design.\n\n\n\nassign_aoi(\n  gaze,\n  screen_size = c(1024, 768),\n  aoi_size = c(400, 300),\n  aoi_loc = NULL,\n  X = \"CURRENT_FIX_X\",\n  Y = \"CURRENT_FIX_Y\"\n)\n\n\n\n\n\n\n\ngaze\n\n\ndata frame containing positions\n\n\n\n\nscreen_size\n\n\nsize of the screen in pixels. Defaults to c(1024, 768) and assumes reversed vertical (i.e., [0,0] is top left).\n\n\n\n\naoi_size\n\n\nsize of AOIs in pixels. Defaults to a c(400, 300) width-height pair and assumes AOIs are in screen corners. AOIs will be coded numerically 1 to 4 in reading order (left to right, top to bottom), with 0 as center location.\n\n\n\n\naoi_loc\n\n\nlocation of rectangular AOIs. Use as alternative to aoi_size for non-corner AOIs. Each AOI location should be a separate row in a data frame that has variables xmin, xmax, ymin, and ymax. Assumes reversed vertical (i.e., [0,0] is top left). AOIs will be coded numerically in row order.\n\n\n\n\nX\n\n\nname of variable containing X coordinates. Defaults to \"CURRENT_FIX_X\"\n\n\n\n\nY\n\n\nname of variable containing Y coordinates. Defaults to \"CURRENT_FIX_Y\"\n\n\n\n\n\n\nOriginal gaze data frame with AOI column added. Non-AOI and off-screen gazes are marked NA.",
    "crumbs": [
      "Reference",
      "assign_aoi"
    ]
  },
  {
    "objectID": "man/assign_aoi.html#assign-coordinates-to-areas-of-interest",
    "href": "man/assign_aoi.html#assign-coordinates-to-areas-of-interest",
    "title": "webgazeR",
    "section": "",
    "text": "Takes a data frame of gaze positions (or other locations), plus screen size and aoi size (or location), and computes the area of interest (AOI) for each location. Defaults assume standard four-corner design.\n\n\n\nassign_aoi(\n  gaze,\n  screen_size = c(1024, 768),\n  aoi_size = c(400, 300),\n  aoi_loc = NULL,\n  X = \"CURRENT_FIX_X\",\n  Y = \"CURRENT_FIX_Y\"\n)\n\n\n\n\n\n\n\ngaze\n\n\ndata frame containing positions\n\n\n\n\nscreen_size\n\n\nsize of the screen in pixels. Defaults to c(1024, 768) and assumes reversed vertical (i.e., [0,0] is top left).\n\n\n\n\naoi_size\n\n\nsize of AOIs in pixels. Defaults to a c(400, 300) width-height pair and assumes AOIs are in screen corners. AOIs will be coded numerically 1 to 4 in reading order (left to right, top to bottom), with 0 as center location.\n\n\n\n\naoi_loc\n\n\nlocation of rectangular AOIs. Use as alternative to aoi_size for non-corner AOIs. Each AOI location should be a separate row in a data frame that has variables xmin, xmax, ymin, and ymax. Assumes reversed vertical (i.e., [0,0] is top left). AOIs will be coded numerically in row order.\n\n\n\n\nX\n\n\nname of variable containing X coordinates. Defaults to \"CURRENT_FIX_X\"\n\n\n\n\nY\n\n\nname of variable containing Y coordinates. Defaults to \"CURRENT_FIX_Y\"\n\n\n\n\n\n\nOriginal gaze data frame with AOI column added. Non-AOI and off-screen gazes are marked NA.",
    "crumbs": [
      "Reference",
      "assign_aoi"
    ]
  },
  {
    "objectID": "man/plot_IA_proportions.html",
    "href": "man/plot_IA_proportions.html",
    "title": "webgazeR",
    "section": "",
    "text": "This function creates a time-course plot of the proportion of looks to specified Interest Areas (IAs). Optionally, it can facet the plot by an experimental condition. Custom labels for each IA can be specified through the ‘ia_mapping’ argument to define the display order.\n\n\n\nplot_IA_proportions(\n  data,\n  ia_column,\n  time_column,\n  proportion_column,\n  condition_column = NULL,\n  ia_mapping\n)\n\n\n\n\n\n\n\ndata\n\n\nA data frame containing the data to plot.\n\n\n\n\nia_column\n\n\nThe name of the column containing Interest Area (IA) identifiers.\n\n\n\n\ntime_column\n\n\nThe name of the column representing time (e.g., milliseconds).\n\n\n\n\nproportion_column\n\n\nThe name of the column with the proportion of looks for each IA.\n\n\n\n\ncondition_column\n\n\nOptional. The name of the column representing experimental conditions. If not provided, the plot will not be faceted by condition.\n\n\n\n\nia_mapping\n\n\nA named list specifying custom labels for each IA in the desired display order (e.g., ‘list(IA1 = \"Target\", IA2 = \"Cohort\", IA3 = \"Rhyme\", IA4 = \"Unrelated\")’).\n\n\n\n\n\n\nA ggplot2 plot of the proportion of looks over time for each IA, optionally faceted by condition.\n\n\n\n\n\nResultInteractive\n\n\nlibrary(webgazeR)\n\n# Example with a condition column\nplot_IA_proportions(gaze_data, ia_column = \"condition\", time_column = \"time_ms\",\n                    proportion_column = \"proportion_looks\", condition_column = \"condition\",\n                    ia_mapping = list(IA1 = \"Target\", IA2 = \"Cohort\", IA3 = \"Rhyme\", IA4 = \"Unrelated\"))\n\n# Example without a condition column\nplot_IA_proportions(gaze_data, ia_column = \"condition\", time_column = \"time_ms\",\n                    proportion_column = \"proportion_looks\",\n                    ia_mapping = list(IA1 = \"Target\", IA2 = \"Cohort\", IA3 = \"Rhyme\", IA4 = \"Unrelated\"))\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.",
    "crumbs": [
      "Reference",
      "plot_IA_proportions"
    ]
  },
  {
    "objectID": "man/plot_IA_proportions.html#plot-proportion-of-looks-over-time-for-interest-areas-ias",
    "href": "man/plot_IA_proportions.html#plot-proportion-of-looks-over-time-for-interest-areas-ias",
    "title": "webgazeR",
    "section": "",
    "text": "This function creates a time-course plot of the proportion of looks to specified Interest Areas (IAs). Optionally, it can facet the plot by an experimental condition. Custom labels for each IA can be specified through the ‘ia_mapping’ argument to define the display order.\n\n\n\nplot_IA_proportions(\n  data,\n  ia_column,\n  time_column,\n  proportion_column,\n  condition_column = NULL,\n  ia_mapping\n)\n\n\n\n\n\n\n\ndata\n\n\nA data frame containing the data to plot.\n\n\n\n\nia_column\n\n\nThe name of the column containing Interest Area (IA) identifiers.\n\n\n\n\ntime_column\n\n\nThe name of the column representing time (e.g., milliseconds).\n\n\n\n\nproportion_column\n\n\nThe name of the column with the proportion of looks for each IA.\n\n\n\n\ncondition_column\n\n\nOptional. The name of the column representing experimental conditions. If not provided, the plot will not be faceted by condition.\n\n\n\n\nia_mapping\n\n\nA named list specifying custom labels for each IA in the desired display order (e.g., ‘list(IA1 = \"Target\", IA2 = \"Cohort\", IA3 = \"Rhyme\", IA4 = \"Unrelated\")’).\n\n\n\n\n\n\nA ggplot2 plot of the proportion of looks over time for each IA, optionally faceted by condition.\n\n\n\n\n\nResultInteractive\n\n\nlibrary(webgazeR)\n\n# Example with a condition column\nplot_IA_proportions(gaze_data, ia_column = \"condition\", time_column = \"time_ms\",\n                    proportion_column = \"proportion_looks\", condition_column = \"condition\",\n                    ia_mapping = list(IA1 = \"Target\", IA2 = \"Cohort\", IA3 = \"Rhyme\", IA4 = \"Unrelated\"))\n\n# Example without a condition column\nplot_IA_proportions(gaze_data, ia_column = \"condition\", time_column = \"time_ms\",\n                    proportion_column = \"proportion_looks\",\n                    ia_mapping = list(IA1 = \"Target\", IA2 = \"Cohort\", IA3 = \"Rhyme\", IA4 = \"Unrelated\"))\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.",
    "crumbs": [
      "Reference",
      "plot_IA_proportions"
    ]
  },
  {
    "objectID": "vignettes/webgazeR_vignette.html",
    "href": "vignettes/webgazeR_vignette.html",
    "title": "Introduction to webgazeR",
    "section": "",
    "text": "Here I outline the basic functions of the webgazeR package. I am using quarto-webr which allows for code to be run interactively in your browser!",
    "crumbs": [
      "Articles",
      "Introduction to webgazeR"
    ]
  },
  {
    "objectID": "vignettes/webgazeR_vignette.html#packages",
    "href": "vignettes/webgazeR_vignette.html#packages",
    "title": "Introduction to webgazeR",
    "section": "Packages",
    "text": "Packages\nBelow are the basic packages needed to run this vignette. The below code chunks will load in the packages needed.\n\n\nResultInteractive\n\n\noptions(stringsAsFactors = F)          # no automatic data transformation\noptions(\"scipen\" = 100, \"digits\" = 10) # suppress math annotation\nlibrary(tidyverse) \nlibrary(here) # relative paths instead of abosoulte aids in reproduce\nlibrary(tinytable) # nice tables\nlibrary(janitor)# functions for cleaning up your column names\nlibrary(easystats)\nlibrary(knitr)\nlibrary(ggokabeito)\ninstall.packages('webgazeR', repos = c('https://jgeller112.r-universe.dev', 'https://cloud.r-project.org'))\n\n\nThe downloaded binary packages are in\n    /var/folders/b6/cndg9nj53jnfy45qtx6h533r0000gs/T//RtmplteiZE/downloaded_packages\n\nlibrary(webgazeR)\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\nLoad webgazeR\n\nFirst you must install it via Github.\n\n\n\nResultInteractive\n\n\n# do not run interactively\nremotes::install_github(\"https://github.com/jgeller112/webgazeR\")\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\nThen you can load it into your session\n\n\n\nResultInteractive\n\n\n# load the package\nlibrary(webgazeR)\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.",
    "crumbs": [
      "Articles",
      "Introduction to webgazeR"
    ]
  },
  {
    "objectID": "vignettes/webgazeR_vignette.html#eye-data",
    "href": "vignettes/webgazeR_vignette.html#eye-data",
    "title": "Introduction to webgazeR",
    "section": "Eye data",
    "text": "Eye data\nWhen data is generated from Gorilla, each trial in your experiment is its own file. Because of this, we need to take all the individual files and merge them together. The merge_webcam_files function merges each trial from each participant into a single tibble or dataframe. Before running the merge_webcam_files function, ensure that your working directory is set to where the files are stored. This function reads in all the .xlsx files, binds them together into one dataframe, and cleans up the column names. The function then filters the data to include only rows where the type is “prediction” and the screen_index matches the specified value (in our case, screen 4). This is where eye-tracking data was recorded. The function renames the spreadsheet_row column to trial and sets both trial and subjectas factors for further analysis in our pipeline. As a note, all steps should be followed in order due to the renaming of column names. If you encounter an error it might be because column names have not been changed.\n\n\nResultInteractive\n\n\n# Get the list of all files in the folder\nvwp_files  &lt;- list.files(here::here(\"data\", \"monolinguals\", \"raw\"), pattern = \"\\\\.xlsx$\", full.names = TRUE)\n\n# Exclude files that contain \"calibration\" in their filename\nvwp_paths_filtered &lt;- vwp_files[!grepl(\"calibration\", vwp_files)]\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\nResultInteractive\n\n\nsetwd(here::here(\"data\", \"monolinguals\", \"raw\")) # set working directory to raw data folder\n\nedat &lt;- merge_webcam_files(vwp_paths_filtered, screen_index=4) # eye tracking occured ons creen index 4\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\nthe webgazeR package includes a combined dataset for us to use.\n\n\nResultInteractive\n\n\nedat &lt;- webgazeR::eyedata\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\nBehavioral Data\nGorilla produces a .csv file that include trial-level information (agg_ege_data). Below we read that object in and create an object called emstr that selects useful columns from that file and renames stimuli to make them more intuitive. Because most of this will be user-specific, no function is called here.\n\n\nResultInteractive\n\n\n# load in trial level data\nagg_eye_data &lt;- webgazeR::behav_data\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\nBelow we describe the pre-processing done on the behavioral data file. The below code processes and transforms the agg_eye_data dataset into a cleaned and structured format for further analysis. First, the code renames several columns for easier access using the janitor::clean_names function. It filters the dataset to include only rows where zone_type is “response_button_image”, representing the picture selected for that trial. Afterward, the function renames additional columns (tlpic to TL, trpic to TR, etc.). We also renamed participant_private_id to subject, spreadsheet_row to trial, and reaction_time to RT. This makes our columns consistent with the edat above for merging later on. Lastly, the `reaction time (RT) is converted to a numeric format for further numerical analysis.\n\n\nResultInteractive\n\n\nemstr &lt;- agg_eye_data %&gt;%\n  \n  janitor::clean_names() %&gt;%\n  \n  # Select specific columns to keep in the dataset\n  dplyr::select(participant_private_id,  correct, tlpic, trpic, blpic, brpic, trialtype, targetword, tlcode, trcode, blcode, brcode, zone_name, zone_type,reaction_time, spreadsheet_row, response) %&gt;%\n  \n  # Filter the rows where 'Zone.Type' equals \"response_button_image\"\n  dplyr::filter(zone_type == \"response_button_image\") %&gt;%\n  \n  # Rename columns for easier use and readability\n  dplyr::rename(\n    \"TL\" = \"tlpic\",              # Rename 'tlpic' to 'TL'\n    \"TR\" = \"trpic\",             # Rename 'trpic' to 'TR'\n    \"BL\" = \"blpic\",            # Rename 'blpic' to 'BL'\n    \"BR\" = \"brpic\",                # Rename 'brpic' to 'BR'\n    \"targ_loc\" = \"zone_name\",       # Rename 'Zone.Name' to 'targ_loc'\n    \"subject\" = \"participant_private_id\",  # Rename 'Participant.Private.ID' to 'subject'\n    \"trial\" = \"spreadsheet_row\",    # Rename 'spreadsheet_row' to 'trial'\n    \"acc\" = \"correct\",              # Rename 'Correct' to 'acc' (accuracy)\n    \"RT\" = \"reaction_time\"          # Rename 'Reaction.Time' to 'RT'\n  ) %&gt;%\n  \n  # Convert the 'RT' (Reaction Time) column to numeric type\n  mutate(RT = as.numeric(RT), \n         subject=as.factor(subject), \n         trial=as.factor(trial))\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\nGet audio onset time\nBecause we are using audio on each trial and we are running this experiment for the browser audio onset is never going to to conistent across participants. In Gorilla there is an option to collect advanced audio features such as when the audio play was requested, fired (played) and ended. We will want to incorporate this into our pipeline. Gorilla records the onset of the audio which varies by participant. We are extracting that here by filtering zone_type to content_web_audio and response equal to “AUDIO PLAY EVENT FIRED”. This will tell us when the audio was triggered in the experiment (reaction_time).\n\n\nResultInteractive\n\n\naudio_rt &lt;- agg_eye_data %&gt;%\n  \n  janitor::clean_names()%&gt;% \n\nselect(participant_private_id,zone_type, spreadsheet_row, reaction_time, response) %&gt;%\n\n  filter(zone_type==\"content_web_audio\", response==\"AUDIO PLAY EVENT FIRED\")%&gt;%\n  distinct() %&gt;%\nrename(\"subject\" = \"participant_private_id\", \n       \"trial\" =\"spreadsheet_row\",  \n       \"RT_audio\" = \"reaction_time\") %&gt;%\nselect(-zone_type) %&gt;%\nmutate(RT_audio=as.numeric(RT_audio))\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\nWe then merge this information with emstr. We see that RT_audio has been added to our dataframe.\n\n\nResultInteractive\n\n\ntrial_data_rt &lt;- merge(emstr, audio_rt, by=c(\"subject\", \"trial\"))\n\nhead(trial_data_rt) %&gt;%\n  head() %&gt;%\n  kable()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsubject\ntrial\nacc\nTL\nTR\nBL\nBR\ntrialtype\ntargetword\ntlcode\ntrcode\nblcode\nbrcode\ntarg_loc\nzone_type\nRT\nresponse.x\nRT_audio\nresponse.y\n\n\n\n\n11788555\n10\n1\nsunrise.jpg\npillar.jpg\npillow.jpg\nwillow.jpg\nTRUU\nwillow.jpg\nR\nU\nU2\nT\nBR\nresponse_button_image\n1822.1999998\nwillow.jpg\n17.09999990\nAUDIO PLAY EVENT FIRED\n\n\n11788555\n103\n1\ncap.jpg\nhose.jpg\ngoal.jpg\nhole.jpg\nTCUU\nhose.jpg\nU\nT\nU2\nC\nTR\nresponse_button_image\n1467.0000000\nhose.jpg\n10.59999990\nAUDIO PLAY EVENT FIRED\n\n\n11788555\n104\n0\nhip.jpg\ncave.jpg\ncage.jpg\ngauge.jpg\nTCRU\ncage.jpg\nU\nC\nT\nR\nTR\nresponse_button_image\n929.8999996\ncave.jpg\n17.89999962\nAUDIO PLAY EVENT FIRED\n\n\n11788555\n106\n1\npear.jpg\nbear.jpg\njet.jpg\nbase.jpg\nTUUU\njet.jpg\nU3\nU\nT\nU2\nBL\nresponse_button_image\n1661.4000001\njet.jpg\n12.00000000\nAUDIO PLAY EVENT FIRED\n\n\n11788555\n107\n1\nbeagle.jpg\nmother.jpg\nmoney.jpg\nhoney.jpg\nTCUU\nmother.jpg\nU\nT\nC\nU2\nTR\nresponse_button_image\n1513.5999999\nmother.jpg\n15.90000010\nAUDIO PLAY EVENT FIRED\n\n\n11788555\n108\n1\nparrot.jpg\ncarrot.jpg\ncarriage.jpg\ntadpole.jpg\nTCRU\ncarrot.jpg\nR\nT\nC\nU\nTR\nresponse_button_image\n1456.8000002\ncarrot.jpg\n16.00000000\nAUDIO PLAY EVENT FIRED\n\n\n\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\nSampling Rate\nWhile most commercial eye-trackers sample at a constant rate, webcam eye-trackers do not. Below is some code to calculate the sampling rate of each participant. Ideally, you should not have a sampling rate less than 5 Hz. It has been recommended you drop those values. The below function analyze_sample_rate calculates calculates the sampling rate for each subject and trial in an eye-tracking dataset. It provides overall statistics, including the median and standard deviation of sampling rates in your experiment,and also generates a histogram of median sampling rates by subject with a density plot overlayed.\n\n\nResultInteractive\n\n\nsamp_rate &lt;- analyze_sampling_rate(edat)\n\nOverall Median Sampling Rate (Hz): 24.76936956 \nOverall Standard Deviation of Sampling Rate (Hz): 7.807913315 \n\nSampling Rate by Trial:\n# A tibble: 3,122 × 5\n# Groups:   subject [23]\n    subject trial max_time n_times    SR\n      &lt;int&gt; &lt;int&gt;    &lt;dbl&gt;   &lt;int&gt; &lt;dbl&gt;\n 1 11788555     7    3664.     107  29.2\n 2 11788555     8    1295       39  30.1\n 3 11788555     9    2298.      68  29.6\n 4 11788555    10    1743.      52  29.8\n 5 11788555    12    1741.      52  29.9\n 6 11788555    13    1365.      40  29.3\n 7 11788555    15    1404.      40  28.5\n 8 11788555    16    1714.      51  29.8\n 9 11788555    21    1584.      47  29.7\n10 11788555    27    2103.      62  29.5\n# ℹ 3,112 more rows\n\nMedian Sampling Rate by Subject:\n# A tibble: 23 × 2\n    subject med_SR\n      &lt;int&gt;  &lt;dbl&gt;\n 1 11788555  29.6 \n 2 11788682  29.7 \n 3 11788824  23.9 \n 4 11788857   8.79\n 5 11789574  11.5 \n 6 11795362  22.6 \n 7 11795372  24.8 \n 8 11795375  28.5 \n 9 11795376  29.9 \n10 11795379  30.4 \n# ℹ 13 more rows\n\n\n\n\n\n\n\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\nIn this example, we have a median sampling rate of 24.77 with a SD of 7.81.\nWhen using the above function, separate data frames are produced for subjects and trials. These can be added to the behavioral data object and this merge process is documented below.\n\n\nResultInteractive\n\n\n# Extract by-subject and by-trial sampling rates from the result\nsubject_sampling_rate &lt;- samp_rate$median_SR_by_subject  # Sampling rate by subject\ntrial_sampling_rate &lt;- samp_rate$SR_by_trial  # Sampling rate by trial\ntrial_sampling_rate$subject&lt;-as.factor(trial_sampling_rate$subject)\n\n# Assuming target_data is your other dataset that contains subject and trial information\n# Append the by-subject sampling rate to target_data (based on subject)\nsubject_sampling_rate$subject &lt;- as.factor(subject_sampling_rate$subject)\n\ntarget_data_with_subject_SR &lt;- trial_data_rt %&gt;%\n  left_join(subject_sampling_rate, by = \"subject\")\n\n# Append the by-trial sampling rate to target_data (based on subject and trial)\n\n\ntrial_sampling_rate$trial &lt;- as.factor(trial_sampling_rate$trial)\n\n\ntarget_data_with_full_SR &lt;- target_data_with_subject_SR %&gt;%\n  select(subject, trial, med_SR)%&gt;%\n  left_join(trial_sampling_rate, by = c(\"subject\", \"trial\"))\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\nWe can add this to our behavioral data\n\n\nResultInteractive\n\n\ntrial_data &lt;- left_join(trial_data_rt, target_data_with_full_SR, by=c(\"subject\", \"trial\"))\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\nUsers can use the filter_sampling_rate function to either either (1) throw out data, by subject, by trial, or both, and (2) label it sampling rates below a certain threshold as bad (TRUE or FALSE). Let’s use the filter_sampling_rate() function to do this. We will read in our target_data_with_full_SR object.\nWe leave it up to the user to decide what to do and make no specific recommendations. In our case we are going to remove the data by subject and by trial (action==“both”) if sampling frequency is below 5hz (threshold=5). The filter_sampling_rate function is designed to process a dataset containing subject-level and trial-level sampling rates. It allows the user to either filter out data that falls below a certain sampling rate threshold or simply label it as “bad”. The function gives flexibility by allowing the threshold to be applied at the subject level, trial level, or both. It also lets the user decide whether to remove the data or flag it as below the threshold without removing it. If action = remove, the function will output how many subjects and trials were removed by on the threshold.\n\n\nResultInteractive\n\n\nfilter_edat &lt;- filter_sampling_rate(trial_data,threshold = 5, \n                                         action = \"remove\", \n                                         by = \"both\")\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\nfilter_edat returns a dataframe with trials and subjects removed. If we set the argument action to label, filter_edat_label would return a dataframe that includes column(s) with sampling rates &lt; 5 labeled as TRUE (bad) or FALSE\n\n\nResultInteractive\n\n\nfilter_edat_label &lt;- filter_sampling_rate(trial_data,threshold = 5, \n                                         action = \"label\", \n                                         by=\"both\")\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\nHere no subjects had a threshold below 5. However, 18 trials did, and they were removed.\n\n\nOut-of-bounds (outside of screen)\nIt is important that we do not include points that fall outside the standardized coordinates. The gaze_oob function calculates how many of the data points fall outside the standardized range. This function returns how many data points fall outside this range by subject and provides a percentage. This information would be useful to include in the final paper. We then add by-subject and by-trial out of bounds data and exclude participants and trials with &gt; 30% missing data.\n\n\nResultInteractive\n\n\noob_data &lt;- gaze_oob(edat)\n\nSubject: 11788555\nTotal points: 2483\nPoints outside the range: 608\nTotal missing percentage: 24.49%\nX: 17.28%\nY: 13.53%\n\n\nSubject: 11788682\nTotal points: 5798\nPoints outside the range: 551\nTotal missing percentage: 9.5%\nX: 6.83%\nY: 3.47%\n\n\nSubject: 11788824\nTotal points: 6961\nPoints outside the range: 1792\nTotal missing percentage: 25.74%\nX: 17.14%\nY: 13.37%\n\n\nSubject: 11788857\nTotal points: 2237\nPoints outside the range: 277\nTotal missing percentage: 12.38%\nX: 11.85%\nY: 1.3%\n\n\nSubject: 11789574\nTotal points: 932\nPoints outside the range: 221\nTotal missing percentage: 23.71%\nX: 14.16%\nY: 16.09%\n\n\nSubject: 11795362\nTotal points: 3951\nPoints outside the range: 608\nTotal missing percentage: 15.39%\nX: 10%\nY: 7.69%\n\n\nSubject: 11795372\nTotal points: 4598\nPoints outside the range: 677\nTotal missing percentage: 14.72%\nX: 9.11%\nY: 8.22%\n\n\nSubject: 11795375\nTotal points: 6795\nPoints outside the range: 1008\nTotal missing percentage: 14.83%\nX: 11.18%\nY: 6.99%\n\n\nSubject: 11795376\nTotal points: 6749\nPoints outside the range: 1676\nTotal missing percentage: 24.83%\nX: 13.48%\nY: 16.42%\n\n\nSubject: 11795379\nTotal points: 2247\nPoints outside the range: 350\nTotal missing percentage: 15.58%\nX: 4.36%\nY: 12.28%\n\n\nSubject: 11795382\nTotal points: 5239\nPoints outside the range: 528\nTotal missing percentage: 10.08%\nX: 6.91%\nY: 5.99%\n\n\nSubject: 11795385\nTotal points: 6172\nPoints outside the range: 1557\nTotal missing percentage: 25.23%\nX: 14.52%\nY: 15.83%\n\n\nSubject: 11795386\nTotal points: 4658\nPoints outside the range: 1397\nTotal missing percentage: 29.99%\nX: 17%\nY: 22.33%\n\n\nSubject: 11795387\nTotal points: 3634\nPoints outside the range: 586\nTotal missing percentage: 16.13%\nX: 9.41%\nY: 9.25%\n\n\nSubject: 11795388\nTotal points: 4097\nPoints outside the range: 755\nTotal missing percentage: 18.43%\nX: 11.33%\nY: 11.11%\n\n\nSubject: 11795426\nTotal points: 1242\nPoints outside the range: 122\nTotal missing percentage: 9.82%\nX: 6.44%\nY: 6.44%\n\n\nSubject: 11795446\nTotal points: 6712\nPoints outside the range: 546\nTotal missing percentage: 8.13%\nX: 5.91%\nY: 4.68%\n\n\nSubject: 11795529\nTotal points: 4668\nPoints outside the range: 482\nTotal missing percentage: 10.33%\nX: 6.92%\nY: 4.86%\n\n\nSubject: 11795650\nTotal points: 2213\nPoints outside the range: 101\nTotal missing percentage: 4.56%\nX: 2.08%\nY: 2.89%\n\n\nSubject: 11795671\nTotal points: 4982\nPoints outside the range: 1438\nTotal missing percentage: 28.86%\nX: 18.15%\nY: 17.7%\n\n\nSubject: 11796749\nTotal points: 6469\nPoints outside the range: 1891\nTotal missing percentage: 29.23%\nX: 23.09%\nY: 13.48%\n\n\nSubject: 11796756\nTotal points: 6249\nPoints outside the range: 820\nTotal missing percentage: 13.12%\nX: 7.25%\nY: 8.64%\n\n\nSubject: 11796779\nTotal points: 5737\nPoints outside the range: 253\nTotal missing percentage: 4.41%\nX: 2.18%\nY: 2.75%\n\noob_data %&gt;% \n  tt()\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                subject\n                total_points\n                outside_count\n                total_missing_percentage\n                x_outside_count\n                y_outside_count\n                x_outside_percentage\n                y_outside_percentage\n              \n        \n        \n        \n                \n                  11788555\n                  2483\n                   608\n                  24.486508256\n                   429\n                   336\n                  17.277486911\n                  13.532017720\n                \n                \n                  11788682\n                  5798\n                   551\n                   9.503276992\n                   396\n                   201\n                   6.829941359\n                   3.466712660\n                \n                \n                  11788824\n                  6961\n                  1792\n                  25.743427668\n                  1193\n                   931\n                  17.138342192\n                  13.374515156\n                \n                \n                  11788857\n                  2237\n                   277\n                  12.382655342\n                   265\n                    29\n                  11.846222620\n                   1.296379079\n                \n                \n                  11789574\n                   932\n                   221\n                  23.712446352\n                   132\n                   150\n                  14.163090129\n                  16.094420601\n                \n                \n                  11795362\n                  3951\n                   608\n                  15.388509238\n                   395\n                   304\n                   9.997468995\n                   7.694254619\n                \n                \n                  11795372\n                  4598\n                   677\n                  14.723792953\n                   419\n                   378\n                   9.112657677\n                   8.220965637\n                \n                \n                  11795375\n                  6795\n                  1008\n                  14.834437086\n                   760\n                   475\n                  11.184694628\n                   6.990434143\n                \n                \n                  11795376\n                  6749\n                  1676\n                  24.833308638\n                   910\n                  1108\n                  13.483479034\n                  16.417247000\n                \n                \n                  11795379\n                  2247\n                   350\n                  15.576323988\n                    98\n                   276\n                   4.361370717\n                  12.283044059\n                \n                \n                  11795382\n                  5239\n                   528\n                  10.078259210\n                   362\n                   314\n                   6.909715595\n                   5.993510212\n                \n                \n                  11795385\n                  6172\n                  1557\n                  25.226830849\n                   896\n                   977\n                  14.517174336\n                  15.829552819\n                \n                \n                  11795386\n                  4658\n                  1397\n                  29.991412623\n                   792\n                  1040\n                  17.003005582\n                  22.327179047\n                \n                \n                  11795387\n                  3634\n                   586\n                  16.125481563\n                   342\n                   336\n                   9.411117226\n                   9.246009906\n                \n                \n                  11795388\n                  4097\n                   755\n                  18.428118135\n                   464\n                   455\n                  11.325360020\n                  11.105687088\n                \n                \n                  11795426\n                  1242\n                   122\n                   9.822866345\n                    80\n                    80\n                   6.441223833\n                   6.441223833\n                \n                \n                  11795446\n                  6712\n                   546\n                   8.134684148\n                   397\n                   314\n                   5.914779499\n                   4.678188319\n                \n                \n                  11795529\n                  4668\n                   482\n                  10.325621251\n                   323\n                   227\n                   6.919451585\n                   4.862896315\n                \n                \n                  11795650\n                  2213\n                   101\n                   4.563940352\n                    46\n                    64\n                   2.078626299\n                   2.892001808\n                \n                \n                  11795671\n                  4982\n                  1438\n                  28.863910076\n                   904\n                   882\n                  18.145323163\n                  17.703733440\n                \n                \n                  11796749\n                  6469\n                  1891\n                  29.231720513\n                  1494\n                   872\n                  23.094759623\n                  13.479672283\n                \n                \n                  11796756\n                  6249\n                   820\n                  13.122099536\n                   453\n                   540\n                   7.249159866\n                   8.641382621\n                \n                \n                  11796779\n                  5737\n                   253\n                   4.409970368\n                   125\n                   158\n                   2.178839115\n                   2.754052641\n                \n        \n      \n    \n\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\nZone coordinates\nIn the lab, we can control every aspect of the experiment. Online we cant do this. Participants are going to be completing the experiment under a variety of conditions. This includes using different computers, with very different screen dimensions. To control for this, Gorilla outputs standardized zone coordinates. As discussed in the Gorilla documentation, the Gorilla layout engine lays everything out in a 4:3 frame and makes that frame as big as possible. The normalized coordinates are then expressed relative to this frame; for example, the coordinate 0.5, 0.5 will always be the center of the screen, regardless of the size of the participant’s screen. We used the normalized coordinates in our analysis. However, there are a few different ways to specify the four coordinates of the screen, which I think is worth highlighting.\n\nQuadrant Approach\nOne way is to make the AOIs as big as possible and place them in the four quadrants of the screen. What we will need to first is create a dataframe with location of the AOI (e.g., TL, TR, BL, BR), x and y normalized coordinates and width and height normalized. In addition, we will get the xmin, xmanx, and ymax and ymin of the AOIs.\n\n\nResultInteractive\n\n\n# Create a data frame for the quadrants with an added column for the quadrant labels\naoi_loc &lt;- data.frame(\n  loc = c('TL', 'TR', 'BL', 'BR'), \n  x_normalized = c(0, 0.5, 0, 0.5),\n   y_normalized = c(0.5, 0.5, 0, 0),\n  width_normalized = c(0.5, 0.5, 0.5, 0.5),\n  height_normalized = c(0.5, 0.5, 0.5, 0.5)) %&gt;% \n  \n  mutate(xmin = x_normalized, ymin = y_normalized,\n         xmax = x_normalized+width_normalized,\n         ymax = y_normalized+height_normalized)\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nloc\nx_normalized\ny_normalized\nwidth_normalized\nheight_normalized\nxmin\nymin\nxmax\nymax\n\n\n\n\nTL\n0.0\n0.5\n0.5\n0.5\n0.0\n0.5\n0.5\n1.0\n\n\nTR\n0.5\n0.5\n0.5\n0.5\n0.5\n0.5\n1.0\n1.0\n\n\nBL\n0.0\n0.0\n0.5\n0.5\n0.0\n0.0\n0.5\n0.5\n\n\nBR\n0.5\n0.0\n0.5\n0.5\n0.5\n0.0\n1.0\n0.5\n\n\n\n\n\n\n\n\nClean-up eye data\nHere we are going to remove poor convergence scales and confidence. We will also remove coordinates that are 0 in our data.\n\n\nResultInteractive\n\n\nedat_1 &lt;- edat %&gt;%\n dplyr::filter(convergence &lt;= .5, face_conf &gt;= .5) %&gt;%\n  # remove rows without gaze information\n  dplyr::filter(x_pred_normalised != 0,\n                y_pred_normalised != 0) \n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\n\nCombining Eye and Trial-level data\nNext we are going to combine the eye-tracking data and behavioral data by using the left_join function.\n\n\nResultInteractive\n\n\nedat_1$subject&lt;-as.factor(edat_1$subject)\nedat_1$trial&lt;-as.factor(edat_1$trial)\n\n\n\ndat &lt;- left_join(edat_1, filter_edat, by = c(\"subject\",\"trial\"))\n\ndat &lt;- dat %&gt;%\n  distinct() # make sure to remove duplicate rows\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\nLet’s verify our AOIs look how they are suppose to.\n\n\n\n\n\n\n\n\n\n\n\n\n\nExcellent!\n\n\nMatching conditions with screen locations\nIn this experiment we have four different trial types:\n\nTarget, Cohort, Rhyme, Unrealted\nTarget, Cohort, Unrealted, Unrelated\nTarget, Unrelated, Unrealted, Unrelated\nTarget, Rhyme, Unrelated, Unrelated\n\nWe will first match the pictures in the TL, TR, BL, BR columns to the correct code condition (T,C, R, U, U2, U3).\n\n\nResultInteractive\n\n\n# Assuming your data is in a data frame called df\ndat &lt;- dat %&gt;%\n  mutate(\n    Target = case_when(\n      tlcode == \"T\" ~ TL,\n      trcode == \"T\" ~ TR,\n      blcode == \"T\" ~ BL,\n      brcode == \"T\" ~ BR,\n      TRUE ~ NA_character_  # Default to NA if no match\n    ),\n    Unrelated = case_when(\n      tlcode == \"U\" ~ TL,\n      trcode == \"U\" ~ TR,\n      blcode == \"U\" ~ BL,\n      brcode == \"U\" ~ BR,\n      TRUE ~ NA_character_\n    ),\n    Unrelated2 = case_when(\n      tlcode == \"U2\" ~ TL,\n      trcode == \"U2\" ~ TR,\n      blcode == \"U2\" ~ BL,\n      brcode == \"U2\" ~ BR,\n      TRUE ~ NA_character_\n    ),\n    Unrelated3 = case_when(\n      tlcode == \"U3\" ~ TL,\n      trcode == \"U3\" ~ TR,\n      blcode == \"U3\" ~ BL,\n      brcode == \"U3\" ~ BR,\n      TRUE ~ NA_character_\n    ),\n    Rhyme = case_when(\n      tlcode == \"R\" ~ TL,\n      trcode == \"R\" ~ TR,\n      blcode == \"R\" ~ BL,\n      brcode == \"R\" ~ BR,\n      TRUE ~ NA_character_\n    ),\n    Cohort = case_when(\n      tlcode == \"C\" ~ TL,\n      trcode == \"C\" ~ TR,\n      blcode == \"C\" ~ BL,\n      brcode == \"C\" ~ BR,\n      TRUE ~ NA_character_\n    )\n  )\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\n\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                X\n                x0\n                filename\n                trial\n                time_stamp\n                time\n                type\n                screen_index\n                x_pred\n                y_pred\n                x_pred_normalised\n                y_pred_normalised\n                convergence\n                face_conf\n                zone_name\n                zone_x\n                zone_y\n                zone_width\n                zone_height\n                zone_x_normalised\n                zone_y_normalised\n                zone_width_normalised\n                zone_height_normalised\n                subject\n                acc\n                TL\n                TR\n                BL\n                BR\n                trialtype\n                targetword\n                tlcode\n                trcode\n                blcode\n                brcode\n                targ_loc\n                zone_type\n                RT\n                response.x\n                RT_audio\n                response.y\n                med_SR\n                max_time\n                n_times\n                SR\n                Target\n                Unrelated\n                Unrelated2\n                Unrelated3\n                Rhyme\n                Cohort\n              \n        \n        \n        \n                \n                  1\n                  NA\n                  eyetracking_collection\n                  153\n                  1727868218964\n                    0.00000000\n                  prediction\n                  4\n                   921.5823073\n                  -61.68745669\n                  0.4717325812\n                  -0.06077581940\n                  0\n                  1\n                  NA\n                  0\n                  0\n                  0\n                  0\n                  0\n                  0\n                  0\n                  0\n                  11788555\n                  1\n                  candle.jpg\n                  sandal.jpg\n                  sandwich.jpg\n                  building.jpg\n                  TCUU\n                  sandwich.jpg\n                  U2\n                  C\n                  T\n                  U\n                  BL\n                  response_button_image\n                  1997.8\n                  sandwich.jpg\n                  13.0999999\n                  AUDIO PLAY EVENT FIRED\n                  29.63857024\n                  1922.4\n                  57\n                  29.65043695\n                  sandwich.jpg\n                  building.jpg\n                  candle.jpg\n                  NA\n                  NA\n                  sandal.jpg\n                \n                \n                  2\n                  NA\n                  eyetracking_collection\n                  153\n                  1727868218999\n                   34.00000000\n                  prediction\n                  4\n                   958.2899489\n                   78.26706763\n                  0.4988631366\n                   0.07711041146\n                  0\n                  1\n                  NA\n                  0\n                  0\n                  0\n                  0\n                  0\n                  0\n                  0\n                  0\n                  11788555\n                  1\n                  candle.jpg\n                  sandal.jpg\n                  sandwich.jpg\n                  building.jpg\n                  TCUU\n                  sandwich.jpg\n                  U2\n                  C\n                  T\n                  U\n                  BL\n                  response_button_image\n                  1997.8\n                  sandwich.jpg\n                  13.0999999\n                  AUDIO PLAY EVENT FIRED\n                  29.63857024\n                  1922.4\n                  57\n                  29.65043695\n                  sandwich.jpg\n                  building.jpg\n                  candle.jpg\n                  NA\n                  NA\n                  sandal.jpg\n                \n                \n                  3\n                  NA\n                  eyetracking_collection\n                  153\n                  1727868219039\n                   73.30000019\n                  prediction\n                  4\n                  1036.1006719\n                  247.37493626\n                  0.5563729098\n                   0.24371914902\n                  0\n                  1\n                  NA\n                  0\n                  0\n                  0\n                  0\n                  0\n                  0\n                  0\n                  0\n                  11788555\n                  1\n                  candle.jpg\n                  sandal.jpg\n                  sandwich.jpg\n                  building.jpg\n                  TCUU\n                  sandwich.jpg\n                  U2\n                  C\n                  T\n                  U\n                  BL\n                  response_button_image\n                  1997.8\n                  sandwich.jpg\n                  13.0999999\n                  AUDIO PLAY EVENT FIRED\n                  29.63857024\n                  1922.4\n                  57\n                  29.65043695\n                  sandwich.jpg\n                  building.jpg\n                  candle.jpg\n                  NA\n                  NA\n                  sandal.jpg\n                \n                \n                  4\n                  NA\n                  eyetracking_collection\n                  153\n                  1727868219076\n                  113.09999990\n                  prediction\n                  4\n                  1048.4626414\n                  383.69717600\n                  0.5655096204\n                   0.37802677438\n                  0\n                  1\n                  NA\n                  0\n                  0\n                  0\n                  0\n                  0\n                  0\n                  0\n                  0\n                  11788555\n                  1\n                  candle.jpg\n                  sandal.jpg\n                  sandwich.jpg\n                  building.jpg\n                  TCUU\n                  sandwich.jpg\n                  U2\n                  C\n                  T\n                  U\n                  BL\n                  response_button_image\n                  1997.8\n                  sandwich.jpg\n                  13.0999999\n                  AUDIO PLAY EVENT FIRED\n                  29.63857024\n                  1922.4\n                  57\n                  29.65043695\n                  sandwich.jpg\n                  building.jpg\n                  candle.jpg\n                  NA\n                  NA\n                  sandal.jpg\n                \n                \n                  5\n                  NA\n                  eyetracking_collection\n                  153\n                  1727868219111\n                  148.40000010\n                  prediction\n                  4\n                  1018.1750413\n                  433.21330043\n                  0.5431241067\n                   0.42681113343\n                  0\n                  1\n                  NA\n                  0\n                  0\n                  0\n                  0\n                  0\n                  0\n                  0\n                  0\n                  11788555\n                  1\n                  candle.jpg\n                  sandal.jpg\n                  sandwich.jpg\n                  building.jpg\n                  TCUU\n                  sandwich.jpg\n                  U2\n                  C\n                  T\n                  U\n                  BL\n                  response_button_image\n                  1997.8\n                  sandwich.jpg\n                  13.0999999\n                  AUDIO PLAY EVENT FIRED\n                  29.63857024\n                  1922.4\n                  57\n                  29.65043695\n                  sandwich.jpg\n                  building.jpg\n                  candle.jpg\n                  NA\n                  NA\n                  sandal.jpg\n                \n                \n                  6\n                  NA\n                  eyetracking_collection\n                  153\n                  1727868219145\n                  182.00000000\n                  prediction\n                  4\n                  1040.6113826\n                  514.57934044\n                  0.5597067684\n                   0.50697471965\n                  0\n                  1\n                  NA\n                  0\n                  0\n                  0\n                  0\n                  0\n                  0\n                  0\n                  0\n                  11788555\n                  1\n                  candle.jpg\n                  sandal.jpg\n                  sandwich.jpg\n                  building.jpg\n                  TCUU\n                  sandwich.jpg\n                  U2\n                  C\n                  T\n                  U\n                  BL\n                  response_button_image\n                  1997.8\n                  sandwich.jpg\n                  13.0999999\n                  AUDIO PLAY EVENT FIRED\n                  29.63857024\n                  1922.4\n                  57\n                  29.65043695\n                  sandwich.jpg\n                  building.jpg\n                  candle.jpg\n                  NA\n                  NA\n                  sandal.jpg\n                \n        \n      \n    \n\n\n\n\n\nIn our study, we need to track not only the condition of each image shown (such as Target, Cohort, Rhyme, or Unrelated) but also where each image is located on the screen during each trial as they are randomized on each trial. To do this, we use a function named find_location. This function is designed to determine the location of a specific image on the screen by comparing the image with the list of possible locations.\nThe function find_location first checks if the image is NA (missing). If the image is NA, the function returns NA, meaning that there’s no location to find for this image. If the image is not NA, the function creates a vector loc_names that lists the names of the possible locations. It then attempts to match the given image with the locations. If a match is found, it returns the name of the location (e.g., TL, TR, BL, or BR) where the image is located. If there is no match, the function returns NA.\n\n\nResultInteractive\n\n\n# Apply the function to each of the targ, cohort, rhyme, and unrelated columns\ndat_colnames &lt;- dat %&gt;%\n  rowwise() %&gt;%\n  mutate(\n    targ_loc = find_location(c(TL, TR, BL, BR), Target),\n    cohort_loc = find_location(c(TL, TR, BL, BR), Cohort),\n    rhyme_loc = find_location(c(TL, TR, BL, BR), Rhyme),\n    unrelated_loc = find_location(c(TL, TR, BL, BR), Unrelated), \n    unrealted2_loc= find_location(c(TL, TR, BL, BR), Unrelated2), \n    unrelated3_loc=find_location(c(TL, TR, BL, BR), Unrelated3)\n  ) %&gt;%\n  ungroup()\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\nHere is where we are going to use our coordinate information from above. We use the assign_aoi that is adaopted from the gazeR package (Geller et al., 2020) to loop through our object dat_colnames and assign locations (i.e., TR, TL, BL, BR) to our normalized x and y coordinates. This function will label non-looks and off screen coordinates with NA. To make it easier to read we change the numerals assigned by the function to actual screen locations.\n\n\nResultInteractive\n\n\nassign &lt;- assign_aoi(dat_colnames,X=\"x_pred_normalised\", Y=\"y_pred_normalised\",aoi_loc = aoi_loc)\n\n\nAOI &lt;- assign %&gt;%\n\n  mutate(loc1 = case_when(\n\n    AOI==1 ~ \"TL\", \n\n    AOI==2 ~ \"TR\", \n\n    AOI==3 ~ \"BL\", \n\n    AOI==4 ~ \"BR\"\n\n  ))\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nX\nx0\nfilename\ntrial\ntime_stamp\ntime\ntype\nscreen_index\nx_pred\ny_pred\nx_pred_normalised\ny_pred_normalised\nconvergence\nface_conf\nzone_name\nzone_x\nzone_y\nzone_width\nzone_height\nzone_x_normalised\nzone_y_normalised\nzone_width_normalised\nzone_height_normalised\nsubject\nacc\nTL\nTR\nBL\nBR\ntrialtype\ntargetword\ntlcode\ntrcode\nblcode\nbrcode\ntarg_loc\nzone_type\nRT\nresponse.x\nRT_audio\nresponse.y\nmed_SR\nmax_time\nn_times\nSR\nTarget\nUnrelated\nUnrelated2\nUnrelated3\nRhyme\nCohort\ncohort_loc\nrhyme_loc\nunrelated_loc\nunrealted2_loc\nunrelated3_loc\nAOI\nloc1\n\n\n\n\n1\nNA\neyetracking_collection\n153\n1727868218964\n0.00000000\nprediction\n4\n921.5823073\n-61.68745669\n0.4717325812\n-0.0607758194\n0\n1\nNA\n0\n0\n0\n0\n0\n0\n0\n0\n11788555\n1\ncandle.jpg\nsandal.jpg\nsandwich.jpg\nbuilding.jpg\nTCUU\nsandwich.jpg\nU2\nC\nT\nU\nBL\nresponse_button_image\n1997.8\nsandwich.jpg\n13.0999999\nAUDIO PLAY EVENT FIRED\n29.63857024\n1922.4\n57\n29.65043695\nsandwich.jpg\nbuilding.jpg\ncandle.jpg\nNA\nNA\nsandal.jpg\nTR\nNA\nBR\nTL\nNA\nNA\nNA\n\n\n2\nNA\neyetracking_collection\n153\n1727868218999\n34.00000000\nprediction\n4\n958.2899489\n78.26706763\n0.4988631366\n0.0771104115\n0\n1\nNA\n0\n0\n0\n0\n0\n0\n0\n0\n11788555\n1\ncandle.jpg\nsandal.jpg\nsandwich.jpg\nbuilding.jpg\nTCUU\nsandwich.jpg\nU2\nC\nT\nU\nBL\nresponse_button_image\n1997.8\nsandwich.jpg\n13.0999999\nAUDIO PLAY EVENT FIRED\n29.63857024\n1922.4\n57\n29.65043695\nsandwich.jpg\nbuilding.jpg\ncandle.jpg\nNA\nNA\nsandal.jpg\nTR\nNA\nBR\nTL\nNA\n3\nBL\n\n\n3\nNA\neyetracking_collection\n153\n1727868219039\n73.30000019\nprediction\n4\n1036.1006719\n247.37493626\n0.5563729098\n0.2437191490\n0\n1\nNA\n0\n0\n0\n0\n0\n0\n0\n0\n11788555\n1\ncandle.jpg\nsandal.jpg\nsandwich.jpg\nbuilding.jpg\nTCUU\nsandwich.jpg\nU2\nC\nT\nU\nBL\nresponse_button_image\n1997.8\nsandwich.jpg\n13.0999999\nAUDIO PLAY EVENT FIRED\n29.63857024\n1922.4\n57\n29.65043695\nsandwich.jpg\nbuilding.jpg\ncandle.jpg\nNA\nNA\nsandal.jpg\nTR\nNA\nBR\nTL\nNA\n4\nBR\n\n\n4\nNA\neyetracking_collection\n153\n1727868219076\n113.09999990\nprediction\n4\n1048.4626414\n383.69717600\n0.5655096204\n0.3780267744\n0\n1\nNA\n0\n0\n0\n0\n0\n0\n0\n0\n11788555\n1\ncandle.jpg\nsandal.jpg\nsandwich.jpg\nbuilding.jpg\nTCUU\nsandwich.jpg\nU2\nC\nT\nU\nBL\nresponse_button_image\n1997.8\nsandwich.jpg\n13.0999999\nAUDIO PLAY EVENT FIRED\n29.63857024\n1922.4\n57\n29.65043695\nsandwich.jpg\nbuilding.jpg\ncandle.jpg\nNA\nNA\nsandal.jpg\nTR\nNA\nBR\nTL\nNA\n4\nBR\n\n\n5\nNA\neyetracking_collection\n153\n1727868219111\n148.40000010\nprediction\n4\n1018.1750413\n433.21330043\n0.5431241067\n0.4268111334\n0\n1\nNA\n0\n0\n0\n0\n0\n0\n0\n0\n11788555\n1\ncandle.jpg\nsandal.jpg\nsandwich.jpg\nbuilding.jpg\nTCUU\nsandwich.jpg\nU2\nC\nT\nU\nBL\nresponse_button_image\n1997.8\nsandwich.jpg\n13.0999999\nAUDIO PLAY EVENT FIRED\n29.63857024\n1922.4\n57\n29.65043695\nsandwich.jpg\nbuilding.jpg\ncandle.jpg\nNA\nNA\nsandal.jpg\nTR\nNA\nBR\nTL\nNA\n4\nBR\n\n\n6\nNA\neyetracking_collection\n153\n1727868219145\n182.00000000\nprediction\n4\n1040.6113826\n514.57934044\n0.5597067684\n0.5069747196\n0\n1\nNA\n0\n0\n0\n0\n0\n0\n0\n0\n11788555\n1\ncandle.jpg\nsandal.jpg\nsandwich.jpg\nbuilding.jpg\nTCUU\nsandwich.jpg\nU2\nC\nT\nU\nBL\nresponse_button_image\n1997.8\nsandwich.jpg\n13.0999999\nAUDIO PLAY EVENT FIRED\n29.63857024\n1922.4\n57\n29.65043695\nsandwich.jpg\nbuilding.jpg\ncandle.jpg\nNA\nNA\nsandal.jpg\nTR\nNA\nBR\nTL\nNA\n2\nTR\n\n\n\n\n\n\n\nIn the AOI object we have our condition variables as columns. For this example, the fixation locations need to be “gathered” from separate columns into a single column and “NA” values need to be re-coded as non-fixations (0). We logically evaluate these below so we know which item was fixated each sample and what was not.\n\n\nResultInteractive\n\n\nAOI$target &lt;- ifelse(AOI$loc1==AOI$targ_loc, 1, 0) # if in coordinates 1, if not 0. \n\nAOI$unrelated &lt;- ifelse(AOI$loc1 == AOI$unrelated_loc, 1, 0)# if in coordinates 1, if not 0. \n\nAOI$unrelated2 &lt;- ifelse(AOI$loc1 == AOI$unrealted2_loc, 1, 0)# if in coordinates 1, if not 0. \n\nAOI$unrelated3 &lt;- ifelse(AOI$loc1 == AOI$unrelated3_loc, 1, 0)# if in coordinates 1, if not 0. \n\nAOI$rhyme &lt;- ifelse(AOI$loc1 == AOI$rhyme_loc, 1, 0)# if in coordinates 1, if not 0. \n\n\nAOI$cohort &lt;- ifelse(AOI$loc1 == AOI$cohort_loc, 1, 0)# if in coordinates 1, if not 0. \n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nX\nx0\nfilename\ntrial\ntime_stamp\ntime\ntype\nscreen_index\nx_pred\ny_pred\nx_pred_normalised\ny_pred_normalised\nconvergence\nface_conf\nzone_name\nzone_x\nzone_y\nzone_width\nzone_height\nzone_x_normalised\nzone_y_normalised\nzone_width_normalised\nzone_height_normalised\nsubject\nacc\nTL\nTR\nBL\nBR\ntrialtype\ntargetword\ntlcode\ntrcode\nblcode\nbrcode\ntarg_loc\nzone_type\nRT\nresponse.x\nRT_audio\nresponse.y\nmed_SR\nmax_time\nn_times\nSR\nTarget\nUnrelated\nUnrelated2\nUnrelated3\nRhyme\nCohort\ncohort_loc\nrhyme_loc\nunrelated_loc\nunrealted2_loc\nunrelated3_loc\nAOI\nloc1\ntarget\nunrelated\nunrelated2\nunrelated3\nrhyme\ncohort\n\n\n\n\n1\nNA\neyetracking_collection\n153\n1727868218964\n0.00000000\nprediction\n4\n921.5823073\n-61.68745669\n0.4717325812\n-0.0607758194\n0\n1\nNA\n0\n0\n0\n0\n0\n0\n0\n0\n11788555\n1\ncandle.jpg\nsandal.jpg\nsandwich.jpg\nbuilding.jpg\nTCUU\nsandwich.jpg\nU2\nC\nT\nU\nBL\nresponse_button_image\n1997.8\nsandwich.jpg\n13.0999999\nAUDIO PLAY EVENT FIRED\n29.63857024\n1922.4\n57\n29.65043695\nsandwich.jpg\nbuilding.jpg\ncandle.jpg\nNA\nNA\nsandal.jpg\nTR\nNA\nBR\nTL\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n\n\n2\nNA\neyetracking_collection\n153\n1727868218999\n34.00000000\nprediction\n4\n958.2899489\n78.26706763\n0.4988631366\n0.0771104115\n0\n1\nNA\n0\n0\n0\n0\n0\n0\n0\n0\n11788555\n1\ncandle.jpg\nsandal.jpg\nsandwich.jpg\nbuilding.jpg\nTCUU\nsandwich.jpg\nU2\nC\nT\nU\nBL\nresponse_button_image\n1997.8\nsandwich.jpg\n13.0999999\nAUDIO PLAY EVENT FIRED\n29.63857024\n1922.4\n57\n29.65043695\nsandwich.jpg\nbuilding.jpg\ncandle.jpg\nNA\nNA\nsandal.jpg\nTR\nNA\nBR\nTL\nNA\n3\nBL\n1\n0\n0\nNA\nNA\n0\n\n\n3\nNA\neyetracking_collection\n153\n1727868219039\n73.30000019\nprediction\n4\n1036.1006719\n247.37493626\n0.5563729098\n0.2437191490\n0\n1\nNA\n0\n0\n0\n0\n0\n0\n0\n0\n11788555\n1\ncandle.jpg\nsandal.jpg\nsandwich.jpg\nbuilding.jpg\nTCUU\nsandwich.jpg\nU2\nC\nT\nU\nBL\nresponse_button_image\n1997.8\nsandwich.jpg\n13.0999999\nAUDIO PLAY EVENT FIRED\n29.63857024\n1922.4\n57\n29.65043695\nsandwich.jpg\nbuilding.jpg\ncandle.jpg\nNA\nNA\nsandal.jpg\nTR\nNA\nBR\nTL\nNA\n4\nBR\n0\n1\n0\nNA\nNA\n0\n\n\n4\nNA\neyetracking_collection\n153\n1727868219076\n113.09999990\nprediction\n4\n1048.4626414\n383.69717600\n0.5655096204\n0.3780267744\n0\n1\nNA\n0\n0\n0\n0\n0\n0\n0\n0\n11788555\n1\ncandle.jpg\nsandal.jpg\nsandwich.jpg\nbuilding.jpg\nTCUU\nsandwich.jpg\nU2\nC\nT\nU\nBL\nresponse_button_image\n1997.8\nsandwich.jpg\n13.0999999\nAUDIO PLAY EVENT FIRED\n29.63857024\n1922.4\n57\n29.65043695\nsandwich.jpg\nbuilding.jpg\ncandle.jpg\nNA\nNA\nsandal.jpg\nTR\nNA\nBR\nTL\nNA\n4\nBR\n0\n1\n0\nNA\nNA\n0\n\n\n5\nNA\neyetracking_collection\n153\n1727868219111\n148.40000010\nprediction\n4\n1018.1750413\n433.21330043\n0.5431241067\n0.4268111334\n0\n1\nNA\n0\n0\n0\n0\n0\n0\n0\n0\n11788555\n1\ncandle.jpg\nsandal.jpg\nsandwich.jpg\nbuilding.jpg\nTCUU\nsandwich.jpg\nU2\nC\nT\nU\nBL\nresponse_button_image\n1997.8\nsandwich.jpg\n13.0999999\nAUDIO PLAY EVENT FIRED\n29.63857024\n1922.4\n57\n29.65043695\nsandwich.jpg\nbuilding.jpg\ncandle.jpg\nNA\nNA\nsandal.jpg\nTR\nNA\nBR\nTL\nNA\n4\nBR\n0\n1\n0\nNA\nNA\n0\n\n\n6\nNA\neyetracking_collection\n153\n1727868219145\n182.00000000\nprediction\n4\n1040.6113826\n514.57934044\n0.5597067684\n0.5069747196\n0\n1\nNA\n0\n0\n0\n0\n0\n0\n0\n0\n11788555\n1\ncandle.jpg\nsandal.jpg\nsandwich.jpg\nbuilding.jpg\nTCUU\nsandwich.jpg\nU2\nC\nT\nU\nBL\nresponse_button_image\n1997.8\nsandwich.jpg\n13.0999999\nAUDIO PLAY EVENT FIRED\n29.63857024\n1922.4\n57\n29.65043695\nsandwich.jpg\nbuilding.jpg\ncandle.jpg\nNA\nNA\nsandal.jpg\nTR\nNA\nBR\nTL\nNA\n2\nTR\n0\n0\n0\nNA\nNA\n1\n\n\n\n\n\n\n\nNow we pivot so instead of each condition being an individual column it is one column. This helps with visualization. We pivot_longer or make longer the target, unrelated, unrealted2, unrelated3, rhyme, and cohort columns. We put them into a column called condition and place the values of 0 and 1 into a column called look.\n\n\nResultInteractive\n\n\ndat_long_aoi_me &lt;- AOI  %&gt;%\n  select(subject, trial, trialtype, target, cohort, unrelated, unrelated2, unrelated3,  rhyme, time, x_pred_normalised, y_pred_normalised, RT_audio) %&gt;%\n    pivot_longer(\n        cols = c(target, unrelated, unrelated2, unrelated3, rhyme, cohort),\n        names_to = \"condition\",\n        values_to = \"Looks\"\n    )\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\n\n\n\n\nNon-looks\n\n\n\nThere are two ways we can handle missingness here. We can either re-code the NA values as non-looks, or we can exclude looks that occurred outside an AOI.\nHere we are going to treat them as non-looks (0)",
    "crumbs": [
      "Articles",
      "Introduction to webgazeR"
    ]
  },
  {
    "objectID": "vignettes/webgazeR_vignette.html#downsampling",
    "href": "vignettes/webgazeR_vignette.html#downsampling",
    "title": "Introduction to webgazeR",
    "section": "Downsampling",
    "text": "Downsampling\nWe also downsampled our data into 100 ms bins using the downsample_gaze function from the webgazeR package. In this process, we read in our gaze_sub object, specified the bin.length argument as 200, and set the time variable as time. We also indicated the variables to aggregate on, such as condition and timebins. The time_bin variable is created by the function and represents the bins we are aggregating across. There is no clear consensus on binning, so we cannot provide a concrete rule of thumb here.\n\n\nResultInteractive\n\n\ngaze_sub &lt;- webgazeR::downsample_gaze(gaze_sub, bin.length=100, timevar=\"time\", aggvars=c(\"condition\", \"time_bin\"))\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\nPlotting\nTo simplify plotting your time-course data, we have created the plot_IA_proportions function. This function takes several arguments. The ia_column argument specifies the column containing your Interest Area (IA) labels. The time_column argument requires the name of your time bin column, and the proportion_column argument specifies the column containing fixation or look proportions. Additional arguments allow you to specify custom names for each IA in the ia_column, enabling you to label them as desired.\n\n\nResultInteractive\n\n\nplot_IA_proportions(gaze_sub, \n                     ia_column = \"condition\", \n                     time_column = \"time_bin\", \n                     proportion_column = \"Fix\", \n                   ia_mapping = list(target = \"Target\", cohort = \"Cohort\", rhyme = \"Rhyme\", unrelated = \"Unrelated\"))\n\n\n\n\n\n\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.",
    "crumbs": [
      "Articles",
      "Introduction to webgazeR"
    ]
  },
  {
    "objectID": "vignettes/webgazeR_vignette.html#gorilla-provided-coordinates",
    "href": "vignettes/webgazeR_vignette.html#gorilla-provided-coordinates",
    "title": "Introduction to webgazeR",
    "section": "Gorilla provided coordinates",
    "text": "Gorilla provided coordinates\nIf you open the each individual .xlsx file provided by gorilla you will see that it provides standardized coordinates for each location: TL, TR, BL, BR. Let’s use these coordinates instead of setting some general coordinates.\nWe will use the function extract_aois to get the coordinates for each quadrant on screen. You can use the zone_names argument to get the zones you want to use.\n\n\nResultInteractive\n\n\naois &lt;- extract_aois(vwp_paths_filtered, zone_names =  c(\"TL\", \"BR\", \"TR\", \"BL\"))\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\nBelow is the table the extract_aois function will return.\n\n\nResultInteractive\n\n\n# Define the data\naois &lt;- data.frame(\n  loc = c(\"BL\", \"TL\", \"TR\", \"BR\"),\n  x_normalized = c(0.03, 0.02, 0.73, 0.73),\n  y_normalized = c(0.04, 0.74, 0.75, 0.06),\n  width_normalized = c(0.26, 0.26, 0.24, 0.23),\n  height_normalized = c(0.25, 0.25, 0.24, 0.25),\n  xmin = c(0.03, 0.02, 0.73, 0.73),\n  ymin = c(0.04, 0.74, 0.75, 0.06),\n  xmax = c(0.29, 0.28, 0.97, 0.96),\n  ymax = c(0.29, 0.99, 0.99, 0.31)\n)\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\nResultInteractive\n\n\n\naois %&gt;%\n  kable()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nloc\nx_normalized\ny_normalized\nwidth_normalized\nheight_normalized\nxmin\nymin\nxmax\nymax\n\n\n\n\nBL\n0.03\n0.04\n0.26\n0.25\n0.03\n0.04\n0.29\n0.29\n\n\nTL\n0.02\n0.74\n0.26\n0.25\n0.02\n0.74\n0.28\n0.99\n\n\nTR\n0.73\n0.75\n0.24\n0.24\n0.73\n0.75\n0.97\n0.99\n\n\nBR\n0.73\n0.06\n0.23\n0.25\n0.73\n0.06\n0.96\n0.31\n\n\n\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\nWe see the AOIs are a bit smaller now with the gorilla provided coordinates.\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe can follow the same steps from above to analyze our data, making sure we input the write coordinates into the aoi_loc argument.\n\n\nResultInteractive\n\n\nassign &lt;- assign_aoi(dat_colnames,X=\"x_pred_normalised\", Y=\"y_pred_normalised\",aoi_loc = aois)\n\n\nAOI &lt;- assign %&gt;%\n\n  mutate(loc1 = case_when(\n\n    AOI==1 ~ \"BL\", \n\n    AOI==2 ~ \"TL\", \n\n    AOI==3 ~ \"TR\", \n\n    AOI==4 ~ \"BR\"\n\n  ))\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\nResultInteractive\n\n\nAOI$target &lt;- ifelse(AOI$loc1==AOI$targ_loc, 1, 0) # if in coordinates 1, if not 0. \n\nAOI$unrelated &lt;- ifelse(AOI$loc1 == AOI$unrelated_loc, 1, 0)# if in coordinates 1, if not 0. \n\nAOI$unrelated2 &lt;- ifelse(AOI$loc1 == AOI$unrealted2_loc, 1, 0)# if in coordinates 1, if not 0. \n\nAOI$unrelated3 &lt;- ifelse(AOI$loc1 == AOI$unrelated3_loc, 1, 0)# if in coordinates 1, if not 0. \n\nAOI$rhyme &lt;- ifelse(AOI$loc1 == AOI$rhyme_loc, 1, 0)# if in coordinates 1, if not 0. \n\n\nAOI$cohort &lt;- ifelse(AOI$loc1 == AOI$cohort_loc, 1, 0)# if in coordinates 1, if not 0. \n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\nNow we pivot so instead of each condition being an individual column it is one column.\n\ndat_long_aoi_me &lt;- AOI  %&gt;%\n  select(subject, trial, trialtype, target, cohort, unrelated, unrelated2, unrelated3,  rhyme, time, x_pred_normalised, y_pred_normalised, RT_audio) %&gt;%\n    pivot_longer(\n        cols = c(target, unrelated, unrelated2, unrelated3, rhyme, cohort),\n        names_to = \"condition\",\n        values_to = \"Looks\"\n    )\n\n\n\nResultInteractive\n\n\ndat_long_aoi_me_TCRU &lt;- dat_long_aoi_me %&gt;%\n  filter(trialtype==\"TCRU\") %&gt;%\n  na.omit()\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\nResultInteractive\n\n\ngaze_sub &lt;-dat_long_aoi_me_TCRU %&gt;% \ngroup_by(subject, trial) %&gt;%\n  mutate(time = (time-RT_audio)-300) %&gt;% # subtract audio rt onset for each\n filter(time &gt;= 0, time &lt; 2000) %&gt;% \n   dplyr::filter(x_pred_normalised &gt; 0,\n                x_pred_normalised &lt; 1,\n                y_pred_normalised &gt; 0,\n                y_pred_normalised &lt; 1)\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\nResultInteractive\n\n\ngaze_sub &lt;- downsample_gaze(gaze_sub, bin.length=100, timevar=\"time\", aggvars=c(\"condition\", \"time_bin\"))\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\nPlotting\n\n\nResultInteractive\n\n\ngor &lt;- plot_IA_proportions(gaze_sub, \n                     ia_column = \"condition\", \n                     time_column = \"time_bin\", \n                     proportion_column = \"Fix\", \n                   ia_mapping = list(target = \"Target\", cohort = \"Cohort\", rhyme = \"Rhyme\", unrelated = \"Unrelated\"))\n\ngor\n\n\n\n\n\n\n\nFigure 1\n\n\n\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\nWe see the effect is a lot larger when using the gorilla provided coordinates, but a bit noiser.",
    "crumbs": [
      "Articles",
      "Introduction to webgazeR"
    ]
  }
]