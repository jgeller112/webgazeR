[{"path":"/articles/webgazeR_vignette.html","id":"packages","dir":"Articles","previous_headings":"","what":"Packages","title":"Introduction to webgazeR","text":"load packages needed run vignette.","code":"options(stringsAsFactors = F)          # no automatic data transformation options(\"scipen\" = 100, \"digits\" = 10) # suppress math annotation library(tidyverse)  library(here) # relative paths instead of abosoulte aids in reproduce library(tinytable) # nice tables library(janitor)# functions for cleaning up your column names library(easystats) remotes::install_github(\"https://github.com/jgeller112/webgazeR\") library(webgazeR)"},{"path":"/articles/webgazeR_vignette.html","id":"load-webgazer","dir":"Articles","previous_headings":"","what":"Load webgazeR","title":"Introduction to webgazeR","text":"","code":"remotes::install_github(\"https://github.com/jgeller112/webgazeR\") library(webgazeR)"},{"path":"/articles/webgazeR_vignette.html","id":"eye-data","dir":"Articles","previous_headings":"","what":"Eye data","title":"Introduction to webgazeR","text":"data generated Gorilla, trial experiment file. , need take individual files merge together. merge_webcam_files function merges trial participant single tibble dataframe. running merge_webcam_files function, ensure working directory set files stored. function reads .xlsx files, binds together one dataframe, cleans column names. function filters data include rows type “prediction” screen_index matches specified value (case, screen 4). eye-tracking data recorded. function renames spreadsheet_row column trial sets trial subjectas factors analysis pipeline. note, steps followed order due renaming column names. encounter error might column names changed. webgazeR package includes combined dataset us use Gorilla produces .csv file include trial-level information (agg_ege_data). read object create object called emstr selects useful columns file renames stimuli make intuitive. user-specific, function called . describe pre-processing done behavioral data file. code processes transforms agg_eye_data dataset cleaned structured format analysis. First, code renames several columns easier access using janitor::clean_names function. filters dataset include rows zone_type “response_button_image”, representing picture selected trial. Afterward, function renames additional columns (tlpic TL, trpic TR, etc.). also renamed participant_private_id subject, spreadsheet_row trial, reaction_time RT. makes columns consistent edat merging later . Lastly, `reaction time (RT) converted numeric format numerical analysis. using audio trial running experiment browser audio onset never going conistent across participants. Gorilla option collect advanced audio features audio play requested, fired )played ended. want incorporate pipeline. Gorilla records onset audio varies participant. extracting filtering zone_type content_web_audio response equal “AUDIO PLAY EVENT FIRED”. tell us audio triggered experiment (reaction_time). merge information emstr. see RT_audio added dataframe. commercial eye-trackers sample constant rate, webcam eye-trackers . code calculate sampling rate participant. Ideally, sampling rate less 5 Hz. recommended drop values. function analyze_sample_rate calculates calculates sampling rate subject trial eye-tracking dataset. provides overall statistics, including median standard deviation sampling rates experiment,also generates histogram median sampling rates subject density plot overlayed.  example, median sampling rate 24.77 SD 7.81. using function, separate data frames produced subjects trials. can added behavioral data object. can add behavioral data Users can use filter_sampling_rate function either either (1) throw data, subject, trial, , (2) label sampling rates certain threshold bad (TRUE FALSE). Let’s use filter_sampling_rate() function . read target_data_with_full_SR object. leave user decide make specific recommendations. case going remove data subject trial (action==“”) sampling frequency 5hz (threshold=5). filter_sampling_rate function designed process dataset containing subject-level trial-level sampling rates. allows user either filter data falls certain sampling rate threshold simply label “bad”. function gives flexibility allowing threshold applied subject level, trial level, . also lets user decide whether remove data flag threshold without removing . action = remove, function output many subjects trials removed threshold. filter_edat returns dataframe trials subjects removed. set argument action label, filter_edat_label return dataframe includes column(s) sampling rates < 5 labeled TRUE (bad) FALSE subjects threshold 5. However, 18 trials , removed. important include points fall outside standardized coordinates. gaze_oob function calculates many data points fall outside standardized range. function returns many data points fall outside range subject provides percentage. information useful include final paper. add -subject -trial bounds data exclude participants trials > 30% missing data. lab, can control every aspect experiment. Online cant . Participants going completing experiment variety conditions. includes using different computers, different screen dimensions. control , Gorilla outputs standardized zone coordinates. discussed Gorilla documentation, Gorilla layout engine lays everything 4:3 frame makes frame big possible. normalized coordinates expressed relative frame; example, coordinate 0.5, 0.5 always center screen, regardless size participant’s screen. used normalized coordinates analysis. However, different ways specify four coordinates screen, think worth highlighting. One way make AOIs big possible place four quadrants screen. need first create dataframe location AOI (e.g., TL, TR, BL, BR), x y normalized coordinates width height normalized. addition, get xmin, xmanx, ymax ymin AOIs. going remove poor convergence scales confidence. also remove coordinates 0 data. Next going combine eye-tracking data behavioral data using left_join function. Let’s verify AOIs look suppose .  Excellent! experiment four different trial types: Target, Cohort, Rhyme, Unrealted Target, Cohort, Unrealted, Unrelated Target, Unrelated, Unrealted, Unrelated Target, Rhyme, Unrelated, Unrelated first match pictures TL, TR, BL, BR columns correct code condition (T,C, R, U, U2, U3). study, need track condition image shown (Target, Cohort, Rhyme, Unrelated) also image located screen trial randomized trial. , use function named find_location. function designed determine location specific image screen comparing image list possible locations. function find_location first checks image NA (missing). image NA, function returns NA, meaning ’s location find image. image NA, function creates vector loc_names lists names possible locations. attempts match given image locations. match found, returns name location (e.g., TL, TR, BL, BR) image located. match, function returns NA. going use coordinate information . use assign_aoi adaopted gazeR package (Geller et al., 2020) loop object dat_colnames assign locations (.e., TR, TL, BL, BR) normalized x y coordinates. function label non-looks screen coordinates NA. make easier read change numerals assigned function actual screen locations. AOI object condition variables columns. example, fixation locations need “gathered” separate columns single column “NA” values need re-coded non-fixations (0). logically evaluate know item fixated sample . Now pivot instead condition individual column one column. helps visualization. pivot_longer make longer target, unrelated, unrealted2, unrelated3, rhyme, cohort columns. put column called condition place values 0 1 column called look. Non-looks two ways can handle missingness . can either re-code NA values non-looks, can exclude looks occurred outside AOI. going treat non-looks (0) presentation audio delay played. coded RT_audio. change time correspond audio_onset. can subtracting RT_audio time. Researchers may decide sample data. sample 100 ms bins get aggregate across time condition plotting. Bramlett Wiener notice significant difference bin size long sampling rate > 5Hz. addition, also remove coordinates outside standardized window. end proportion looks AOIs stored meanfix column.","code":"# Get the list of all files in the folder vwp_files  <- list.files(here::here(\"data\", \"monolinguals\", \"raw\"), pattern = \"\\\\.xlsx$\", full.names = TRUE)  # Exclude files that contain \"calibration\" in their filename vwp_paths_filtered <- vwp_files[!grepl(\"calibration\", vwp_files)] setwd(here::here(\"data\", \"monolinguals\", \"raw\")) # set working directory to raw data folder  edat <- merge_webcam_files(vwp_paths_filtered, screen_index=4) # eye tracking occured ons creen index 4 edat <- webgazeR::eyedata # load in trial level data agg_eye_data <- webgazeR::behav_data emstr <- agg_eye_data %>%      janitor::clean_names() %>%      # Select specific columns to keep in the dataset   dplyr::select(participant_private_id,  correct, tlpic, trpic, blpic, brpic, trialtype, targetword, tlcode, trcode, blcode, brcode, zone_name, zone_type,reaction_time, spreadsheet_row, response) %>%      # Filter the rows where 'Zone.Type' equals \"response_button_image\"   dplyr::filter(zone_type == \"response_button_image\") %>%      # Rename columns for easier use and readability   dplyr::rename(     \"TL\" = \"tlpic\",              # Rename 'tlpic' to 'TL'     \"TR\" = \"trpic\",             # Rename 'trpic' to 'TR'     \"BL\" = \"blpic\",            # Rename 'blpic' to 'BL'     \"BR\" = \"brpic\",                # Rename 'brpic' to 'BR'     \"targ_loc\" = \"zone_name\",       # Rename 'Zone.Name' to 'targ_loc'     \"subject\" = \"participant_private_id\",  # Rename 'Participant.Private.ID' to 'subject'     \"trial\" = \"spreadsheet_row\",    # Rename 'spreadsheet_row' to 'trial'     \"acc\" = \"correct\",              # Rename 'Correct' to 'acc' (accuracy)     \"RT\" = \"reaction_time\"          # Rename 'Reaction.Time' to 'RT'   ) %>%      # Convert the 'RT' (Reaction Time) column to numeric type   mutate(RT = as.numeric(RT),           subject=as.factor(subject),           trial=as.factor(trial)) audio_rt <- agg_eye_data %>%      janitor::clean_names()%>%   select(participant_private_id,zone_type, spreadsheet_row, reaction_time, response) %>%    filter(zone_type==\"content_web_audio\", response==\"AUDIO PLAY EVENT FIRED\")%>%   distinct() %>% rename(\"subject\" = \"participant_private_id\",         \"trial\" =\"spreadsheet_row\",          \"RT_audio\" = \"reaction_time\") %>% select(-zone_type) %>% mutate(RT_audio=as.numeric(RT_audio)) trial_data_rt <- merge(emstr, audio_rt, by=c(\"subject\", \"trial\"))  head(trial_data_rt) %>%   head() %>%   tt() samp_rate <- analyze_sampling_rate(edat) Overall Median Sampling Rate (Hz): 24.76936956 Overall Standard Deviation of Sampling Rate (Hz): 7.807913315  Sampling Rate by Trial: # A tibble: 3,122 × 5 # Groups:   subject [23]     subject trial max_time n_times    SR       <int> <int>    <dbl>   <int> <dbl>  1 11788555     7    3664.     107  29.2  2 11788555     8    1295       39  30.1  3 11788555     9    2298.      68  29.6  4 11788555    10    1743.      52  29.8  5 11788555    12    1741.      52  29.9  6 11788555    13    1365.      40  29.3  7 11788555    15    1404.      40  28.5  8 11788555    16    1714.      51  29.8  9 11788555    21    1584.      47  29.7 10 11788555    27    2103.      62  29.5 # ℹ 3,112 more rows  Median Sampling Rate by Subject: # A tibble: 23 × 2     subject med_SR       <int>  <dbl>  1 11788555  29.6  2 11788682  29.7  3 11788824  23.9  4 11788857   8.79  5 11789574  11.5  6 11795362  22.6  7 11795372  24.8  8 11795375  28.5  9 11795376  29.9 10 11795379  30.4 # ℹ 13 more rows # Extract by-subject and by-trial sampling rates from the result subject_sampling_rate <- samp_rate$median_SR_by_subject  # Sampling rate by subject trial_sampling_rate <- samp_rate$SR_by_trial  # Sampling rate by trial trial_sampling_rate$subject<-as.factor(trial_sampling_rate$subject)  # Assuming target_data is your other dataset that contains subject and trial information # Append the by-subject sampling rate to target_data (based on subject) subject_sampling_rate$subject <- as.factor(subject_sampling_rate$subject)  target_data_with_subject_SR <- trial_data_rt %>%   left_join(subject_sampling_rate, by = \"subject\")  # Append the by-trial sampling rate to target_data (based on subject and trial)   trial_sampling_rate$trial <- as.factor(trial_sampling_rate$trial)   target_data_with_full_SR <- target_data_with_subject_SR %>%   select(subject, trial, med_SR)%>%   left_join(trial_sampling_rate, by = c(\"subject\", \"trial\")) trial_data <- left_join(trial_data_rt, target_data_with_full_SR, by=c(\"subject\", \"trial\")) filter_edat <- filter_sampling_rate(trial_data,threshold = 5,                                           action = \"remove\",                                           by = \"both\") filter_edat_label <- filter_sampling_rate(trial_data,threshold = 5,                                           action = \"label\",                                           by=\"both\") oob_data <- gaze_oob(edat) Subject: 11788555 Total points: 2483 Points outside the range: 608 Total missing percentage: 24.49% X: 17.28% Y: 13.53%   Subject: 11788682 Total points: 5798 Points outside the range: 551 Total missing percentage: 9.5% X: 6.83% Y: 3.47%   Subject: 11788824 Total points: 6961 Points outside the range: 1792 Total missing percentage: 25.74% X: 17.14% Y: 13.37%   Subject: 11788857 Total points: 2237 Points outside the range: 277 Total missing percentage: 12.38% X: 11.85% Y: 1.3%   Subject: 11789574 Total points: 932 Points outside the range: 221 Total missing percentage: 23.71% X: 14.16% Y: 16.09%   Subject: 11795362 Total points: 3951 Points outside the range: 608 Total missing percentage: 15.39% X: 10% Y: 7.69%   Subject: 11795372 Total points: 4598 Points outside the range: 677 Total missing percentage: 14.72% X: 9.11% Y: 8.22%   Subject: 11795375 Total points: 6795 Points outside the range: 1008 Total missing percentage: 14.83% X: 11.18% Y: 6.99%   Subject: 11795376 Total points: 6749 Points outside the range: 1676 Total missing percentage: 24.83% X: 13.48% Y: 16.42%   Subject: 11795379 Total points: 2247 Points outside the range: 350 Total missing percentage: 15.58% X: 4.36% Y: 12.28%   Subject: 11795382 Total points: 5239 Points outside the range: 528 Total missing percentage: 10.08% X: 6.91% Y: 5.99%   Subject: 11795385 Total points: 6172 Points outside the range: 1557 Total missing percentage: 25.23% X: 14.52% Y: 15.83%   Subject: 11795386 Total points: 4658 Points outside the range: 1397 Total missing percentage: 29.99% X: 17% Y: 22.33%   Subject: 11795387 Total points: 3634 Points outside the range: 586 Total missing percentage: 16.13% X: 9.41% Y: 9.25%   Subject: 11795388 Total points: 4097 Points outside the range: 755 Total missing percentage: 18.43% X: 11.33% Y: 11.11%   Subject: 11795426 Total points: 1242 Points outside the range: 122 Total missing percentage: 9.82% X: 6.44% Y: 6.44%   Subject: 11795446 Total points: 6712 Points outside the range: 546 Total missing percentage: 8.13% X: 5.91% Y: 4.68%   Subject: 11795529 Total points: 4668 Points outside the range: 482 Total missing percentage: 10.33% X: 6.92% Y: 4.86%   Subject: 11795650 Total points: 2213 Points outside the range: 101 Total missing percentage: 4.56% X: 2.08% Y: 2.89%   Subject: 11795671 Total points: 4982 Points outside the range: 1438 Total missing percentage: 28.86% X: 18.15% Y: 17.7%   Subject: 11796749 Total points: 6469 Points outside the range: 1891 Total missing percentage: 29.23% X: 23.09% Y: 13.48%   Subject: 11796756 Total points: 6249 Points outside the range: 820 Total missing percentage: 13.12% X: 7.25% Y: 8.64%   Subject: 11796779 Total points: 5737 Points outside the range: 253 Total missing percentage: 4.41% X: 2.18% Y: 2.75% oob_data %>%    tt() # Create a data frame for the quadrants with an added column for the quadrant labels aoi_loc <- data.frame(   loc = c('TL', 'TR', 'BL', 'BR'),    x_normalized = c(0, 0.5, 0, 0.5),    y_normalized = c(0.5, 0.5, 0, 0),   width_normalized = c(0.5, 0.5, 0.5, 0.5),   height_normalized = c(0.5, 0.5, 0.5, 0.5)) %>%       mutate(xmin = x_normalized, ymin = y_normalized,          xmax = x_normalized+width_normalized,          ymax = y_normalized+height_normalized)  aoi_loc %>%   tt() edat_1 <- edat %>%  dplyr::filter(convergence <= .5, face_conf >= .5) %>%   # remove rows without gaze information   dplyr::filter(x_pred_normalised != 0,                 y_pred_normalised != 0) edat_1$subject<-as.factor(edat_1$subject) edat_1$trial<-as.factor(edat_1$trial)    dat <- left_join(edat_1, filter_edat, by = c(\"subject\",\"trial\"))  dat <- dat %>%   distinct() # make sure to remove duplicate rows #look at the AOIs and see if they make sense  # Create a data frame for the quadrants quadrants <- data.frame(   x = c(0, 0.5, 0, 0.5),   y = c(0.5, 0.5, 0, 0),   width = c(0.5, 0.5, 0.5, 0.5),   height = c(0.5, 0.5, 0.5, 0.5),   color = c('red', 'blue', 'green', 'orange'),   label = c('TL Width = 0.5', 'TR Width = 0.5', 'BL Width = 0.5', 'BR Width = 0.5') )  # Create the plot ggplot() +   geom_rect(data = quadrants, aes(xmin = x, xmax = x + width, ymin = y, ymax = y + height, fill = color),              color = 'black', alpha = 0) +   geom_text(data = quadrants, aes(x = x + width/2, y = y + height/2, label = label), color = 'black', size = 5) +   scale_fill_identity() +   coord_fixed() +   labs(x = 'Normalized X', y = 'Normalized Y', title = 'Quadrants with Width Annotations') +   theme_minimal() # Assuming your data is in a data frame called df dat <- dat %>%   mutate(     Target = case_when(       tlcode == \"T\" ~ TL,       trcode == \"T\" ~ TR,       blcode == \"T\" ~ BL,       brcode == \"T\" ~ BR,       TRUE ~ NA_character_  # Default to NA if no match     ),     Unrelated = case_when(       tlcode == \"U\" ~ TL,       trcode == \"U\" ~ TR,       blcode == \"U\" ~ BL,       brcode == \"U\" ~ BR,       TRUE ~ NA_character_     ),     Unrelated2 = case_when(       tlcode == \"U2\" ~ TL,       trcode == \"U2\" ~ TR,       blcode == \"U2\" ~ BL,       brcode == \"U2\" ~ BR,       TRUE ~ NA_character_     ),     Unrelated3 = case_when(       tlcode == \"U3\" ~ TL,       trcode == \"U3\" ~ TR,       blcode == \"U3\" ~ BL,       brcode == \"U3\" ~ BR,       TRUE ~ NA_character_     ),     Rhyme = case_when(       tlcode == \"R\" ~ TL,       trcode == \"R\" ~ TR,       blcode == \"R\" ~ BL,       brcode == \"R\" ~ BR,       TRUE ~ NA_character_     ),     Cohort = case_when(       tlcode == \"C\" ~ TL,       trcode == \"C\" ~ TR,       blcode == \"C\" ~ BL,       brcode == \"C\" ~ BR,       TRUE ~ NA_character_     )   ) head(dat) %>%      tt() # Apply the function to each of the targ, cohort, rhyme, and unrelated columns dat_colnames <- dat %>%   rowwise() %>%   mutate(     targ_loc = find_location(c(TL, TR, BL, BR), Target),     cohort_loc = find_location(c(TL, TR, BL, BR), Cohort),     rhyme_loc = find_location(c(TL, TR, BL, BR), Rhyme),     unrelated_loc = find_location(c(TL, TR, BL, BR), Unrelated),      unrealted2_loc= find_location(c(TL, TR, BL, BR), Unrelated2),      unrelated3_loc=find_location(c(TL, TR, BL, BR), Unrelated3)   ) %>%   ungroup() assign <- gazer::assign_aoi(dat_colnames,X=\"x_pred_normalised\", Y=\"y_pred_normalised\",aoi_loc = aoi_loc)   AOI <- assign %>%    mutate(loc1 = case_when(      AOI==1 ~ \"TL\",       AOI==2 ~ \"TR\",       AOI==3 ~ \"BL\",       AOI==4 ~ \"BR\"    ))  head(AOI) # A tibble: 6 × 58       X x0    filename   trial time_stamp  time type  screen_index x_pred y_pred   <int> <lgl> <chr>      <fct>      <dbl> <dbl> <chr>        <int>  <dbl>  <dbl> 1     1 NA    eyetracki… 153      1.73e12   0   pred…            4   922.  -61.7 2     2 NA    eyetracki… 153      1.73e12  34   pred…            4   958.   78.3 3     3 NA    eyetracki… 153      1.73e12  73.3 pred…            4  1036.  247. 4     4 NA    eyetracki… 153      1.73e12 113.  pred…            4  1048.  384. 5     5 NA    eyetracki… 153      1.73e12 148.  pred…            4  1018.  433. 6     6 NA    eyetracki… 153      1.73e12 182   pred…            4  1041.  515. # ℹ 48 more variables: x_pred_normalised <dbl>, y_pred_normalised <dbl>, #   convergence <int>, face_conf <dbl>, zone_name <lgl>, zone_x <int>, #   zone_y <int>, zone_width <int>, zone_height <int>, zone_x_normalised <int>, #   zone_y_normalised <int>, zone_width_normalised <int>, #   zone_height_normalised <int>, subject <fct>, acc <int>, TL <chr>, TR <chr>, #   BL <chr>, BR <chr>, trialtype <chr>, targetword <chr>, tlcode <chr>, #   trcode <chr>, blcode <chr>, brcode <chr>, targ_loc <chr>, … AOI$target <- ifelse(AOI$loc1==AOI$targ_loc, 1, 0) # if in coordinates 1, if not 0.   AOI$unrelated <- ifelse(AOI$loc1 == AOI$unrelated_loc, 1, 0)# if in coordinates 1, if not 0.   AOI$unrelated2 <- ifelse(AOI$loc1 == AOI$unrealted2_loc, 1, 0)# if in coordinates 1, if not 0.   AOI$unrelated3 <- ifelse(AOI$loc1 == AOI$unrelated3_loc, 1, 0)# if in coordinates 1, if not 0.   AOI$rhyme <- ifelse(AOI$loc1 == AOI$rhyme_loc, 1, 0)# if in coordinates 1, if not 0.    AOI$cohort <- ifelse(AOI$loc1 == AOI$cohort_loc, 1, 0)# if in coordinates 1, if not 0.   head(AOI) # A tibble: 6 × 64       X x0    filename   trial time_stamp  time type  screen_index x_pred y_pred   <int> <lgl> <chr>      <fct>      <dbl> <dbl> <chr>        <int>  <dbl>  <dbl> 1     1 NA    eyetracki… 153      1.73e12   0   pred…            4   922.  -61.7 2     2 NA    eyetracki… 153      1.73e12  34   pred…            4   958.   78.3 3     3 NA    eyetracki… 153      1.73e12  73.3 pred…            4  1036.  247. 4     4 NA    eyetracki… 153      1.73e12 113.  pred…            4  1048.  384. 5     5 NA    eyetracki… 153      1.73e12 148.  pred…            4  1018.  433. 6     6 NA    eyetracki… 153      1.73e12 182   pred…            4  1041.  515. # ℹ 54 more variables: x_pred_normalised <dbl>, y_pred_normalised <dbl>, #   convergence <int>, face_conf <dbl>, zone_name <lgl>, zone_x <int>, #   zone_y <int>, zone_width <int>, zone_height <int>, zone_x_normalised <int>, #   zone_y_normalised <int>, zone_width_normalised <int>, #   zone_height_normalised <int>, subject <fct>, acc <int>, TL <chr>, TR <chr>, #   BL <chr>, BR <chr>, trialtype <chr>, targetword <chr>, tlcode <chr>, #   trcode <chr>, blcode <chr>, brcode <chr>, targ_loc <chr>, … dat_long_aoi_me <- AOI  %>%   select(subject, trial, trialtype, target, cohort, unrelated, unrelated2, unrelated3,  rhyme, time, x_pred_normalised, y_pred_normalised, RT_audio) %>%     pivot_longer(         cols = c(target, unrelated, unrelated2, unrelated3, rhyme, cohort),         names_to = \"condition\",         values_to = \"look\"     ) dat_long_aoi_me_TCRU <- dat_long_aoi_me %>%   filter(trialtype==\"TCRU\") %>%   na.omit() gaze_sub <-dat_long_aoi_me_TCRU%>%  group_by(subject, trial) %>%   mutate(time = time-RT_audio) %>% # subtract audio rt onset for each  filter(time >= -100, time < 2000) %>% # start -100 to 2000 ms     dplyr::filter(x_pred_normalised > 0,                 x_pred_normalised < 1,                 y_pred_normalised > 0,                 y_pred_normalised < 1) %>%     mutate(bin= 100*floor(time/100)) %>% # timebin 100 ms ungroup() %>%    group_by(condition, bin) %>%   summarise(meanfix = mean(look, na.rm = TRUE)) %>%   ungroup() ggplot(gaze_sub, aes(y = meanfix, x = bin, color = condition)) +   #geom_ribbon(aes(ymin = Proportion - se, ymax = Proportion + se),    #           alpha = 0.5) +   # lines for proportions   geom_line() +   theme_lucid() +    # no grid lines   theme(panel.grid.major = element_blank(),          panel.grid.minor = element_blank(),         legend.position = \"right\",         # define x-axis tick labels         axis.text.x = element_text(angle = 45, vjust=0.6, size = 10)) +        labs(x = \"Time (in ms) centered around verb onset\", y = \"Proportion of looks\", color = \"Conditions\") +        #scale_color_discrete(labels = c(\"Constraining verb\",\"Non-constraining verb\")) +         #scale_color_manual(values=c(\"#F8766D\",\"#00BA38\"))+   # define y-axis   scale_y_continuous(name = \"Proportion in AOI\",                       limits = c(0, 1.0),                       breaks = seq(0, 1.0,.1),                       labels = seq(0, 1.0, .1)) +    ggtitle(\"TCRU\")"},{"path":"/articles/webgazeR_vignette.html","id":"behavioral-data","dir":"Articles","previous_headings":"","what":"Behavioral Data","title":"Introduction to webgazeR","text":"Gorilla produces .csv file include trial-level information (agg_ege_data). read object create object called emstr selects useful columns file renames stimuli make intuitive. user-specific, function called . describe pre-processing done behavioral data file. code processes transforms agg_eye_data dataset cleaned structured format analysis. First, code renames several columns easier access using janitor::clean_names function. filters dataset include rows zone_type “response_button_image”, representing picture selected trial. Afterward, function renames additional columns (tlpic TL, trpic TR, etc.). also renamed participant_private_id subject, spreadsheet_row trial, reaction_time RT. makes columns consistent edat merging later . Lastly, `reaction time (RT) converted numeric format numerical analysis.","code":"# load in trial level data agg_eye_data <- webgazeR::behav_data emstr <- agg_eye_data %>%      janitor::clean_names() %>%      # Select specific columns to keep in the dataset   dplyr::select(participant_private_id,  correct, tlpic, trpic, blpic, brpic, trialtype, targetword, tlcode, trcode, blcode, brcode, zone_name, zone_type,reaction_time, spreadsheet_row, response) %>%      # Filter the rows where 'Zone.Type' equals \"response_button_image\"   dplyr::filter(zone_type == \"response_button_image\") %>%      # Rename columns for easier use and readability   dplyr::rename(     \"TL\" = \"tlpic\",              # Rename 'tlpic' to 'TL'     \"TR\" = \"trpic\",             # Rename 'trpic' to 'TR'     \"BL\" = \"blpic\",            # Rename 'blpic' to 'BL'     \"BR\" = \"brpic\",                # Rename 'brpic' to 'BR'     \"targ_loc\" = \"zone_name\",       # Rename 'Zone.Name' to 'targ_loc'     \"subject\" = \"participant_private_id\",  # Rename 'Participant.Private.ID' to 'subject'     \"trial\" = \"spreadsheet_row\",    # Rename 'spreadsheet_row' to 'trial'     \"acc\" = \"correct\",              # Rename 'Correct' to 'acc' (accuracy)     \"RT\" = \"reaction_time\"          # Rename 'Reaction.Time' to 'RT'   ) %>%      # Convert the 'RT' (Reaction Time) column to numeric type   mutate(RT = as.numeric(RT),           subject=as.factor(subject),           trial=as.factor(trial))"},{"path":"/articles/webgazeR_vignette.html","id":"get-audio-onset-time","dir":"Articles","previous_headings":"","what":"Get audio onset time","title":"Introduction to webgazeR","text":"using audio trial running experiment browser audio onset never going conistent across participants. Gorilla option collect advanced audio features audio play requested, fired )played ended. want incorporate pipeline. Gorilla records onset audio varies participant. extracting filtering zone_type content_web_audio response equal “AUDIO PLAY EVENT FIRED”. tell us audio triggered experiment (reaction_time). merge information emstr. see RT_audio added dataframe.","code":"audio_rt <- agg_eye_data %>%      janitor::clean_names()%>%   select(participant_private_id,zone_type, spreadsheet_row, reaction_time, response) %>%    filter(zone_type==\"content_web_audio\", response==\"AUDIO PLAY EVENT FIRED\")%>%   distinct() %>% rename(\"subject\" = \"participant_private_id\",         \"trial\" =\"spreadsheet_row\",          \"RT_audio\" = \"reaction_time\") %>% select(-zone_type) %>% mutate(RT_audio=as.numeric(RT_audio)) trial_data_rt <- merge(emstr, audio_rt, by=c(\"subject\", \"trial\"))  head(trial_data_rt) %>%   head() %>%   tt()"},{"path":"/articles/webgazeR_vignette.html","id":"sampling-rate","dir":"Articles","previous_headings":"","what":"Sampling Rate","title":"Introduction to webgazeR","text":"commercial eye-trackers sample constant rate, webcam eye-trackers . code calculate sampling rate participant. Ideally, sampling rate less 5 Hz. recommended drop values. function analyze_sample_rate calculates calculates sampling rate subject trial eye-tracking dataset. provides overall statistics, including median standard deviation sampling rates experiment,also generates histogram median sampling rates subject density plot overlayed.  example, median sampling rate 24.77 SD 7.81. using function, separate data frames produced subjects trials. can added behavioral data object. can add behavioral data Users can use filter_sampling_rate function either either (1) throw data, subject, trial, , (2) label sampling rates certain threshold bad (TRUE FALSE). Let’s use filter_sampling_rate() function . read target_data_with_full_SR object. leave user decide make specific recommendations. case going remove data subject trial (action==“”) sampling frequency 5hz (threshold=5). filter_sampling_rate function designed process dataset containing subject-level trial-level sampling rates. allows user either filter data falls certain sampling rate threshold simply label “bad”. function gives flexibility allowing threshold applied subject level, trial level, . also lets user decide whether remove data flag threshold without removing . action = remove, function output many subjects trials removed threshold. filter_edat returns dataframe trials subjects removed. set argument action label, filter_edat_label return dataframe includes column(s) sampling rates < 5 labeled TRUE (bad) FALSE subjects threshold 5. However, 18 trials , removed.","code":"samp_rate <- analyze_sampling_rate(edat) Overall Median Sampling Rate (Hz): 24.76936956 Overall Standard Deviation of Sampling Rate (Hz): 7.807913315  Sampling Rate by Trial: # A tibble: 3,122 × 5 # Groups:   subject [23]     subject trial max_time n_times    SR       <int> <int>    <dbl>   <int> <dbl>  1 11788555     7    3664.     107  29.2  2 11788555     8    1295       39  30.1  3 11788555     9    2298.      68  29.6  4 11788555    10    1743.      52  29.8  5 11788555    12    1741.      52  29.9  6 11788555    13    1365.      40  29.3  7 11788555    15    1404.      40  28.5  8 11788555    16    1714.      51  29.8  9 11788555    21    1584.      47  29.7 10 11788555    27    2103.      62  29.5 # ℹ 3,112 more rows  Median Sampling Rate by Subject: # A tibble: 23 × 2     subject med_SR       <int>  <dbl>  1 11788555  29.6  2 11788682  29.7  3 11788824  23.9  4 11788857   8.79  5 11789574  11.5  6 11795362  22.6  7 11795372  24.8  8 11795375  28.5  9 11795376  29.9 10 11795379  30.4 # ℹ 13 more rows # Extract by-subject and by-trial sampling rates from the result subject_sampling_rate <- samp_rate$median_SR_by_subject  # Sampling rate by subject trial_sampling_rate <- samp_rate$SR_by_trial  # Sampling rate by trial trial_sampling_rate$subject<-as.factor(trial_sampling_rate$subject)  # Assuming target_data is your other dataset that contains subject and trial information # Append the by-subject sampling rate to target_data (based on subject) subject_sampling_rate$subject <- as.factor(subject_sampling_rate$subject)  target_data_with_subject_SR <- trial_data_rt %>%   left_join(subject_sampling_rate, by = \"subject\")  # Append the by-trial sampling rate to target_data (based on subject and trial)   trial_sampling_rate$trial <- as.factor(trial_sampling_rate$trial)   target_data_with_full_SR <- target_data_with_subject_SR %>%   select(subject, trial, med_SR)%>%   left_join(trial_sampling_rate, by = c(\"subject\", \"trial\")) trial_data <- left_join(trial_data_rt, target_data_with_full_SR, by=c(\"subject\", \"trial\")) filter_edat <- filter_sampling_rate(trial_data,threshold = 5,                                           action = \"remove\",                                           by = \"both\") filter_edat_label <- filter_sampling_rate(trial_data,threshold = 5,                                           action = \"label\",                                           by=\"both\")"},{"path":"/articles/webgazeR_vignette.html","id":"out-of-bounds-outside-of-screen","dir":"Articles","previous_headings":"","what":"Out-of-bounds (outside of screen)","title":"Introduction to webgazeR","text":"important include points fall outside standardized coordinates. gaze_oob function calculates many data points fall outside standardized range. function returns many data points fall outside range subject provides percentage. information useful include final paper. add -subject -trial bounds data exclude participants trials > 30% missing data.","code":"oob_data <- gaze_oob(edat) Subject: 11788555 Total points: 2483 Points outside the range: 608 Total missing percentage: 24.49% X: 17.28% Y: 13.53%   Subject: 11788682 Total points: 5798 Points outside the range: 551 Total missing percentage: 9.5% X: 6.83% Y: 3.47%   Subject: 11788824 Total points: 6961 Points outside the range: 1792 Total missing percentage: 25.74% X: 17.14% Y: 13.37%   Subject: 11788857 Total points: 2237 Points outside the range: 277 Total missing percentage: 12.38% X: 11.85% Y: 1.3%   Subject: 11789574 Total points: 932 Points outside the range: 221 Total missing percentage: 23.71% X: 14.16% Y: 16.09%   Subject: 11795362 Total points: 3951 Points outside the range: 608 Total missing percentage: 15.39% X: 10% Y: 7.69%   Subject: 11795372 Total points: 4598 Points outside the range: 677 Total missing percentage: 14.72% X: 9.11% Y: 8.22%   Subject: 11795375 Total points: 6795 Points outside the range: 1008 Total missing percentage: 14.83% X: 11.18% Y: 6.99%   Subject: 11795376 Total points: 6749 Points outside the range: 1676 Total missing percentage: 24.83% X: 13.48% Y: 16.42%   Subject: 11795379 Total points: 2247 Points outside the range: 350 Total missing percentage: 15.58% X: 4.36% Y: 12.28%   Subject: 11795382 Total points: 5239 Points outside the range: 528 Total missing percentage: 10.08% X: 6.91% Y: 5.99%   Subject: 11795385 Total points: 6172 Points outside the range: 1557 Total missing percentage: 25.23% X: 14.52% Y: 15.83%   Subject: 11795386 Total points: 4658 Points outside the range: 1397 Total missing percentage: 29.99% X: 17% Y: 22.33%   Subject: 11795387 Total points: 3634 Points outside the range: 586 Total missing percentage: 16.13% X: 9.41% Y: 9.25%   Subject: 11795388 Total points: 4097 Points outside the range: 755 Total missing percentage: 18.43% X: 11.33% Y: 11.11%   Subject: 11795426 Total points: 1242 Points outside the range: 122 Total missing percentage: 9.82% X: 6.44% Y: 6.44%   Subject: 11795446 Total points: 6712 Points outside the range: 546 Total missing percentage: 8.13% X: 5.91% Y: 4.68%   Subject: 11795529 Total points: 4668 Points outside the range: 482 Total missing percentage: 10.33% X: 6.92% Y: 4.86%   Subject: 11795650 Total points: 2213 Points outside the range: 101 Total missing percentage: 4.56% X: 2.08% Y: 2.89%   Subject: 11795671 Total points: 4982 Points outside the range: 1438 Total missing percentage: 28.86% X: 18.15% Y: 17.7%   Subject: 11796749 Total points: 6469 Points outside the range: 1891 Total missing percentage: 29.23% X: 23.09% Y: 13.48%   Subject: 11796756 Total points: 6249 Points outside the range: 820 Total missing percentage: 13.12% X: 7.25% Y: 8.64%   Subject: 11796779 Total points: 5737 Points outside the range: 253 Total missing percentage: 4.41% X: 2.18% Y: 2.75% oob_data %>%    tt()"},{"path":"/articles/webgazeR_vignette.html","id":"zone-coordinates","dir":"Articles","previous_headings":"","what":"Zone coordinates","title":"Introduction to webgazeR","text":"lab, can control every aspect experiment. Online cant . Participants going completing experiment variety conditions. includes using different computers, different screen dimensions. control , Gorilla outputs standardized zone coordinates. discussed Gorilla documentation, Gorilla layout engine lays everything 4:3 frame makes frame big possible. normalized coordinates expressed relative frame; example, coordinate 0.5, 0.5 always center screen, regardless size participant’s screen. used normalized coordinates analysis. However, different ways specify four coordinates screen, think worth highlighting. One way make AOIs big possible place four quadrants screen. need first create dataframe location AOI (e.g., TL, TR, BL, BR), x y normalized coordinates width height normalized. addition, get xmin, xmanx, ymax ymin AOIs. going remove poor convergence scales confidence. also remove coordinates 0 data. Next going combine eye-tracking data behavioral data using left_join function. Let’s verify AOIs look suppose .  Excellent! experiment four different trial types: Target, Cohort, Rhyme, Unrealted Target, Cohort, Unrealted, Unrelated Target, Unrelated, Unrealted, Unrelated Target, Rhyme, Unrelated, Unrelated first match pictures TL, TR, BL, BR columns correct code condition (T,C, R, U, U2, U3). study, need track condition image shown (Target, Cohort, Rhyme, Unrelated) also image located screen trial randomized trial. , use function named find_location. function designed determine location specific image screen comparing image list possible locations. function find_location first checks image NA (missing). image NA, function returns NA, meaning ’s location find image. image NA, function creates vector loc_names lists names possible locations. attempts match given image locations. match found, returns name location (e.g., TL, TR, BL, BR) image located. match, function returns NA. going use coordinate information . use assign_aoi adaopted gazeR package (Geller et al., 2020) loop object dat_colnames assign locations (.e., TR, TL, BL, BR) normalized x y coordinates. function label non-looks screen coordinates NA. make easier read change numerals assigned function actual screen locations. AOI object condition variables columns. example, fixation locations need “gathered” separate columns single column “NA” values need re-coded non-fixations (0). logically evaluate know item fixated sample . Now pivot instead condition individual column one column. helps visualization. pivot_longer make longer target, unrelated, unrealted2, unrelated3, rhyme, cohort columns. put column called condition place values 0 1 column called look. Non-looks two ways can handle missingness . can either re-code NA values non-looks, can exclude looks occurred outside AOI. going treat non-looks (0)","code":"# Create a data frame for the quadrants with an added column for the quadrant labels aoi_loc <- data.frame(   loc = c('TL', 'TR', 'BL', 'BR'),    x_normalized = c(0, 0.5, 0, 0.5),    y_normalized = c(0.5, 0.5, 0, 0),   width_normalized = c(0.5, 0.5, 0.5, 0.5),   height_normalized = c(0.5, 0.5, 0.5, 0.5)) %>%       mutate(xmin = x_normalized, ymin = y_normalized,          xmax = x_normalized+width_normalized,          ymax = y_normalized+height_normalized)  aoi_loc %>%   tt() edat_1 <- edat %>%  dplyr::filter(convergence <= .5, face_conf >= .5) %>%   # remove rows without gaze information   dplyr::filter(x_pred_normalised != 0,                 y_pred_normalised != 0) edat_1$subject<-as.factor(edat_1$subject) edat_1$trial<-as.factor(edat_1$trial)    dat <- left_join(edat_1, filter_edat, by = c(\"subject\",\"trial\"))  dat <- dat %>%   distinct() # make sure to remove duplicate rows #look at the AOIs and see if they make sense  # Create a data frame for the quadrants quadrants <- data.frame(   x = c(0, 0.5, 0, 0.5),   y = c(0.5, 0.5, 0, 0),   width = c(0.5, 0.5, 0.5, 0.5),   height = c(0.5, 0.5, 0.5, 0.5),   color = c('red', 'blue', 'green', 'orange'),   label = c('TL Width = 0.5', 'TR Width = 0.5', 'BL Width = 0.5', 'BR Width = 0.5') )  # Create the plot ggplot() +   geom_rect(data = quadrants, aes(xmin = x, xmax = x + width, ymin = y, ymax = y + height, fill = color),              color = 'black', alpha = 0) +   geom_text(data = quadrants, aes(x = x + width/2, y = y + height/2, label = label), color = 'black', size = 5) +   scale_fill_identity() +   coord_fixed() +   labs(x = 'Normalized X', y = 'Normalized Y', title = 'Quadrants with Width Annotations') +   theme_minimal() # Assuming your data is in a data frame called df dat <- dat %>%   mutate(     Target = case_when(       tlcode == \"T\" ~ TL,       trcode == \"T\" ~ TR,       blcode == \"T\" ~ BL,       brcode == \"T\" ~ BR,       TRUE ~ NA_character_  # Default to NA if no match     ),     Unrelated = case_when(       tlcode == \"U\" ~ TL,       trcode == \"U\" ~ TR,       blcode == \"U\" ~ BL,       brcode == \"U\" ~ BR,       TRUE ~ NA_character_     ),     Unrelated2 = case_when(       tlcode == \"U2\" ~ TL,       trcode == \"U2\" ~ TR,       blcode == \"U2\" ~ BL,       brcode == \"U2\" ~ BR,       TRUE ~ NA_character_     ),     Unrelated3 = case_when(       tlcode == \"U3\" ~ TL,       trcode == \"U3\" ~ TR,       blcode == \"U3\" ~ BL,       brcode == \"U3\" ~ BR,       TRUE ~ NA_character_     ),     Rhyme = case_when(       tlcode == \"R\" ~ TL,       trcode == \"R\" ~ TR,       blcode == \"R\" ~ BL,       brcode == \"R\" ~ BR,       TRUE ~ NA_character_     ),     Cohort = case_when(       tlcode == \"C\" ~ TL,       trcode == \"C\" ~ TR,       blcode == \"C\" ~ BL,       brcode == \"C\" ~ BR,       TRUE ~ NA_character_     )   ) head(dat) %>%      tt() # Apply the function to each of the targ, cohort, rhyme, and unrelated columns dat_colnames <- dat %>%   rowwise() %>%   mutate(     targ_loc = find_location(c(TL, TR, BL, BR), Target),     cohort_loc = find_location(c(TL, TR, BL, BR), Cohort),     rhyme_loc = find_location(c(TL, TR, BL, BR), Rhyme),     unrelated_loc = find_location(c(TL, TR, BL, BR), Unrelated),      unrealted2_loc= find_location(c(TL, TR, BL, BR), Unrelated2),      unrelated3_loc=find_location(c(TL, TR, BL, BR), Unrelated3)   ) %>%   ungroup() assign <- gazer::assign_aoi(dat_colnames,X=\"x_pred_normalised\", Y=\"y_pred_normalised\",aoi_loc = aoi_loc)   AOI <- assign %>%    mutate(loc1 = case_when(      AOI==1 ~ \"TL\",       AOI==2 ~ \"TR\",       AOI==3 ~ \"BL\",       AOI==4 ~ \"BR\"    ))  head(AOI) # A tibble: 6 × 58       X x0    filename   trial time_stamp  time type  screen_index x_pred y_pred   <int> <lgl> <chr>      <fct>      <dbl> <dbl> <chr>        <int>  <dbl>  <dbl> 1     1 NA    eyetracki… 153      1.73e12   0   pred…            4   922.  -61.7 2     2 NA    eyetracki… 153      1.73e12  34   pred…            4   958.   78.3 3     3 NA    eyetracki… 153      1.73e12  73.3 pred…            4  1036.  247. 4     4 NA    eyetracki… 153      1.73e12 113.  pred…            4  1048.  384. 5     5 NA    eyetracki… 153      1.73e12 148.  pred…            4  1018.  433. 6     6 NA    eyetracki… 153      1.73e12 182   pred…            4  1041.  515. # ℹ 48 more variables: x_pred_normalised <dbl>, y_pred_normalised <dbl>, #   convergence <int>, face_conf <dbl>, zone_name <lgl>, zone_x <int>, #   zone_y <int>, zone_width <int>, zone_height <int>, zone_x_normalised <int>, #   zone_y_normalised <int>, zone_width_normalised <int>, #   zone_height_normalised <int>, subject <fct>, acc <int>, TL <chr>, TR <chr>, #   BL <chr>, BR <chr>, trialtype <chr>, targetword <chr>, tlcode <chr>, #   trcode <chr>, blcode <chr>, brcode <chr>, targ_loc <chr>, … AOI$target <- ifelse(AOI$loc1==AOI$targ_loc, 1, 0) # if in coordinates 1, if not 0.   AOI$unrelated <- ifelse(AOI$loc1 == AOI$unrelated_loc, 1, 0)# if in coordinates 1, if not 0.   AOI$unrelated2 <- ifelse(AOI$loc1 == AOI$unrealted2_loc, 1, 0)# if in coordinates 1, if not 0.   AOI$unrelated3 <- ifelse(AOI$loc1 == AOI$unrelated3_loc, 1, 0)# if in coordinates 1, if not 0.   AOI$rhyme <- ifelse(AOI$loc1 == AOI$rhyme_loc, 1, 0)# if in coordinates 1, if not 0.    AOI$cohort <- ifelse(AOI$loc1 == AOI$cohort_loc, 1, 0)# if in coordinates 1, if not 0.   head(AOI) # A tibble: 6 × 64       X x0    filename   trial time_stamp  time type  screen_index x_pred y_pred   <int> <lgl> <chr>      <fct>      <dbl> <dbl> <chr>        <int>  <dbl>  <dbl> 1     1 NA    eyetracki… 153      1.73e12   0   pred…            4   922.  -61.7 2     2 NA    eyetracki… 153      1.73e12  34   pred…            4   958.   78.3 3     3 NA    eyetracki… 153      1.73e12  73.3 pred…            4  1036.  247. 4     4 NA    eyetracki… 153      1.73e12 113.  pred…            4  1048.  384. 5     5 NA    eyetracki… 153      1.73e12 148.  pred…            4  1018.  433. 6     6 NA    eyetracki… 153      1.73e12 182   pred…            4  1041.  515. # ℹ 54 more variables: x_pred_normalised <dbl>, y_pred_normalised <dbl>, #   convergence <int>, face_conf <dbl>, zone_name <lgl>, zone_x <int>, #   zone_y <int>, zone_width <int>, zone_height <int>, zone_x_normalised <int>, #   zone_y_normalised <int>, zone_width_normalised <int>, #   zone_height_normalised <int>, subject <fct>, acc <int>, TL <chr>, TR <chr>, #   BL <chr>, BR <chr>, trialtype <chr>, targetword <chr>, tlcode <chr>, #   trcode <chr>, blcode <chr>, brcode <chr>, targ_loc <chr>, … dat_long_aoi_me <- AOI  %>%   select(subject, trial, trialtype, target, cohort, unrelated, unrelated2, unrelated3,  rhyme, time, x_pred_normalised, y_pred_normalised, RT_audio) %>%     pivot_longer(         cols = c(target, unrelated, unrelated2, unrelated3, rhyme, cohort),         names_to = \"condition\",         values_to = \"look\"     )"},{"path":"/articles/webgazeR_vignette.html","id":"quadrant-approach","dir":"Articles","previous_headings":"","what":"Quadrant Approach","title":"Introduction to webgazeR","text":"One way make AOIs big possible place four quadrants screen. need first create dataframe location AOI (e.g., TL, TR, BL, BR), x y normalized coordinates width height normalized. addition, get xmin, xmanx, ymax ymin AOIs. going remove poor convergence scales confidence. also remove coordinates 0 data.","code":"# Create a data frame for the quadrants with an added column for the quadrant labels aoi_loc <- data.frame(   loc = c('TL', 'TR', 'BL', 'BR'),    x_normalized = c(0, 0.5, 0, 0.5),    y_normalized = c(0.5, 0.5, 0, 0),   width_normalized = c(0.5, 0.5, 0.5, 0.5),   height_normalized = c(0.5, 0.5, 0.5, 0.5)) %>%       mutate(xmin = x_normalized, ymin = y_normalized,          xmax = x_normalized+width_normalized,          ymax = y_normalized+height_normalized)  aoi_loc %>%   tt() edat_1 <- edat %>%  dplyr::filter(convergence <= .5, face_conf >= .5) %>%   # remove rows without gaze information   dplyr::filter(x_pred_normalised != 0,                 y_pred_normalised != 0)"},{"path":"/articles/webgazeR_vignette.html","id":"clean-up-eye-data","dir":"Articles","previous_headings":"","what":"Clean-up eye data","title":"Introduction to webgazeR","text":"going remove poor convergence scales confidence. also remove coordinates 0 data.","code":"edat_1 <- edat %>%  dplyr::filter(convergence <= .5, face_conf >= .5) %>%   # remove rows without gaze information   dplyr::filter(x_pred_normalised != 0,                 y_pred_normalised != 0)"},{"path":"/articles/webgazeR_vignette.html","id":"combining-eye-and-trial-level-data","dir":"Articles","previous_headings":"","what":"Combining Eye and Trial-level data","title":"Introduction to webgazeR","text":"Next going combine eye-tracking data behavioral data using left_join function. Let’s verify AOIs look suppose .  Excellent!","code":"edat_1$subject<-as.factor(edat_1$subject) edat_1$trial<-as.factor(edat_1$trial)    dat <- left_join(edat_1, filter_edat, by = c(\"subject\",\"trial\"))  dat <- dat %>%   distinct() # make sure to remove duplicate rows #look at the AOIs and see if they make sense  # Create a data frame for the quadrants quadrants <- data.frame(   x = c(0, 0.5, 0, 0.5),   y = c(0.5, 0.5, 0, 0),   width = c(0.5, 0.5, 0.5, 0.5),   height = c(0.5, 0.5, 0.5, 0.5),   color = c('red', 'blue', 'green', 'orange'),   label = c('TL Width = 0.5', 'TR Width = 0.5', 'BL Width = 0.5', 'BR Width = 0.5') )  # Create the plot ggplot() +   geom_rect(data = quadrants, aes(xmin = x, xmax = x + width, ymin = y, ymax = y + height, fill = color),              color = 'black', alpha = 0) +   geom_text(data = quadrants, aes(x = x + width/2, y = y + height/2, label = label), color = 'black', size = 5) +   scale_fill_identity() +   coord_fixed() +   labs(x = 'Normalized X', y = 'Normalized Y', title = 'Quadrants with Width Annotations') +   theme_minimal()"},{"path":"/articles/webgazeR_vignette.html","id":"matching-conditions-with-screen-locations","dir":"Articles","previous_headings":"","what":"Matching conditions with screen locations","title":"Introduction to webgazeR","text":"experiment four different trial types: Target, Cohort, Rhyme, Unrealted Target, Cohort, Unrealted, Unrelated Target, Unrelated, Unrealted, Unrelated Target, Rhyme, Unrelated, Unrelated first match pictures TL, TR, BL, BR columns correct code condition (T,C, R, U, U2, U3). study, need track condition image shown (Target, Cohort, Rhyme, Unrelated) also image located screen trial randomized trial. , use function named find_location. function designed determine location specific image screen comparing image list possible locations. function find_location first checks image NA (missing). image NA, function returns NA, meaning ’s location find image. image NA, function creates vector loc_names lists names possible locations. attempts match given image locations. match found, returns name location (e.g., TL, TR, BL, BR) image located. match, function returns NA. going use coordinate information . use assign_aoi adaopted gazeR package (Geller et al., 2020) loop object dat_colnames assign locations (.e., TR, TL, BL, BR) normalized x y coordinates. function label non-looks screen coordinates NA. make easier read change numerals assigned function actual screen locations. AOI object condition variables columns. example, fixation locations need “gathered” separate columns single column “NA” values need re-coded non-fixations (0). logically evaluate know item fixated sample . Now pivot instead condition individual column one column. helps visualization. pivot_longer make longer target, unrelated, unrealted2, unrelated3, rhyme, cohort columns. put column called condition place values 0 1 column called look. Non-looks two ways can handle missingness . can either re-code NA values non-looks, can exclude looks occurred outside AOI. going treat non-looks (0)","code":"# Assuming your data is in a data frame called df dat <- dat %>%   mutate(     Target = case_when(       tlcode == \"T\" ~ TL,       trcode == \"T\" ~ TR,       blcode == \"T\" ~ BL,       brcode == \"T\" ~ BR,       TRUE ~ NA_character_  # Default to NA if no match     ),     Unrelated = case_when(       tlcode == \"U\" ~ TL,       trcode == \"U\" ~ TR,       blcode == \"U\" ~ BL,       brcode == \"U\" ~ BR,       TRUE ~ NA_character_     ),     Unrelated2 = case_when(       tlcode == \"U2\" ~ TL,       trcode == \"U2\" ~ TR,       blcode == \"U2\" ~ BL,       brcode == \"U2\" ~ BR,       TRUE ~ NA_character_     ),     Unrelated3 = case_when(       tlcode == \"U3\" ~ TL,       trcode == \"U3\" ~ TR,       blcode == \"U3\" ~ BL,       brcode == \"U3\" ~ BR,       TRUE ~ NA_character_     ),     Rhyme = case_when(       tlcode == \"R\" ~ TL,       trcode == \"R\" ~ TR,       blcode == \"R\" ~ BL,       brcode == \"R\" ~ BR,       TRUE ~ NA_character_     ),     Cohort = case_when(       tlcode == \"C\" ~ TL,       trcode == \"C\" ~ TR,       blcode == \"C\" ~ BL,       brcode == \"C\" ~ BR,       TRUE ~ NA_character_     )   ) head(dat) %>%      tt() # Apply the function to each of the targ, cohort, rhyme, and unrelated columns dat_colnames <- dat %>%   rowwise() %>%   mutate(     targ_loc = find_location(c(TL, TR, BL, BR), Target),     cohort_loc = find_location(c(TL, TR, BL, BR), Cohort),     rhyme_loc = find_location(c(TL, TR, BL, BR), Rhyme),     unrelated_loc = find_location(c(TL, TR, BL, BR), Unrelated),      unrealted2_loc= find_location(c(TL, TR, BL, BR), Unrelated2),      unrelated3_loc=find_location(c(TL, TR, BL, BR), Unrelated3)   ) %>%   ungroup() assign <- gazer::assign_aoi(dat_colnames,X=\"x_pred_normalised\", Y=\"y_pred_normalised\",aoi_loc = aoi_loc)   AOI <- assign %>%    mutate(loc1 = case_when(      AOI==1 ~ \"TL\",       AOI==2 ~ \"TR\",       AOI==3 ~ \"BL\",       AOI==4 ~ \"BR\"    ))  head(AOI) # A tibble: 6 × 58       X x0    filename   trial time_stamp  time type  screen_index x_pred y_pred   <int> <lgl> <chr>      <fct>      <dbl> <dbl> <chr>        <int>  <dbl>  <dbl> 1     1 NA    eyetracki… 153      1.73e12   0   pred…            4   922.  -61.7 2     2 NA    eyetracki… 153      1.73e12  34   pred…            4   958.   78.3 3     3 NA    eyetracki… 153      1.73e12  73.3 pred…            4  1036.  247. 4     4 NA    eyetracki… 153      1.73e12 113.  pred…            4  1048.  384. 5     5 NA    eyetracki… 153      1.73e12 148.  pred…            4  1018.  433. 6     6 NA    eyetracki… 153      1.73e12 182   pred…            4  1041.  515. # ℹ 48 more variables: x_pred_normalised <dbl>, y_pred_normalised <dbl>, #   convergence <int>, face_conf <dbl>, zone_name <lgl>, zone_x <int>, #   zone_y <int>, zone_width <int>, zone_height <int>, zone_x_normalised <int>, #   zone_y_normalised <int>, zone_width_normalised <int>, #   zone_height_normalised <int>, subject <fct>, acc <int>, TL <chr>, TR <chr>, #   BL <chr>, BR <chr>, trialtype <chr>, targetword <chr>, tlcode <chr>, #   trcode <chr>, blcode <chr>, brcode <chr>, targ_loc <chr>, … AOI$target <- ifelse(AOI$loc1==AOI$targ_loc, 1, 0) # if in coordinates 1, if not 0.   AOI$unrelated <- ifelse(AOI$loc1 == AOI$unrelated_loc, 1, 0)# if in coordinates 1, if not 0.   AOI$unrelated2 <- ifelse(AOI$loc1 == AOI$unrealted2_loc, 1, 0)# if in coordinates 1, if not 0.   AOI$unrelated3 <- ifelse(AOI$loc1 == AOI$unrelated3_loc, 1, 0)# if in coordinates 1, if not 0.   AOI$rhyme <- ifelse(AOI$loc1 == AOI$rhyme_loc, 1, 0)# if in coordinates 1, if not 0.    AOI$cohort <- ifelse(AOI$loc1 == AOI$cohort_loc, 1, 0)# if in coordinates 1, if not 0.   head(AOI) # A tibble: 6 × 64       X x0    filename   trial time_stamp  time type  screen_index x_pred y_pred   <int> <lgl> <chr>      <fct>      <dbl> <dbl> <chr>        <int>  <dbl>  <dbl> 1     1 NA    eyetracki… 153      1.73e12   0   pred…            4   922.  -61.7 2     2 NA    eyetracki… 153      1.73e12  34   pred…            4   958.   78.3 3     3 NA    eyetracki… 153      1.73e12  73.3 pred…            4  1036.  247. 4     4 NA    eyetracki… 153      1.73e12 113.  pred…            4  1048.  384. 5     5 NA    eyetracki… 153      1.73e12 148.  pred…            4  1018.  433. 6     6 NA    eyetracki… 153      1.73e12 182   pred…            4  1041.  515. # ℹ 54 more variables: x_pred_normalised <dbl>, y_pred_normalised <dbl>, #   convergence <int>, face_conf <dbl>, zone_name <lgl>, zone_x <int>, #   zone_y <int>, zone_width <int>, zone_height <int>, zone_x_normalised <int>, #   zone_y_normalised <int>, zone_width_normalised <int>, #   zone_height_normalised <int>, subject <fct>, acc <int>, TL <chr>, TR <chr>, #   BL <chr>, BR <chr>, trialtype <chr>, targetword <chr>, tlcode <chr>, #   trcode <chr>, blcode <chr>, brcode <chr>, targ_loc <chr>, … dat_long_aoi_me <- AOI  %>%   select(subject, trial, trialtype, target, cohort, unrelated, unrelated2, unrelated3,  rhyme, time, x_pred_normalised, y_pred_normalised, RT_audio) %>%     pivot_longer(         cols = c(target, unrelated, unrelated2, unrelated3, rhyme, cohort),         names_to = \"condition\",         values_to = \"look\"     )"},{"path":"/articles/webgazeR_vignette.html","id":"samples-to-bins","dir":"Articles","previous_headings":"","what":"Samples to bins","title":"Introduction to webgazeR","text":"presentation audio delay played. coded RT_audio. change time correspond audio_onset. can subtracting RT_audio time. Researchers may decide sample data. sample 100 ms bins get aggregate across time condition plotting. Bramlett Wiener notice significant difference bin size long sampling rate > 5Hz. addition, also remove coordinates outside standardized window. end proportion looks AOIs stored meanfix column.","code":"dat_long_aoi_me_TCRU <- dat_long_aoi_me %>%   filter(trialtype==\"TCRU\") %>%   na.omit() gaze_sub <-dat_long_aoi_me_TCRU%>%  group_by(subject, trial) %>%   mutate(time = time-RT_audio) %>% # subtract audio rt onset for each  filter(time >= -100, time < 2000) %>% # start -100 to 2000 ms     dplyr::filter(x_pred_normalised > 0,                 x_pred_normalised < 1,                 y_pred_normalised > 0,                 y_pred_normalised < 1) %>%     mutate(bin= 100*floor(time/100)) %>% # timebin 100 ms ungroup() %>%    group_by(condition, bin) %>%   summarise(meanfix = mean(look, na.rm = TRUE)) %>%   ungroup() ggplot(gaze_sub, aes(y = meanfix, x = bin, color = condition)) +   #geom_ribbon(aes(ymin = Proportion - se, ymax = Proportion + se),    #           alpha = 0.5) +   # lines for proportions   geom_line() +   theme_lucid() +    # no grid lines   theme(panel.grid.major = element_blank(),          panel.grid.minor = element_blank(),         legend.position = \"right\",         # define x-axis tick labels         axis.text.x = element_text(angle = 45, vjust=0.6, size = 10)) +        labs(x = \"Time (in ms) centered around verb onset\", y = \"Proportion of looks\", color = \"Conditions\") +        #scale_color_discrete(labels = c(\"Constraining verb\",\"Non-constraining verb\")) +         #scale_color_manual(values=c(\"#F8766D\",\"#00BA38\"))+   # define y-axis   scale_y_continuous(name = \"Proportion in AOI\",                       limits = c(0, 1.0),                       breaks = seq(0, 1.0,.1),                       labels = seq(0, 1.0, .1)) +    ggtitle(\"TCRU\")"},{"path":"/articles/webgazeR_vignette.html","id":"tcru","dir":"Articles","previous_headings":"","what":"TCRU","title":"Introduction to webgazeR","text":"","code":"dat_long_aoi_me_TCRU <- dat_long_aoi_me %>%   filter(trialtype==\"TCRU\") %>%   na.omit() gaze_sub <-dat_long_aoi_me_TCRU%>%  group_by(subject, trial) %>%   mutate(time = time-RT_audio) %>% # subtract audio rt onset for each  filter(time >= -100, time < 2000) %>% # start -100 to 2000 ms     dplyr::filter(x_pred_normalised > 0,                 x_pred_normalised < 1,                 y_pred_normalised > 0,                 y_pred_normalised < 1) %>%     mutate(bin= 100*floor(time/100)) %>% # timebin 100 ms ungroup() %>%    group_by(condition, bin) %>%   summarise(meanfix = mean(look, na.rm = TRUE)) %>%   ungroup() ggplot(gaze_sub, aes(y = meanfix, x = bin, color = condition)) +   #geom_ribbon(aes(ymin = Proportion - se, ymax = Proportion + se),    #           alpha = 0.5) +   # lines for proportions   geom_line() +   theme_lucid() +    # no grid lines   theme(panel.grid.major = element_blank(),          panel.grid.minor = element_blank(),         legend.position = \"right\",         # define x-axis tick labels         axis.text.x = element_text(angle = 45, vjust=0.6, size = 10)) +        labs(x = \"Time (in ms) centered around verb onset\", y = \"Proportion of looks\", color = \"Conditions\") +        #scale_color_discrete(labels = c(\"Constraining verb\",\"Non-constraining verb\")) +         #scale_color_manual(values=c(\"#F8766D\",\"#00BA38\"))+   # define y-axis   scale_y_continuous(name = \"Proportion in AOI\",                       limits = c(0, 1.0),                       breaks = seq(0, 1.0,.1),                       labels = seq(0, 1.0, .1)) +    ggtitle(\"TCRU\")"},{"path":"/articles/webgazeR_vignette.html","id":"plotting","dir":"Articles","previous_headings":"","what":"Plotting","title":"Introduction to webgazeR","text":"","code":"ggplot(gaze_sub, aes(y = meanfix, x = bin, color = condition)) +   #geom_ribbon(aes(ymin = Proportion - se, ymax = Proportion + se),    #           alpha = 0.5) +   # lines for proportions   geom_line() +   theme_lucid() +    # no grid lines   theme(panel.grid.major = element_blank(),          panel.grid.minor = element_blank(),         legend.position = \"right\",         # define x-axis tick labels         axis.text.x = element_text(angle = 45, vjust=0.6, size = 10)) +        labs(x = \"Time (in ms) centered around verb onset\", y = \"Proportion of looks\", color = \"Conditions\") +        #scale_color_discrete(labels = c(\"Constraining verb\",\"Non-constraining verb\")) +         #scale_color_manual(values=c(\"#F8766D\",\"#00BA38\"))+   # define y-axis   scale_y_continuous(name = \"Proportion in AOI\",                       limits = c(0, 1.0),                       breaks = seq(0, 1.0,.1),                       labels = seq(0, 1.0, .1)) +    ggtitle(\"TCRU\")"},{"path":"/articles/webgazeR_vignette.html","id":"gorilla-provided-coordinates","dir":"Articles","previous_headings":"","what":"Gorilla provided coordinates","title":"Introduction to webgazeR","text":"open individual .xlsx file provided gorilla see provides standardized coordinates location: TL, TR, BL, BR. Let’s use coordinates instead setting general coordinates. use function extract_aois get coordinates quadrant screen. can use zone_names argument get zones want use. table extract_aois function return. see AOIs bit smaller now gorilla provided coordinates.  AOI object condition variables columns. example, fixation locations need “gathered” separate columns single column “NA” values need re-coded non-fixations (0). logically evaluate know item fixated sample . Now pivot instead condition individual column one column. Non-looks two ways can handle missingness . can either re-code NA values non-looks, can exclude looks occurred outside AOI. going treat non-looks missing variables exclude .  see effect lot larger using gorilla provided coordinates.","code":"aois <- extract_aois(vwp_paths_filtered, zone_names =  c(\"TL\", \"BR\", \"TR\", \"BL\")) # Define the data aois <- data.frame(   loc = c(\"BL\", \"TL\", \"TR\", \"BR\"),   x_normalized = c(0.03, 0.02, 0.73, 0.73),   y_normalized = c(0.04, 0.74, 0.75, 0.06),   width_normalized = c(0.26, 0.26, 0.24, 0.23),   height_normalized = c(0.25, 0.25, 0.24, 0.25),   xmin = c(0.03, 0.02, 0.73, 0.73),   ymin = c(0.04, 0.74, 0.75, 0.06),   xmax = c(0.29, 0.28, 0.97, 0.96),   ymax = c(0.29, 0.99, 0.99, 0.31) )  aois %>%   tt() #look at the AOIs and see if they make sense  # Create a data frame for the quadrants quadrants <- data.frame(   x = aois$x_normalized,   y = aois$y_normalized,   width = aois$width_normalized,   height = aois$height_normalized,   color = c('red', 'blue', 'green', 'orange'),   label = c('BL Width = 0.5', 'TL Width = 0.5', 'TR Width = 0.5', 'BR Width = 0.5') )  # Create the plot ggplot() +   geom_rect(data = quadrants, aes(xmin = x, xmax = x + width, ymin = y, ymax = y + height, fill = color),              color = 'black', alpha = 0) +   geom_text(data = quadrants, aes(x = x + width/2, y = y + height/2, label = label), color = 'black', size = 5) +   scale_fill_identity() +   coord_fixed() +   labs(x = 'Normalized X', y = 'Normalized Y', title = 'Quadrants with Width Annotations') +   theme_minimal() assign <- gazer::assign_aoi(dat_colnames,X=\"x_pred_normalised\", Y=\"y_pred_normalised\",aoi_loc = aois)   AOI <- assign %>%    mutate(loc1 = case_when(      AOI==1 ~ \"BL\",       AOI==2 ~ \"TL\",       AOI==3 ~ \"TR\",       AOI==4 ~ \"BR\"    ))  head(AOI) # A tibble: 6 × 58       X x0    filename   trial time_stamp  time type  screen_index x_pred y_pred   <int> <lgl> <chr>      <fct>      <dbl> <dbl> <chr>        <int>  <dbl>  <dbl> 1     1 NA    eyetracki… 153      1.73e12   0   pred…            4   922.  -61.7 2     2 NA    eyetracki… 153      1.73e12  34   pred…            4   958.   78.3 3     3 NA    eyetracki… 153      1.73e12  73.3 pred…            4  1036.  247. 4     4 NA    eyetracki… 153      1.73e12 113.  pred…            4  1048.  384. 5     5 NA    eyetracki… 153      1.73e12 148.  pred…            4  1018.  433. 6     6 NA    eyetracki… 153      1.73e12 182   pred…            4  1041.  515. # ℹ 48 more variables: x_pred_normalised <dbl>, y_pred_normalised <dbl>, #   convergence <int>, face_conf <dbl>, zone_name <lgl>, zone_x <int>, #   zone_y <int>, zone_width <int>, zone_height <int>, zone_x_normalised <int>, #   zone_y_normalised <int>, zone_width_normalised <int>, #   zone_height_normalised <int>, subject <fct>, acc <int>, TL <chr>, TR <chr>, #   BL <chr>, BR <chr>, trialtype <chr>, targetword <chr>, tlcode <chr>, #   trcode <chr>, blcode <chr>, brcode <chr>, targ_loc <chr>, … AOI$target <- ifelse(AOI$loc1==AOI$targ_loc, 1, 0) # if in coordinates 1, if not 0.   AOI$unrelated <- ifelse(AOI$loc1 == AOI$unrelated_loc, 1, 0)# if in coordinates 1, if not 0.   AOI$unrelated2 <- ifelse(AOI$loc1 == AOI$unrealted2_loc, 1, 0)# if in coordinates 1, if not 0.   AOI$unrelated3 <- ifelse(AOI$loc1 == AOI$unrelated3_loc, 1, 0)# if in coordinates 1, if not 0.   AOI$rhyme <- ifelse(AOI$loc1 == AOI$rhyme_loc, 1, 0)# if in coordinates 1, if not 0.    AOI$cohort <- ifelse(AOI$loc1 == AOI$cohort_loc, 1, 0)# if in coordinates 1, if not 0.   head(AOI) # A tibble: 6 × 64       X x0    filename   trial time_stamp  time type  screen_index x_pred y_pred   <int> <lgl> <chr>      <fct>      <dbl> <dbl> <chr>        <int>  <dbl>  <dbl> 1     1 NA    eyetracki… 153      1.73e12   0   pred…            4   922.  -61.7 2     2 NA    eyetracki… 153      1.73e12  34   pred…            4   958.   78.3 3     3 NA    eyetracki… 153      1.73e12  73.3 pred…            4  1036.  247. 4     4 NA    eyetracki… 153      1.73e12 113.  pred…            4  1048.  384. 5     5 NA    eyetracki… 153      1.73e12 148.  pred…            4  1018.  433. 6     6 NA    eyetracki… 153      1.73e12 182   pred…            4  1041.  515. # ℹ 54 more variables: x_pred_normalised <dbl>, y_pred_normalised <dbl>, #   convergence <int>, face_conf <dbl>, zone_name <lgl>, zone_x <int>, #   zone_y <int>, zone_width <int>, zone_height <int>, zone_x_normalised <int>, #   zone_y_normalised <int>, zone_width_normalised <int>, #   zone_height_normalised <int>, subject <fct>, acc <int>, TL <chr>, TR <chr>, #   BL <chr>, BR <chr>, trialtype <chr>, targetword <chr>, tlcode <chr>, #   trcode <chr>, blcode <chr>, brcode <chr>, targ_loc <chr>, … dat_long_aoi_me <- AOI  %>%   select(subject, trial, target, cohort, unrelated, rhyme, time, x_pred_normalised, y_pred_normalised, RT_audio) %>%     pivot_longer(         cols = c(target, unrelated, rhyme, cohort),         names_to = \"condition\",         values_to = \"look\"     ) gaze_sub <-dat_long_aoi_me%>%  group_by(subject, trial) %>%   mutate(time = time-RT_audio) %>% # subtract audio rt onset for each  filter(time >= -100, time < 2000) %>%     dplyr::filter(x_pred_normalised > 0,                 x_pred_normalised < 1,                 y_pred_normalised > 0,                 y_pred_normalised < 1) %>%     mutate(bin= 100*floor(time/100)) %>% # timebin 100 ms ungroup() %>%    group_by(condition, bin) %>%   summarise(meanfix = mean(look, na.rm = TRUE)) %>%   ungroup() ggplot(gaze_sub, aes(y = meanfix, x = bin, color = condition)) +   #geom_ribbon(aes(ymin = Proportion - se, ymax = Proportion + se),    #           alpha = 0.5) +   # lines for proportions   geom_line() +   theme_bw() +    # no grid lines   theme(panel.grid.major = element_blank(),          panel.grid.minor = element_blank(),         legend.position = \"right\",         # define x-axis tick labels         axis.text.x = element_text(angle = 45, vjust=0.6, size = 10)) +        labs(x = \"Time (in ms) centered around verb onset\", y = \"Proportion of looks\", color = \"Conditions\") +        #scale_color_discrete(labels = c(\"Constraining verb\",\"Non-constraining verb\")) +         #scale_color_manual(values=c(\"#F8766D\",\"#00BA38\"))+   # define y-axis   scale_y_continuous(name = \"Proportion in AOI\",                       limits = c(0, 1.0),                       breaks = seq(0, 1.0,.1),                       labels = seq(0, 1.0, .1))"},{"path":"/articles/webgazeR_vignette.html","id":"samples-to-bins-1","dir":"Articles","previous_headings":"","what":"Samples to bins","title":"Introduction to webgazeR","text":"","code":"gaze_sub <-dat_long_aoi_me%>%  group_by(subject, trial) %>%   mutate(time = time-RT_audio) %>% # subtract audio rt onset for each  filter(time >= -100, time < 2000) %>%     dplyr::filter(x_pred_normalised > 0,                 x_pred_normalised < 1,                 y_pred_normalised > 0,                 y_pred_normalised < 1) %>%     mutate(bin= 100*floor(time/100)) %>% # timebin 100 ms ungroup() %>%    group_by(condition, bin) %>%   summarise(meanfix = mean(look, na.rm = TRUE)) %>%   ungroup()"},{"path":"/articles/webgazeR_vignette.html","id":"plotting-1","dir":"Articles","previous_headings":"","what":"Plotting","title":"Introduction to webgazeR","text":"see effect lot larger using gorilla provided coordinates.","code":"ggplot(gaze_sub, aes(y = meanfix, x = bin, color = condition)) +   #geom_ribbon(aes(ymin = Proportion - se, ymax = Proportion + se),    #           alpha = 0.5) +   # lines for proportions   geom_line() +   theme_bw() +    # no grid lines   theme(panel.grid.major = element_blank(),          panel.grid.minor = element_blank(),         legend.position = \"right\",         # define x-axis tick labels         axis.text.x = element_text(angle = 45, vjust=0.6, size = 10)) +        labs(x = \"Time (in ms) centered around verb onset\", y = \"Proportion of looks\", color = \"Conditions\") +        #scale_color_discrete(labels = c(\"Constraining verb\",\"Non-constraining verb\")) +         #scale_color_manual(values=c(\"#F8766D\",\"#00BA38\"))+   # define y-axis   scale_y_continuous(name = \"Proportion in AOI\",                       limits = c(0, 1.0),                       breaks = seq(0, 1.0,.1),                       labels = seq(0, 1.0, .1))"},{"path":"/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Jason Geller. Author, maintainer. Yanina Prystauka. Author, maintainer.","code":""},{"path":"/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Geller J, Prystauka Y (2024). webgazeR: Tools Processing Webcam Eye Tracking Data. R package version 0.1.0.","code":"@Manual{,   title = {webgazeR: Tools for Processing Webcam Eye Tracking Data},   author = {Jason Geller and Yanina Prystauka},   year = {2024},   note = {R package version 0.1.0}, }"},{"path":"/index.html","id":"webgazer","dir":"","previous_headings":"","what":"Tools for Processing Webcam Eye Tracking Data","title":"Tools for Processing Webcam Eye Tracking Data","text":"Functions analyzing webcam eye-tracking data","code":""},{"path":"/reference/analyze_sampling_rate.html","id":null,"dir":"Reference","previous_headings":"","what":"Analyze Sampling Rates for Eye-Tracking Data — analyze_sampling_rate","title":"Analyze Sampling Rates for Eye-Tracking Data — analyze_sampling_rate","text":"function calculates sampling rate subject trial eye-tracking dataset. provides overall statistics, including median standard deviation sampling rates, also generates histogram median sampling rates subject, density plot overlayed, vertical line showing overall median sampling rate standard deviation displayed.","code":""},{"path":"/reference/analyze_sampling_rate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Analyze Sampling Rates for Eye-Tracking Data — analyze_sampling_rate","text":"","code":"analyze_sampling_rate(eye_data)"},{"path":"/reference/analyze_sampling_rate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Analyze Sampling Rates for Eye-Tracking Data — analyze_sampling_rate","text":"eye_data dataframe containing eye-tracking data columns `subject`, `trial`, `time`. column `time` represent time milliseconds trial.","code":""},{"path":"/reference/analyze_sampling_rate.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Analyze Sampling Rates for Eye-Tracking Data — analyze_sampling_rate","text":"list containing: overall_median_SR overall median sampling rate (Hz). overall_sd_SR overall standard deviation sampling rates. median_SR_by_subject dataframe median sampling rate subject. SR_by_trial dataframe sampling rate subject trial.","code":""},{"path":"/reference/analyze_sampling_rate.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Analyze Sampling Rates for Eye-Tracking Data — analyze_sampling_rate","text":"","code":"if (FALSE) { # \\dontrun{   # Assuming eye_data is a dataframe with appropriate columns   result <- analyze_sampling_rate(eye_data)   print(result) } # }"},{"path":"/reference/assign_aoi.html","id":null,"dir":"Reference","previous_headings":"","what":"Assign coordinates to areas of interest — assign_aoi","title":"Assign coordinates to areas of interest — assign_aoi","text":"Takes data frame gaze positions (locations), plus screen size aoi size (location), computes area interest (AOI) location. Defaults assume standard four-corner design.","code":""},{"path":"/reference/assign_aoi.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Assign coordinates to areas of interest — assign_aoi","text":"","code":"assign_aoi(   gaze,   screen_size = c(1024, 768),   aoi_size = c(400, 300),   aoi_loc = NULL,   X = \"CURRENT_FIX_X\",   Y = \"CURRENT_FIX_Y\" )"},{"path":"/reference/assign_aoi.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Assign coordinates to areas of interest — assign_aoi","text":"gaze data frame containing positions screen_size size screen pixels. Defaults c(1024, 768) assumes reversed vertical (.e., [0,0] top left). aoi_size size AOIs pixels. Defaults c(400, 300) width-height pair assumes AOIs screen corners. AOIs coded numerically 1 4 reading order (left right, top bottom), 0 center location. aoi_loc location rectangular AOIs. Use alternative aoi_size non-corner AOIs. AOI location separate row data frame variables xmin, xmax, ymin, ymax. Assumes reversed vertical (.e., [0,0] top left). AOIs coded numerically row order. X name variable containing X coordinates. Defaults \"CURRENT_FIX_X\" Y name variable containing Y coordinates. Defaults \"CURRENT_FIX_Y\"","code":""},{"path":"/reference/assign_aoi.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Assign coordinates to areas of interest — assign_aoi","text":"Original gaze data frame AOI column added. Non-AOI -screen gazes marked NA.","code":""},{"path":"/reference/downsample_gaze.html","id":null,"dir":"Reference","previous_headings":"","what":"Downsample gaze data — downsample_gaze","title":"Downsample gaze data — downsample_gaze","text":"function combine gaze samples time bins.","code":""},{"path":"/reference/downsample_gaze.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Downsample gaze data — downsample_gaze","text":"","code":"downsample_gaze(   dataframe,   bin.length = 50,   timevar = \"time\",   aggvars = c(\"subject\", \"condition\", \"target\", \"trial\", \"object\", \"timebins\") )"},{"path":"/reference/downsample_gaze.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Downsample gaze data — downsample_gaze","text":"dataframe DataFrame containing gaze data. bin.length Length time bins (milliseconds). timevar Column name representing time. aggvars Vector variable names group aggregation.","code":""},{"path":"/reference/downsample_gaze.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Downsample gaze data — downsample_gaze","text":"Downsampled DataFrame.","code":""},{"path":"/reference/extract_aois.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract AOI-related Columns from Webcam Files and Calculate Locations — extract_aois","title":"Extract AOI-related Columns from Webcam Files and Calculate Locations — extract_aois","text":"function reads multiple Gorilla webcam files, extracts `loc`, `x_normalised`, `y_normalised`, `width_normalised`, `height_normalised` columns, calculates bounding box coordinates AOIs. also rounds numeric columns 3 decimal places.","code":""},{"path":"/reference/extract_aois.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract AOI-related Columns from Webcam Files and Calculate Locations — extract_aois","text":"","code":"extract_aois(file_paths, zone_names = NULL)"},{"path":"/reference/extract_aois.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract AOI-related Columns from Webcam Files and Calculate Locations — extract_aois","text":"file_paths list file paths webcam files (.xlsx format).","code":""},{"path":"/reference/extract_aois.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract AOI-related Columns from Webcam Files and Calculate Locations — extract_aois","text":"dataframe containing distinct rows AOI-related columns calculated coordinates.","code":""},{"path":"/reference/extract_aois.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract AOI-related Columns from Webcam Files and Calculate Locations — extract_aois","text":"","code":"# Example usage: # file_paths <- c(\"file1.xlsx\", \"file2.xlsx\") # aoi_data <- extract_aois(file_paths)"},{"path":"/reference/filter_sampling_rate.html","id":null,"dir":"Reference","previous_headings":"","what":"Filter or Label Data Based on Sampling Rate Threshold — filter_sampling_rate","title":"Filter or Label Data Based on Sampling Rate Threshold — filter_sampling_rate","text":"function allows users set sampling rate threshold choose either remove data falls threshold label \"bad.\" Users can apply threshold either subject level, trial level, .","code":""},{"path":"/reference/filter_sampling_rate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Filter or Label Data Based on Sampling Rate Threshold — filter_sampling_rate","text":"","code":"filter_sampling_rate(   data,   threshold = NA,   action = c(\"remove\", \"label\"),   by = c(\"subject\", \"trial\", \"both\") )"},{"path":"/reference/filter_sampling_rate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Filter or Label Data Based on Sampling Rate Threshold — filter_sampling_rate","text":"data dataframe contains data processed. dataframe include columns: `subject` Unique identifier participant dataset. `med_SR` Subject-level median sampling rate (Hz). represents median sampling rate subject across trials. `SR` Trial-level sampling rate (Hz). represents sampling rate specific trial. threshold Numeric value specifying sampling rate threshold. Data falling threshold either removed labeled \"bad\". action Character string specifying whether \"remove\" data falls threshold \"label\" bad. Acceptable values `\"remove\"` `\"label\"`. `\"remove\"` Removes rows dataset sampling rate falls threshold. `\"label\"` Adds new columns `is_bad_subject` /`is_bad_trial` flag rows sampling rate falls threshold. Character string specifying whether threshold applied \"subject\" level, \"trial\" level, \"\". Acceptable values `\"subject\"`, `\"trial\"`, `\"\"`. `\"subject\"` Applies threshold subject-level median sampling rate (`med_SR`). `\"trial\"` Applies threshold trial-level sampling rate (`SR`). `\"\"` Applies threshold subject-level (`med_SR`) trial-level (`SR`) rates. Data removed/labeled either rate falls threshold.","code":""},{"path":"/reference/filter_sampling_rate.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Filter or Label Data Based on Sampling Rate Threshold — filter_sampling_rate","text":"dataframe either rows removed new columns (`is_bad_subject`, `is_bad_trial`) added indicate whether data threshold. Additionally, messages inform user many subjects trials removed labeled \"bad.\"","code":""},{"path":"/reference/filter_sampling_rate.html","id":"output","dir":"Reference","previous_headings":"","what":"Output","title":"Filter or Label Data Based on Sampling Rate Threshold — filter_sampling_rate","text":"function either return dataset rows removed based sampling rate threshold add new columns, `is_bad_subject` /`is_bad_trial` dataset, indicates whether data considered \"bad\" (.e., sampling rate threshold).","code":""},{"path":"/reference/filter_sampling_rate.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Filter or Label Data Based on Sampling Rate Threshold — filter_sampling_rate","text":"","code":"# Example usage of the filter_sampling_rate function result <- filter_sampling_rate(data = data_with_sr, threshold = 500, action = \"remove\", by = \"both\") #> Error in eval(expr, envir, enclos): object 'data_with_sr' not found # Example usage to label data as \"bad\" result <- filter_sampling_rate(data = data_with_sr, threshold = 500, action = \"label\", by = \"trial\") #> Error in eval(expr, envir, enclos): object 'data_with_sr' not found"},{"path":"/reference/find_location.html","id":null,"dir":"Reference","previous_headings":"","what":"Find Image Location in a Given Set of Locations — find_location","title":"Find Image Location in a Given Set of Locations — find_location","text":"function determines location image within set locations. function accepts vector locations (\"TL\", \"TR\", \"BL\", \"BR\") image identifier. returns corresponding location name image found, `NA` image present `NA`.","code":""},{"path":"/reference/find_location.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Find Image Location in a Given Set of Locations — find_location","text":"","code":"find_location(locations, image)"},{"path":"/reference/find_location.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Find Image Location in a Given Set of Locations — find_location","text":"locations character vector representing possible locations (e.g., `c(\"TL\", \"TR\", \"BL\", \"BR\")`). image character value representing image find locations.","code":""},{"path":"/reference/find_location.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Find Image Location in a Given Set of Locations — find_location","text":"character string representing location image, `NA` image found missing.","code":""},{"path":"/reference/find_location.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Find Image Location in a Given Set of Locations — find_location","text":"","code":"# Example usage of the find_location function locations <- c(\"apple\", \"banana\", \"cherry\", \"date\") find_location(locations, \"banana\")  # Returns \"TR\" if locations follow c(\"TL\", \"TR\", \"BL\", \"BR\") #> [1] \"TR\" find_location(locations, \"orange\")  # Returns NA #> [1] NA"},{"path":"/reference/gaze_oob.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate Out-of-Bounds Proportion by Subject — gaze_oob","title":"Calculate Out-of-Bounds Proportion by Subject — gaze_oob","text":"function calculates number percentage points fall outside specified range (0, 1) X Y coordinates, grouped subject.","code":""},{"path":"/reference/gaze_oob.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate Out-of-Bounds Proportion by Subject — gaze_oob","text":"","code":"gaze_oob(   data,   subject_col = \"subject\",   x_col = \"x_pred_normalised\",   y_col = \"y_pred_normalised\" )"},{"path":"/reference/gaze_oob.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate Out-of-Bounds Proportion by Subject — gaze_oob","text":"data data frame containing gaze data. subject_col string specifying name column contains subject identifier. Default \"subject\". x_col string specifying name column contains X coordinate. Default \"x_pred_normalised\". y_col string specifying name column contains Y coordinate. Default \"y_pred_normalised\".","code":""},{"path":"/reference/gaze_oob.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate Out-of-Bounds Proportion by Subject — gaze_oob","text":"data frame following columns: subject subject identifier. total_points total number points subject. outside_count number points outside range X Y coordinates. x_outside_count number points outside range X coordinate. y_outside_count number points outside range Y coordinate. x_outside_percentage percentage points outside range X coordinate. y_outside_percentage percentage points outside range Y coordinate.","code":""},{"path":"/reference/gaze_oob.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate Out-of-Bounds Proportion by Subject — gaze_oob","text":"","code":"if (FALSE) { # \\dontrun{   # Example data   data <- data.frame(     subject = rep(1:2, each = 100),     x_pred_normalised = runif(200, -0.5, 1.5),     y_pred_normalised = runif(200, -0.5, 1.5)   )    # Calculate out-of-bounds proportion by subject   results <- calculate_out_of_bounds_by_subject(data)   print(results) } # }"},{"path":"/reference/merge_webcam_files.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract and Merge Gorilla Webcam Files with Optional AOI Extraction — merge_webcam_files","title":"Extract and Merge Gorilla Webcam Files with Optional AOI Extraction — merge_webcam_files","text":"function reads multiple Gorilla webcam files, merges , optionally extracts area interest (AOI) data. cleans column names, allows filtering screen index. `extract_aois` TRUE, extracts specific AOI-related columns (`zone_name`, `zone_x_normalized`, `zone_y_normalized`, `zone_width_normalized`, `zone_height_normalized`) returns distinct rows columns.","code":""},{"path":"/reference/merge_webcam_files.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract and Merge Gorilla Webcam Files with Optional AOI Extraction — merge_webcam_files","text":"","code":"merge_webcam_files(file_paths, screen_index = NULL)"},{"path":"/reference/merge_webcam_files.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract and Merge Gorilla Webcam Files with Optional AOI Extraction — merge_webcam_files","text":"file_paths list file paths webcam files (.xlsx format). screen_index optional screen index filter data . NULL, filter ignored. extract_aois Logical. TRUE, extracts AOI-related columns returns distinct rows .","code":""},{"path":"/reference/merge_webcam_files.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract and Merge Gorilla Webcam Files with Optional AOI Extraction — merge_webcam_files","text":"dataframe containing merged processed data webcam files. `extract_aois` TRUE, returns dataframe distinct AOI-related columns.","code":""},{"path":"/reference/merge_webcam_files.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract and Merge Gorilla Webcam Files with Optional AOI Extraction — merge_webcam_files","text":"","code":"# Example usage: # file_paths <- c(\"file1.xlsx\", \"file2.xlsx\") # merged_data <- extract_gorilla_aois(file_paths, screen_index = 4, extract_aois = FALSE) # aoi_data <- extract_gorilla_aois(file_paths, screen_index = 4, extract_aois = TRUE)"},{"path":"/reference/plot_IA_proportions.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Proportion of Looks Over Time for Interest Areas — plot_IA_proportions","title":"Plot Proportion of Looks Over Time for Interest Areas — plot_IA_proportions","text":"function generates plot proportion looks time specified Interest Areas (IAs). optionally facets plot condition column. user can provide custom labels IA.","code":""},{"path":"/reference/plot_IA_proportions.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Proportion of Looks Over Time for Interest Areas — plot_IA_proportions","text":"","code":"plot_IA_proportions(   data,   ia_column,   time_column,   proportion_column,   condition_column = NULL,   ... )"},{"path":"/reference/plot_IA_proportions.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Proportion of Looks Over Time for Interest Areas — plot_IA_proportions","text":"data data frame containing data plotted. ia_column name column containing Interest Areas (IAs). time_column name column representing time (e.g., milliseconds). proportion_column name column containing proportion looks IA. condition_column (Optional) name column representing experimental condition. provided, plot faceted condition. ... Mappings IA names custom labels (e.g., IA1 = \"target\", IA2 = \"unrelated\").","code":""},{"path":"/reference/plot_IA_proportions.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Proportion of Looks Over Time for Interest Areas — plot_IA_proportions","text":"ggplot2 plot showing proportion looks time IA, optionally faceted condition.","code":""},{"path":"/reference/plot_IA_proportions.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Proportion of Looks Over Time for Interest Areas — plot_IA_proportions","text":"","code":"# Example with a condition column plot_IA_proportions(gaze_data, ia_column = \"condition\", time_column = \"time_ms\",   proportion_column = \"proportion_looks\", condition_column = \"condition\",   IA1 = \"target\", IA2 = \"cohort\", IA3 = \"rhyme\", IA4 = \"unrelated\") #> Error in eval(expr, envir, enclos): object 'gaze_data' not found  # Example without a condition column plot_IA_proportions(gaze_data, ia_column = \"condition\", time_column = \"time_ms\",   proportion_column = \"proportion_looks\", IA1 = \"target\", IA2 = \"cohort\",   IA3 = \"rhyme\", IA4 = \"unrelated\") #> Error in eval(expr, envir, enclos): object 'gaze_data' not found"}]
